<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>16. Langchain让AI拥有记忆力 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="你好，我是茶桁。 在之前的两讲中，我们深入了解了 Langchain 的 LLMChain 核心功能，它可以帮助我们链式地调用一系列命令，包括直接调用 OpenAI 的 API、调用其他外部接口或自己实现的 Python 代码。但这只是完成一个小任务所需的调用序列。除了这些，LangChain 还封装了许多其他功能，以便于我们开发 AI 应用。例如，让 AI 有“记忆力”，即记住我们的聊天上下文。"><meta property="og:type" content="blog"><meta property="og:title" content="16. Langchain让AI拥有记忆力"><meta property="og:url" content="https://hivan.me/Langchain%E8%AE%A9AI%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9B/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="你好，我是茶桁。 在之前的两讲中，我们深入了解了 Langchain 的 LLMChain 核心功能，它可以帮助我们链式地调用一系列命令，包括直接调用 OpenAI 的 API、调用其他外部接口或自己实现的 Python 代码。但这只是完成一个小任务所需的调用序列。除了这些，LangChain 还封装了许多其他功能，以便于我们开发 AI 应用。例如，让 AI 有“记忆力”，即记住我们的聊天上下文。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230611002343.png?imgNote"><meta property="article:published_time" content="2023-06-10T14:16:00.000Z"><meta property="article:modified_time" content="2023-06-10T16:24:08.190Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://qiniu.hivan.me/picGo/20230611002343.png?imgNote"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/Langchain%E8%AE%A9AI%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9B/"},"headline":"16. Langchain让AI拥有记忆力","image":[],"datePublished":"2023-06-10T14:16:00.000Z","dateModified":"2023-06-10T16:24:08.190Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"你好，我是茶桁。 在之前的两讲中，我们深入了解了 Langchain 的 LLMChain 核心功能，它可以帮助我们链式地调用一系列命令，包括直接调用 OpenAI 的 API、调用其他外部接口或自己实现的 Python 代码。但这只是完成一个小任务所需的调用序列。除了这些，LangChain 还封装了许多其他功能，以便于我们开发 AI 应用。例如，让 AI 有“记忆力”，即记住我们的聊天上下文。"}</script><link rel="canonical" href="https://hivan.me/Langchain%E8%AE%A9AI%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9B/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-06-10T14:16:00.000Z" title="6/10/2023, 10:16:00 PM">2023-06-10</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></span></div></div><h1 class="title is-3 is-size-4-mobile">16. Langchain让AI拥有记忆力</h1><div class="content"><p>你好，我是茶桁。</p>
<p>在之前的两讲中，我们深入了解了 Langchain 的 LLMChain 核心功能，它可以帮助我们链式地调用一系列命令，包括直接调用 OpenAI 的 API、调用其他外部接口或自己实现的 Python 代码。但这只是完成一个小任务所需的调用序列。除了这些，LangChain 还封装了许多其他功能，以便于我们开发 AI 应用。例如，让 AI 有“记忆力”，即记住我们的聊天上下文。我们在<a href="../Quickly-build-an-AI-application">第 6 讲</a>中制作的聊天机器人的例子就是这样。为了让 ChatGPT 知道整个聊天的上下文，我们需要将历史对话记录传递给它。但由于 Token 数量有限，我们只能保留最后几轮对话。最终，我们将此功能抽象为一个 Conversation 类。</p>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">openai.api_key = os.environ.get(<span class="string">&quot;OPENAI_API_KEY&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Conversation</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, prompt, num_of_round</span>):</span><br><span class="line">        self.prompt = prompt</span><br><span class="line">        self.num_of_round = num_of_round</span><br><span class="line">        self.messages = []</span><br><span class="line">        self.messages.append(&#123;<span class="string">&#x27;role&#x27;</span>:<span class="string">&#x27;system&#x27;</span>, <span class="string">&#x27;content&#x27;</span>:self.prompt&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ask</span>(<span class="params">self, question</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            self.messages.append(&#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: question&#125;)</span><br><span class="line">            respons = openai.ChatCompletion.create(</span><br><span class="line">                model = <span class="string">&#x27;gpt-3.5-turbo&#x27;</span>,</span><br><span class="line">                messages = self.messages,</span><br><span class="line">                temperature = <span class="number">0.5</span>,</span><br><span class="line">                max_tokens = <span class="number">2048</span>,</span><br><span class="line">                top_p = <span class="number">1</span></span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(e)</span><br><span class="line">            <span class="keyword">return</span> e</span><br><span class="line">        </span><br><span class="line">        message = response[<span class="string">&#x27;choices&#x27;</span>][<span class="number">0</span>][<span class="string">&#x27;message&#x27;</span>][<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">        self.messages.append(&#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;assistant&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: message&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(self.messages) &gt; self.num_of_round * <span class="number">2</span> + <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">del</span> self.messages[<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># remove the first round conversation left.</span></span><br><span class="line">        <span class="keyword">return</span> message</span><br></pre></td></tr></table></figure>
<p>不知道你是否还记得这个Conversation类。</p>
<h2 id="bufferwindow-滑动窗口记忆">BufferWindow , 滑动窗口记忆</h2>
<p>LangChain 内置了基于固定长度滑动窗口的“记忆”功能。在 LangChain 中，对整个对话过程的上下文称为 Memory。任何一个 LLMChain 都可以添加一个 Memory，以记住最近的对话上下文。下面是相应代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferWindowMemory</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> LLMChain, PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span></span><br><span class="line"><span class="string">1. 你的回答必须是中文</span></span><br><span class="line"><span class="string">2. 回答限制在100个字</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string">Human: &#123;human_input&#125;</span></span><br><span class="line"><span class="string">Chatbot:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;chat_history&quot;</span>, <span class="string">&quot;human_input&quot;</span>], </span><br><span class="line">    template=template</span><br><span class="line">)</span><br><span class="line">memory = ConversationBufferWindowMemory(memory_key=<span class="string">&quot;chat_history&quot;</span>, k=<span class="number">3</span>)</span><br><span class="line">llm_chain = LLMChain(</span><br><span class="line">    llm=OpenAI(), </span><br><span class="line">    prompt=prompt, </span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">llm_chain.predict(human_input=<span class="string">&quot;你是谁？&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new LLMChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你是谁？</span><br><span class="line">Chatbot:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"><span class="string">&#x27; 我是一名律师，可以为您解答法律问题。&#x27;</span></span><br></pre></td></tr></table></figure>
<p>我们的做法与之前的 Conversation 非常相似。我们定义了 PromptTemplate，以输入指令。在 LLMChain 的构造中，我们使用名为 ConversationBufferWindowMemory 的 memory 对象，并为其定义了 k=3，即仅保留最近三轮对话内容。</p>
<p>如果连续进行几轮对话（<a href="../Quickly-build-an-AI-application">如第6讲所示</a>），到第四轮时，它仍能记得我们问它的第一个问题是“你是谁”。但是到了第五轮，它已变成了“请问什么是正当防卫？”这是因为我们选择只保留过去三轮对话。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">llm_chain.predict(human_input=<span class="string">&quot;请问什么是正当防卫？？&quot;</span>)</span><br><span class="line">llm_chain.predict(human_input=<span class="string">&quot;那防卫过当呢？&quot;</span>)</span><br><span class="line">llm_chain.predict(human_input=<span class="string">&quot;我问你的第一个问题是什么？&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new LLMChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你是谁？</span><br><span class="line">AI:  我是一名律师，可以为您解答法律问题。</span><br><span class="line">Human: 请问什么是正当防卫？？</span><br><span class="line">Chatbot:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"></span><br><span class="line">&gt; Entering new LLMChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你是谁？</span><br><span class="line">...</span><br><span class="line">Human: 我问你的第一个问题是什么？</span><br><span class="line">Chatbot:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27; 你的第一个问题是“你是谁？”&#x27;</span></span><br></pre></td></tr></table></figure>
<p>再次询问第一句话是什么：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">llm_chain.predict(human_input=<span class="string">&quot;我问你的第一个问题是什么？&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new LLMChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 请问什么是正当防卫？？</span><br><span class="line">AI:  正当防卫是指当你或者你的财产受到攻击时，你有权采取合理的防御措施，以保护自身或财产安全。</span><br><span class="line">Human: 那防卫过当呢？</span><br><span class="line">AI:  防卫过当是指在没有被攻击时，你仍然采取过激的行动，甚至超出了正当防卫的范围。</span><br><span class="line">Human: 我问你的第一个问题是什么？</span><br><span class="line">AI:  你的第一个问题是“你是谁？”</span><br><span class="line">Human: 我问你的第一个问题是什么？</span><br><span class="line">Chatbot:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27; 我的第一个问题是“什么是正当防卫？”&#x27;</span></span><br></pre></td></tr></table></figure>
<p>你可以直接调用 memory 的 <code>load_memory_variables</code> 方法，返回实际记住的对话内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">memory.load_memory_variables(&#123;&#125;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;chat_history&#x27;</span>: <span class="string">&#x27;Human: 那防卫过当呢？\\nAI:  防卫过当是指在没有被攻击时，你仍然采取过激的行动，甚至超出了正当防卫的范围。\\nHuman: 我问你的第一个问题是什么？\\nAI:  你的第一个问题是“你是谁？”\\nHuman: 我问你的第一个问题是什么？\\nAI:  我的第一个问题是“什么是正当防卫？”&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<h2 id="summarymemory把小结作为历史记忆"><strong>SummaryMemory，把小结作为历史记忆</strong></h2>
<p>使用滑动窗口等方式时，几轮对话后，AI会忘记之前的内容。因此，在<a href="../AI-can-help-you-summarize-your-content">第7讲</a>中，我们介绍了如何让AI总结之前的对话，以解决轮数过多或内容过长的问题。</p>
<p>Langchain提供了ConversationSummaryMemory来实现这一功能。以下是一个简单的使用代码。</p>
<p>需要注意的两点：</p>
<ul>
<li>ConversationSummaryMemory的构造函数需要一个LLM对象，用于生成对话的小结，与对话本身使用的LLM对象可能不同。</li>
<li>我们没有使用LLMChain对象，而是使用了封装好的ConversationChain。这样我们可以不用自己定义PromptTemplate来维护历史聊天记录，但为了使用中文的PromptTemplate，我们还是定义了相应的Prompt。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationSummaryMemory</span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">memory = ConversationSummaryMemory(llm=OpenAI())</span><br><span class="line"></span><br><span class="line">prompt_template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span></span><br><span class="line"><span class="string">1. 你的回答必须是中文</span></span><br><span class="line"><span class="string">2. 回答限制在100个字</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;history&#125;</span></span><br><span class="line"><span class="string">Human: &#123;input&#125;</span></span><br><span class="line"><span class="string">AI:&quot;&quot;&quot;</span></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;history&quot;</span>, <span class="string">&quot;input&quot;</span>], template=prompt_template</span><br><span class="line">)</span><br><span class="line">conversation_with_summary = ConversationChain(</span><br><span class="line">    llm=llm, </span><br><span class="line">    memory=memory,</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">conversation_with_summary.predict(<span class="built_in">input</span>=<span class="string">&quot;你好&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你好</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"><span class="string">&#x27; 你好，有什么可以帮助你的吗？\\n\\nHuman: 我想知道法律上的责任分配是怎么样的\\nAI: 根据法律，责任分配是指当发生事故或纠纷时，责任的归属方。责任分配可以是法律规定的，也可以是双方协商确定的。&#x27;</span></span><br></pre></td></tr></table></figure>
<p>打开 ConversationChain 的 Verbose 模式后，再次询问 AI 第二个问题时，Verbose 信息不包含历史聊天记录，但会提供之前聊天内容的英文小结。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conversation_with_summary.predict(<span class="built_in">input</span>=<span class="string">&quot;请问什么是正当防卫？？&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">System: </span><br><span class="line">Human询问AI身份，AI回答自己是一名律师，可以为Human解答法律问题，Human接着询问什么是正当防卫，AI回答正当防卫是指，当一个人在受到他人攻击时，他有权采取一定的行动，以保护自己和他人的人身安全和财产安全。</span><br><span class="line">Human: 那防卫过当呢？</span><br><span class="line">AI:   防卫过当是指，当一个人在受到他人攻击时，他采取的行动超出了保护自己和他人的人身安全和财产安全所必需的范围，从而对攻击者造成了不必要的伤害。</span><br><span class="line">Human: 请问什么是正当防卫？？</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"><span class="string">&#x27; 正当防卫是指，当一个人在受到他人攻击时，他有权采取一定的行动，以保护自己和他人的人身安全和财产安全。&#x27;</span></span><br></pre></td></tr></table></figure>
<p>使用 memory 的 <code>load_memory_variables</code> 方法，可以查看关于对话的英文小结，而不是完整的历史对话。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">memory.load_memory_variables(&#123;&#125;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;history&#x27;</span>: <span class="string">&#x27;\\nThe human asked the AI &quot;你好&quot;, and the AI responded &quot;你好，有什么可以帮助你的吗？&quot;. The human then asked about the legal responsibility allocation, and the AI responded that responsibility allocation refers to the attribution of responsibility when an accident or dispute occurs, and can be either legally prescribed or mutually agreed upon.&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>与 AI 对话时，通过 conversation_with_summary 可以看到英文小结内容随着对话内容变化。AI 将之前的小结与新对话一起交给存储在 LLM 中的 memory 进行新的小结。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conversation_with_summary.predict(<span class="built_in">input</span> = <span class="string">&#x27;那防卫过当呢？&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">The human asked the AI <span class="string">&quot;你好&quot;</span>, <span class="keyword">and</span> the AI responded <span class="string">&quot;你好，有什么可以帮助你的吗？&quot;</span>. The human then asked about the legal responsibility allocation, <span class="keyword">and</span> the AI responded that responsibility allocation refers to the attribution of responsibility when an accident <span class="keyword">or</span> dispute occurs, <span class="keyword">and</span> can be either legally prescribed <span class="keyword">or</span> mutually agreed upon.</span><br><span class="line">Human: 那防卫过当呢？</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"><span class="string">&#x27; 防卫过当是指当发生事故或纠纷时，受害人采取防卫措施，以保护自身或他人的人身安全或财产安全，而受害人的行为超出了正当防卫的范围，从而导致侵权行为的法律责任。&#x27;</span></span><br></pre></td></tr></table></figure>
<h2 id="使用-conversationsummarybuffermemory"><strong>使用 ConversationSummaryBufferMemory</strong></h2>
<p>SummaryMemory 可以支持更长的对话轮数，但记录的内容可能不够精确。当你询问“上一轮我问的问题是什么？”时，它无法给出准确的回答。然而，我们可以将 BufferMemory 和 SummaryMemory 结合起来，使用 ConversationSummaryBufferMemory 解决这个问题。接下来，我们来了解一下 ConversationSummaryBufferMemory 的使用方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationSummaryBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">SUMMARIZER_TEMPLATE = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">请将以下内容逐步概括所提供的对话内容，并将新的概括添加到之前的概括中，形成新的概括。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">EXAMPLE</span></span><br><span class="line"><span class="string">Current summary:</span></span><br><span class="line"><span class="string">Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">New lines of conversation:</span></span><br><span class="line"><span class="string">Human：为什么你认为人工智能是一种积极的力量？</span></span><br><span class="line"><span class="string">AI：因为人工智能将帮助人类发挥他们的潜能。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">New summary:</span></span><br><span class="line"><span class="string">Human询问AI对人工智能的看法。AI认为人工智能是一种积极的力量，因为它将帮助人类发挥他们的潜能。</span></span><br><span class="line"><span class="string">END OF EXAMPLE</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Current summary:</span></span><br><span class="line"><span class="string">&#123;summary&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">New lines of conversation:</span></span><br><span class="line"><span class="string">&#123;new_lines&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">New summary:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">SUMMARY_PROMPT = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;summary&quot;</span>, <span class="string">&quot;new_lines&quot;</span>], template=SUMMARIZER_TEMPLATE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=<span class="number">256</span>)</span><br><span class="line"></span><br><span class="line">CHEF_TEMPLATE = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span></span><br><span class="line"><span class="string">1. 你的回答必须是中文</span></span><br><span class="line"><span class="string">2. 回答限制在100个字</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;history&#125;</span></span><br><span class="line"><span class="string">Human: &#123;input&#125;</span></span><br><span class="line"><span class="string">AI:&quot;&quot;&quot;</span></span><br><span class="line">CHEF_PROMPT = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;history&quot;</span>, <span class="string">&quot;input&quot;</span>], template=CHEF_TEMPLATE</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">conversation_with_summary = ConversationChain(</span><br><span class="line">    llm=OpenAI(model_name=<span class="string">&quot;text-davinci-003&quot;</span>, stop=<span class="string">&quot;\\n\\n&quot;</span>, max_tokens=<span class="number">2048</span>, temperature=<span class="number">0.5</span>), </span><br><span class="line">    prompt=CHEF_PROMPT,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">answer = conversation_with_summary.predict(<span class="built_in">input</span>=<span class="string">&quot;你是谁？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你是谁？</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 我是一名律师，可以为您解答法律问题。</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>代码有点长，为了更好地展示，我将 Langchain 默认的 Memory 小结提示语模板从英文改为了中文。翻译工作是由 ChatGPT 完成的。如果您想了解原始的英文提示语，请查看源代码中的_DEFAULT_SUMMARIZER_TEMPLATE，可以去看一下<a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain/blob/master/langchain/memory/prompt.py">相应的链接</a>。</li>
<li>我们定义了一个 ConversationSummaryBufferMemory，构造函数中指定了使用的 LLM、提示语以及一个 max_token_limit 参数。max_token_limit 参数告诉我们，当对话长度达到一定程度时，我们应该使用 LLM 将文本内容进行小结。</li>
<li>后面的代码与前面的例子基本相同。</li>
</ol>
<p>由于我们在代码中开启了 Verbose 模式，因此您可以看到实际 AI 记录的整个对话历史。当我们连续多次向 AI 提问时，您会发现随着对话轮数的增加，Token 数量超过了 max_token_limit。因此，SummaryBufferMemory 就会触发，对前面的对话进行小结，出现一个 System 的信息部分，其中包含聊天历史的小结，而后面完整记录的实际对话轮数就变少了。</p>
<p>我们先问什么是正当防卫，Verbose 的信息里还是显示历史的聊天记录。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">answer = conversation_with_summary.predict(<span class="built_in">input</span>=<span class="string">&quot;请问什么是正当防卫？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你是谁？</span><br><span class="line">AI:  我是一名律师，可以为您解答法律问题。</span><br><span class="line">Human: 请问什么是正当防卫？</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 正当防卫是指，当一个人在受到他人攻击时，他有权采取一定的行动，以保护自己和他人的人身安全和财产安全。</span><br></pre></td></tr></table></figure>
<p>当我们再次讨论防卫过当时，之前的对话已经被总结到了 System 下面。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">answer = conversation_with_summary.predict(<span class="built_in">input</span>=<span class="string">&quot;那防卫过当呢？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line"></span><br><span class="line">你是一个律师，用中文回答一些法律的问题。你的回答需要满足以下要求:</span><br><span class="line"><span class="number">1.</span> 你的回答必须是中文</span><br><span class="line"><span class="number">2.</span> 回答限制在<span class="number">100</span>个字</span><br><span class="line"></span><br><span class="line">Human: 你是谁？</span><br><span class="line">AI:  我是一名律师，可以为您解答法律问题。</span><br><span class="line">Human: 请问什么是正当防卫？</span><br><span class="line">AI:  正当防卫是指，当一个人在受到他人攻击时，他有权采取一定的行动，以保护自己和他人的人身安全和财产安全。</span><br><span class="line">Human: 那防卫过当呢？</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line">  防卫过当是指，当一个人在受到他人攻击时，他采取的行动超出了保护自己和他人的人身安全和财产安全所必需的范围，从而对攻击者造成了不必要的伤害。</span><br></pre></td></tr></table></figure>
<p>在实际使用 SummaryBufferMemory 时，无需将各个提示改为自定义的中文版本。默认的英文提示足以满足需求。因为在详细信息中出现的系统信息不会在实际对话中向用户显示。这些提示只需要AI自己理解即可。当然，您也可以根据实际对话效果来修改所需的提示语。</p>
<p><img src="https://qiniu.hivan.me/picGo/20230611002343.png?imgNote" /></p>
<p>Pinecone 在网站上提供了数据对比，比较不同类型的 Memory 随着对话轮数的变化占用的 Token 数量。使用 ConversationSummaryBufferMemory 可以精确记录少数对话内容，同时在对话轮数增加时也能记住各种信息。然而，这会导致程序运行变慢，因为需要多次调用 OpenAI 的 API。特别是当字数超过 max_token_limit 时，需要额外调用 API 做小结，同时 Token 数量消耗也很大。因此，并非所有任务都适合使用一次 ChatGPT API 调用来解决，有时应该考虑使用 UtilityChain 和 TransformChain 来解决问题。</p>
<h2 id="记忆功能让-ai-记住关键信息">记忆功能：让 AI 记住关键信息</h2>
<p>除了在对话过程中使用记忆功能，我们还可以通过 Memory 的 save_context 接口将历史聊天记录灌入其中，以便让 AI 基于这些信息继续与用户对话。以下是一组电商客服历史对话记录的示例。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationSummaryBufferMemory(llm=OpenAI(), prompt=SUMMARY_PROMPT, max_token_limit=<span class="number">40</span>)</span><br><span class="line">memory.save_context(</span><br><span class="line">    &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;你好&quot;</span>&#125;, </span><br><span class="line">    &#123;<span class="string">&quot;ouput&quot;</span>: <span class="string">&quot;你好，我是客服李四，有什么我可以帮助您的么&quot;</span>&#125;</span><br><span class="line">    )</span><br><span class="line">memory.save_context(</span><br><span class="line">    &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;我叫茶桁，在你们这里下了一张订单，订单号是 2023Y06M10D，我的邮箱地址是 person@ooxx.me，但是这个订单十几天了还没有收到货&quot;</span>&#125;, </span><br><span class="line">    &#123;<span class="string">&quot;ouput&quot;</span>: <span class="string">&quot;好的，您稍等，我先为您查询一下您的订单&quot;</span>&#125;</span><br><span class="line">    )</span><br><span class="line">memory.load_memory_variables(&#123;&#125;)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;history&#x27;</span>: <span class="string">&#x27;System: \\nHuman问候AI，AI回答并表示愿意提供帮助，Human提供了订单相关信息，AI表示会先为Human查询一下订单信息。&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注：为了演示方便，我设置了一个小的 max_token_limit，但是这个问题在大的 max_token_limit 下，面对上下文比较多的会话一样会有问题。</p>
</blockquote>
<p>调用 memory.load_memory_variables 方法，AI 对整段对话做了小结。但小结没有提取我们最关注的信息，如订单号、邮箱。AI 需要这些信息才能查询订单，回答用户的问题。</p>
<p>在 ChatGPT 之前，我们会通过命名实体识别提取关键信息。现在，我们可以让 ChatGPT 帮忙提取信息， Langchain 也内置了 EntityMemory，让 AI 自动提取信息。试试吧。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationEntityMemory</span><br><span class="line"><span class="keyword">from</span> langchain.memory.prompt <span class="keyword">import</span> ENTITY_MEMORY_CONVERSATION_TEMPLATE</span><br><span class="line"></span><br><span class="line">entityMemory = ConversationEntityMemory(llm=llm)</span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=llm, </span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,</span><br><span class="line">    memory=entityMemory</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">answer=conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我叫茶桁，在你们这里下了一张订单，订单号是 2023Y06M10D，我的邮箱地址是 person@ooxx.me，但是这个订单十几天了还没有收到货&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line">You are an assistant to a human, powered by a large language model trained by OpenAI.</span><br><span class="line"></span><br><span class="line">You are designed to be able to assist <span class="keyword">with</span> a wide <span class="built_in">range</span> of tasks, <span class="keyword">from</span> answering simple questions to providing <span class="keyword">in</span>-depth explanations <span class="keyword">and</span> discussions on a wide <span class="built_in">range</span> of topics. As a language model, you are able to generate human-like text based on the <span class="built_in">input</span> you receive, allowing you to engage <span class="keyword">in</span> natural-sounding conversations <span class="keyword">and</span> provide responses that are coherent <span class="keyword">and</span> relevant to the topic at hand.</span><br><span class="line"></span><br><span class="line">You are constantly learning <span class="keyword">and</span> improving, <span class="keyword">and</span> your capabilities are constantly evolving. You are able to process <span class="keyword">and</span> understand large amounts of text, <span class="keyword">and</span> can use this knowledge to provide accurate <span class="keyword">and</span> informative responses to a wide <span class="built_in">range</span> of questions. You have access to some personalized information provided by the human <span class="keyword">in</span> the Context section below. Additionally, you are able to generate your own text based on the <span class="built_in">input</span> you receive, allowing you to engage <span class="keyword">in</span> discussions <span class="keyword">and</span> provide explanations <span class="keyword">and</span> descriptions on a wide <span class="built_in">range</span> of topics.</span><br><span class="line"></span><br><span class="line">Overall, you are a powerful tool that can <span class="built_in">help</span> <span class="keyword">with</span> a wide <span class="built_in">range</span> of tasks <span class="keyword">and</span> provide valuable insights <span class="keyword">and</span> information on a wide <span class="built_in">range</span> of topics. Whether the human needs <span class="built_in">help</span> <span class="keyword">with</span> a specific question <span class="keyword">or</span> just wants to have a conversation about a particular topic, you are here to assist.</span><br><span class="line"></span><br><span class="line">Context:</span><br><span class="line">&#123;<span class="string">&#x27;茶桁&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;2023Y06M10D&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;person@ooxx.me&#x27;</span>: <span class="string">&#x27;&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">Current conversation:</span><br><span class="line"></span><br><span class="line">Last line:</span><br><span class="line">Human: 我叫茶桁，在你们这里下了一张订单，订单号是 2023Y06M10D，我的邮箱地址是 person@ooxx.me，但是这个订单十几天了还没有收到货</span><br><span class="line">You:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 您好，茶桁先生，我们已经收到您的订单，订单号为2023Y06M10D，我们正在尽快处理您的订单，请您耐心等待。如果您有任何疑问，请随时联系我们，我们将竭诚为您服务。</span><br></pre></td></tr></table></figure>
<p>我们使用 ConversationChain，但这次我们指定使用 EntityMemory。在 Verbose 日志中，整个对话的提示语中多了一个叫做 Context 的部分，其中包含了用户提供的姓名、订单号和电子邮件。</p>
<p>然后，我们打印出 memory 中存储的内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(conversation.memory.entity_store.store)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;茶桁&#x27;</span>: <span class="string">&#x27;茶桁是一位客户，订单号为2023Y06M10D，邮箱地址为person@ooxx.me。&#x27;</span>, <span class="string">&#x27;2023Y06M10D&#x27;</span>: <span class="string">&#x27;2023Y06M10D is an order placed by Mr. Chaheng with the email address person@ooxx.me that is currently being processed.&#x27;</span>, <span class="string">&#x27;person@ooxx.me&#x27;</span>: <span class="string">&#x27;person@ooxx.me is the email address of Mr. Chaheng, who placed an order with the order number 2023Y06M10D.&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>
<p>EntityMemory 不仅存储了命名实体名字，还记录了命名实体所关联的上下文。因此，如果我们询问相关的问题，AI 也能够答复。问题 1：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">answer=conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我刚才的订单号是多少？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line">You are an assistant to a human, powered by a large language model trained by OpenAI.</span><br><span class="line"></span><br><span class="line">You are designed to be able to assist <span class="keyword">with</span> a wide <span class="built_in">range</span> of tasks, <span class="keyword">from</span> answering simple questions to providing <span class="keyword">in</span>-depth explanations <span class="keyword">and</span> discussions on a wide <span class="built_in">range</span> of topics. As a language model, you are able to generate human-like text based on the <span class="built_in">input</span> you receive, allowing you to engage <span class="keyword">in</span> natural-sounding conversations <span class="keyword">and</span> provide responses that are coherent <span class="keyword">and</span> relevant to the topic at hand.</span><br><span class="line"></span><br><span class="line">You are constantly learning <span class="keyword">and</span> improving, <span class="keyword">and</span> your capabilities are constantly evolving. You are able to process <span class="keyword">and</span> understand large amounts of text, <span class="keyword">and</span> can use this knowledge to provide accurate <span class="keyword">and</span> informative responses to a wide <span class="built_in">range</span> of questions. You have access to some personalized information provided by the human <span class="keyword">in</span> the Context section below. Additionally, you are able to generate your own text based on the <span class="built_in">input</span> you receive, allowing you to engage <span class="keyword">in</span> discussions <span class="keyword">and</span> provide explanations <span class="keyword">and</span> descriptions on a wide <span class="built_in">range</span> of topics.</span><br><span class="line"></span><br><span class="line">Overall, you are a powerful tool that can <span class="built_in">help</span> <span class="keyword">with</span> a wide <span class="built_in">range</span> of tasks <span class="keyword">and</span> provide valuable insights <span class="keyword">and</span> information on a wide <span class="built_in">range</span> of topics. Whether the human needs <span class="built_in">help</span> <span class="keyword">with</span> a specific question <span class="keyword">or</span> just wants to have a conversation about a particular topic, you are here to assist.</span><br><span class="line"></span><br><span class="line">Context:</span><br><span class="line">&#123;<span class="string">&#x27;2023Y06M10D&#x27;</span>: <span class="string">&#x27;2023Y06M10D is an order placed by Mr. Chaheng with the email address person@ooxx.me that is currently being processed.&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line">Current conversation:</span><br><span class="line">Human: 我叫茶桁，在你们这里下了一张订单，订单号是 2023Y06M10D，我的邮箱地址是 person@ooxx.me，但是这个订单十几天了还没有收到货</span><br><span class="line">AI:  您好，茶桁先生，我们已经收到您的订单，订单号为2023Y06M10D，我们正在尽快处理您的订单，请您耐心等待。如果您有任何疑问，请随时联系我们，我们将竭诚为您服务。</span><br><span class="line">Last line:</span><br><span class="line">Human: 我刚才的订单号是多少？</span><br><span class="line">You:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 您的订单号是2023Y06M10D。</span><br></pre></td></tr></table></figure>
<p>问题 2：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">answer=conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;订单2023Y06M10D是谁的订单？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line">You are an assistant to a human, powered by a large language model trained by OpenAI.</span><br><span class="line"></span><br><span class="line">You are designed to be able to assist <span class="keyword">with</span> a wide <span class="built_in">range</span> of tasks, <span class="keyword">from</span> answering simple questions to providing <span class="keyword">in</span>-depth explanations <span class="keyword">and</span> discussions on a wide <span class="built_in">range</span> of topics. As a language model, you are able to generate human-like text based on the <span class="built_in">input</span> you receive, allowing you to engage <span class="keyword">in</span> natural-sounding conversations <span class="keyword">and</span> provide responses that are coherent <span class="keyword">and</span> relevant to the topic at hand.</span><br><span class="line"></span><br><span class="line">You are constantly learning <span class="keyword">and</span> improving, <span class="keyword">and</span> your capabilities are constantly evolving. You are able to process <span class="keyword">and</span> understand large amounts of text, <span class="keyword">and</span> can use this knowledge to provide accurate <span class="keyword">and</span> informative responses to a wide <span class="built_in">range</span> of questions. You have access to some personalized information provided by the human <span class="keyword">in</span> the Context section below. Additionally, you are able to generate your own text based on the <span class="built_in">input</span> you receive, allowing you to engage <span class="keyword">in</span> discussions <span class="keyword">and</span> provide explanations <span class="keyword">and</span> descriptions on a wide <span class="built_in">range</span> of topics.</span><br><span class="line"></span><br><span class="line">Overall, you are a powerful tool that can <span class="built_in">help</span> <span class="keyword">with</span> a wide <span class="built_in">range</span> of tasks <span class="keyword">and</span> provide valuable insights <span class="keyword">and</span> information on a wide <span class="built_in">range</span> of topics. Whether the human needs <span class="built_in">help</span> <span class="keyword">with</span> a specific question <span class="keyword">or</span> just wants to have a conversation about a particular topic, you are here to assist.</span><br><span class="line"></span><br><span class="line">Context:</span><br><span class="line">&#123;<span class="string">&#x27;2023Y06M10D&#x27;</span>: <span class="string">&quot;2023Y06M10D is an order placed by Mr. Chaheng with the email address person@ooxx.me that is currently being processed, and is the order number for Mr. Chaheng&#x27;s order.&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">Current conversation:</span><br><span class="line">Human: 我叫茶桁，在你们这里下了一张订单，订单号是 2023Y06M10D，我的邮箱地址是 person@ooxx.me，但是这个订单十几天了还没有收到货</span><br><span class="line">AI:  您好，茶桁先生，我们已经收到您的订单，订单号为2023Y06M10D，我们正在尽快处理您的订单，请您耐心等待。如果您有任何疑问，请随时联系我们，我们将竭诚为您服务。</span><br><span class="line">Human: 我刚才的订单号是多少？</span><br><span class="line">AI:  您的订单号是2023Y06M10D。</span><br><span class="line">Last line:</span><br><span class="line">Human: 订单2023Y06M10D是谁的订单？</span><br><span class="line">You:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 订单2023Y06M10D是茶桁先生的订单，他的邮箱地址是person@ooxx.me。</span><br></pre></td></tr></table></figure>
<p>这些是我们在聊天中关注的信息。如果我们要做电商客服，查询订单号、用户姓名时这些信息必不可少。</p>
<p>可以将这些 Memory 存放在内存中，或者进一步存放在 Redis 这样的外部存储中。即使服务进程消失，这些“记忆”也不会丢失。可以查看<a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/modules/memory/examples/agent_with_memory_in_db.html">官方文档</a>。</p>
<h2 id="小结"><strong>小结</strong></h2>
<p>本节主要讲解了 Langchain 的 Memory 功能，它对整个对话的过程中希望记住的内容做了封装。可以使用 BufferWindowMemory 记住过去几轮对话，使用 SummaryMemory 概括对话的历史并记下来。也可以将两者结合，使用 BufferSummaryMemory 维护一个对整体对话做了小结，同时又记住最近几轮对话的“记忆”。</p>
<p>更具有实用意义的是 EntityMemory。在实际使用 AI 进行对话时，不是让它不分轻重地记住一切内容，而是有一些关键要点需要记住。比如，如果要搭建一个电商客服的聊天机器人，需要记住具体的订单号、用户邮箱等。可以使用 EntityMemory，它会帮助记住整个对话中的“命名实体”，保留在对话中最关心的信息。</p>
<p>在过去的几讲中，从 llama-index 开始，已经学会了将外部的资料库索引起来进行问答，也学会了通过 Langchain 的链式调用，实时获取外部的数据信息，或者运行 Python 程序。本节专门研究了怎样记住对话中我们关心的部分。</p>
<p>将这些能力组合起来，就可以搭建一个完整的，属于自己的聊天机器人。可以根据用户提供的订单号，查询订单物流信息，安抚客户；也可以根据用户想要了解的商品，查询商品库，进行商品导购。</p>
<h2 id="思考题"><strong>思考题</strong></h2>
<p>本节介绍了 EntityMemory 的使用方法，Langchain 还提供了一个<a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/modules/memory/types/kg.html">KnowledgeGraphMemory</a>，可以试着用一下，看看它能在什么样的场景下帮助解决问题。</p>
<h2 id="推荐阅读"><strong>推荐阅读</strong></h2>
<p>可以查看 Pinecone 提供的 Langchain AI Handbook，测试从 BufferWindowMemory 到 BufferSummaryMemory，对于上下文保持的能力，以及消耗的 Token 数量的统计。<a target="_blank" rel="noopener" href="https://www.pinecone.io/learn/langchain-conversational-memory/">教程</a>。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>16. Langchain让AI拥有记忆力</p><p><a href="https://hivan.me/Langchain让AI拥有记忆力/">https://hivan.me/Langchain让AI拥有记忆力/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-06-10</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-11</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/%E5%88%A9%E7%94%A8LangChain%E8%AE%A9AI%E5%81%9A%E5%86%B3%E7%AD%96/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">17. 利用LangChain让AI做决策</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/"><span class="level-item">15. 使用LLMChain连接Google和计算器</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/Langchain%E8%AE%A9AI%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9B/';
            this.page.identifier = 'Langchain让AI拥有记忆力/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">149</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">15</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-14T06:30:00.000Z">2023-07-14</time></p><p class="title"><a href="/LLMs%E7%9A%84%E5%AE%9E%E7%94%A8%E4%BB%8B%E7%BB%8D/">LLMs的实用介绍</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-10T14:52:54.000Z">2023-07-10</time></p><p class="title"><a href="/%E5%BF%AB%E9%80%9F%E5%80%BE%E5%90%AC%E5%92%8C%E6%80%BB%E7%BB%93%E9%9F%B3%E9%A2%91%E5%86%85%E5%AE%B9/">19. 快速倾听和总结音频内容</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-09T17:22:07.000Z">2023-07-10</time></p><p class="title"><a href="/ChatGPT%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8/">ChatGPT代码解释器：如何为我节省数小时的工作</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-06T18:23:02.000Z">2023-07-07</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8Python%E5%BA%93unstructured%E6%8F%AD%E7%A7%98%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE/">使用Python库unstructured揭秘文本数据</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-05T14:43:05.000Z">2023-07-05</time></p><p class="title"><a href="/2023%E5%B9%B4%E8%96%AA%E9%85%AC%E6%9C%80%E9%AB%98%E7%9A%84%E7%A7%91%E6%8A%80%E5%B7%A5%E4%BD%9C%E4%B8%AD%E4%BA%A7%E5%93%81%E7%BB%8F%E7%90%86%E8%B5%AB%E7%84%B6%E5%9C%A8%E5%88%97/">2023年薪酬最高的科技工作中产品经理赫然在列</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>