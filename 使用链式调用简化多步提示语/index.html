<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>14. 使用链式调用简化多步提示语 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Hi, 大家好，我是茶桁。 OpenAI 的大语言模型提供了 Completion 和 Embedding 两个核心接口。 我们可以通过增加提示语（Prompt）历史记录来提高模型的回答准确性和自然性。还可以将 Embedding提前索引好存起来，以此做到让AI根据外部知识来回答问题，"><meta property="og:type" content="blog"><meta property="og:title" content="14. 使用链式调用简化多步提示语"><meta property="og:url" content="https://hivan.me/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Hi, 大家好，我是茶桁。 OpenAI 的大语言模型提供了 Completion 和 Embedding 两个核心接口。 我们可以通过增加提示语（Prompt）历史记录来提高模型的回答准确性和自然性。还可以将 Embedding提前索引好存起来，以此做到让AI根据外部知识来回答问题，"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230602165232.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230602165359.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230602165505.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230602173646.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230602163412.png?imgNote"><meta property="article:published_time" content="2023-06-02T09:14:18.000Z"><meta property="article:modified_time" content="2023-06-10T14:17:27.850Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://qiniu.hivan.me/picGo/20230602165232.png?imgNote"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/"},"headline":"14. 使用链式调用简化多步提示语","image":[],"datePublished":"2023-06-02T09:14:18.000Z","dateModified":"2023-06-10T14:17:27.850Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Hi, 大家好，我是茶桁。 OpenAI 的大语言模型提供了 Completion 和 Embedding 两个核心接口。 我们可以通过增加提示语（Prompt）历史记录来提高模型的回答准确性和自然性。还可以将 Embedding提前索引好存起来，以此做到让AI根据外部知识来回答问题，"}</script><link rel="canonical" href="https://hivan.me/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-06-02T09:14:18.000Z" title="6/2/2023, 5:14:18 PM">2023-06-02</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></span></div></div><h1 class="title is-3 is-size-4-mobile">14. 使用链式调用简化多步提示语</h1><div class="content"><p>Hi, 大家好，我是茶桁。</p>
<p>OpenAI 的大语言模型提供了 Completion 和 Embedding 两个核心接口。</p>
<p>我们可以通过增加提示语（Prompt）历史记录来提高模型的回答准确性和自然性。还可以将 Embedding提前索引好存起来，以此做到让AI根据外部知识来回答问题，</p>
<span id="more"></span>
<p>在我们多次与AI对话的过程中，讲AI返回的答案放在新的问题里，那么我们就可以让AI帮主我们给自己的代码撰写单元测试了。</p>
<p>以上这些方法是自然语言类应用中常见的模式。为了方便应用开发者使用这些模式，开源社区开发了名为 Langchain 的开源库，使用 Langchain，我们可以更加快速地实现之前利用大语言模型实现过的功能，并且可以更好地将模型集成到我们的业务系统中，实现更加复杂、有价值的功能。</p>
<h2 id="何谓链式调用">何谓链式调用</h2>
<p>在<a href="../Save-costs-with-an-open-source-model">第 11 讲</a>中，我们学习了 llama-index 的使用，并在此过程中已经安装了 Langchain。虽然 Langchain 也有类似 llama-index 的功能，但这不是 Langchain 的主要卖点。Langchain 带来的第一个主要优势就在于它的名字，也就是链式调用。</p>
<p>链式调用是指在程序中可以使用点 <code>.</code> 来连接对象，然后在这些对象上调用方法，以此来实现更加复杂的操作。在使用 ChatGPT 的过程中，我们经常会遇到中文语料较少的问题，以至于它不能很好地回答问题。为了解决这个问题，我们可以采取以下措施。</p>
<p>我们可以把中文问题交给 AI，让它翻译成英文，然后把英文问题贴进去提问，得到一个英文答案。最后，再请 AI 把英文答案翻译回中文。通过这种方式，我们可以得到更加准确的答案。</p>
<blockquote>
<p>可能部分读者会觉得这样做有些脱裤子放屁多此一举，但是其实你真的完全用英文来完成你的问题和获取答案，你就能很明显的感觉到差别。这个问题曾经有一个业内人士延展的谈到过，其实这是一个很严重的问题，也是我们这几十年来的互联网环境造成了今天的局面，而再这样下去，中文的AI环境就此完蛋，我们也可能再也追不上国外的脚步。当然，到底是否危言耸听仁者见仁智者见智，每个人有自己的看法，可是从我自己使用之后和对于一些原理的理解来看，这真的不是危言耸听。理解大语言模型原理的人应该都能懂。好了，我把视频链接放在这，有兴趣的自己去看看吧，一段7分钟的视频：<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Nm4y1z7AT/">中文互联网的凋零，正在杀死中国人工智能的未来【为什么我们搞不出ChatGPT】</a></p>
</blockquote>
<p>我们还可以通过增加数据样本的方式来扩展 ChatGPT 的知识库，让其可以更好地回答问题。除此之外，我们还可以通过使用更加复杂的算法和技术来提高 ChatGPT 的回答质量，例如使用迁移学习等技术。</p>
<p>例如，下面的截图里，我请 ChatGPT 简单介绍一下 Stable Diffusion 的原理。通过 Langchain 的链式调用，我们可以更方便地使用 ChatGPT 来解决各种问题。</p>
<p>Langchain 带来的链式调用优势可以让我们更加灵活地使用 ChatGPT，同时也可以帮助我们解决中文语料较少的问题。通过不断地扩展 ChatGPT 的知识库和使用更加先进的技术，我们相信 ChatGPT 可以成为一个更加强大的工具，帮助我们解决各种问题。</p>
<blockquote>
<p>Stable Diffusion 是一个非常热门的开源 AI 画图工具，我们在最开始的导读课程中有过一些贴图。除此之外，我以前也写过专门介绍的文章：<a href="../How-to-install-and-run-Stable-Diffusion-on-Apple-Silicon">在 Apple Silicon M1/M2 Mac 上安装和运行Stable Diffusion</a></p>
</blockquote>
<p>一般来说，如果我们人工询问ChatGPT，应该是这样的步骤, 我将其称之为“<strong>人工链式调用</strong>”：</p>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230602165232.png?imgNote" alt="image-20230602165232370" /><figcaption aria-hidden="true">image-20230602165232370</figcaption>
</figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230602165359.png?imgNote" alt="image-20230602165359092" /><figcaption aria-hidden="true">image-20230602165359092</figcaption>
</figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230602165505.png?imgNote" alt="image-20230602165505848" /><figcaption aria-hidden="true">image-20230602165505848</figcaption>
</figure>
<p>可以从截图中看到，我们一共经历了三步：</p>
<ol type="1">
<li>把我们的问题翻译成了英文</li>
<li>用翻译好的英文向ChatGPT提问</li>
<li>最后将ChatGPT的回答再翻译回中文</li>
</ol>
<p>那如果我们用API来实现这整个过程，其实就是一个链式调用的过程。</p>
<h2 id="使用llmchain进行链式调用">使用LLMChain进行链式调用</h2>
<p>我们可以使用 OpenAI 进行翻译请求和原始问题的组合，并将其发送给 AI，以完成问题的中译英转换，从而获得翻译好的英文问题。</p>
<p>接下来，我们可以将翻译好的英文问题发送回 OpenAI，以获得英文答案。</p>
<p>最后，我们可以将英文答案与要求 AI 翻译答案的请求组合在一起，以完成答案的英译中转换。</p>
<p>如果我们使用 LLMChain 进行链式调用，我们可以在代码中逐步进行如下操作：</p>
<ol type="1">
<li>发送翻译请求和原始问题给 OpenAI 进行中译英转换。</li>
<li>得到翻译好的英文问题。</li>
<li>发送翻译好的英文问题给 OpenAI 进行英文答案的获取。</li>
<li>得到英文答案。</li>
<li>将英文答案与要求 AI 翻译答案的请求组合在一起，完成答案的英译中转换。</li>
</ol>
<p>通过以上操作，我们可以获得更加准确和完整的翻译结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai, os</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = <span class="string">&#x27;OPENAI_API_KEY&#x27;</span></span><br><span class="line">openai.api_key = <span class="string">&quot;OPENAI_API_KEY&quot;</span></span><br><span class="line"></span><br><span class="line">llm = OpenAI(model_name = <span class="string">&quot;text-davinci-003&quot;</span>,  temperature = <span class="number">0.5</span>, max_tokens=<span class="number">2048</span>)</span><br><span class="line"></span><br><span class="line">en_to_zh_prompt = PromptTemplate(</span><br><span class="line">    template = <span class="string">&quot;请把下面这句话翻译成英文： \n\n &#123;question&#125;?&quot;</span>, input_variables = [<span class="string">&#x27;question&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">question_prompt = PromptTemplate(</span><br><span class="line">    template = <span class="string">&quot;&#123;english_question&#125;&quot;</span>, input_variables=[<span class="string">&#x27;english_question&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">zh_to_cn_prompt = PromptTemplate(</span><br><span class="line">    input_variables = [<span class="string">&#x27;english_answer&#x27;</span>],</span><br><span class="line">    template = <span class="string">&#x27;请把下面这一段翻译成中文: \n\n &#123;english_answer&#125;?&#x27;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">question_translate_chain = LLMChain(llm = llm, prompt = en_to_zh_prompt, output_key = <span class="string">&#x27;english_question&#x27;</span>)</span><br><span class="line">english = question_translate_chain.run(question = <span class="string">&#x27;请你作为一个机器学习的专家，介绍一下CNN的原理&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(english)</span><br></pre></td></tr></table></figure>
<p>得到英文翻译结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Please <span class="keyword">as</span> an expert <span class="keyword">in</span> Machine Learning, introduce the principle of CNN?</span><br></pre></td></tr></table></figure>
<p>让我们接着上面的代码继续：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">qa_chain = LLMChain(llm = llm, prompt = question_prompt, output_key = <span class="string">&#x27;english_answer&#x27;</span>)</span><br><span class="line">english_answer = qa_chain.run(english_question = english)</span><br><span class="line"><span class="built_in">print</span>(english_answer)</span><br></pre></td></tr></table></figure>
<p>得到英文回答：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Convolutional Neural Networks (CNNs) are a <span class="built_in">type</span> of deep learning neural network architecture that are particularly well suited <span class="keyword">for</span> processing <span class="keyword">and</span> analyzing data that has a spatial <span class="keyword">or</span> temporal component. The main principle of CNNs <span class="keyword">is</span> to learn features <span class="keyword">from</span> the data <span class="keyword">in</span> a hierarchical manner, starting <span class="keyword">from</span> basic features at the lower layers <span class="keyword">and</span> gradually increasing the complexity of the features at the higher layers. The main components of a CNN include convolutional layers, pooling layers, <span class="keyword">and</span> fully connected layers. The convolutional layers are used to extract features <span class="keyword">from</span> the <span class="built_in">input</span> data, <span class="keyword">while</span> the pooling layers are used to reduce the size of the <span class="built_in">input</span> data <span class="keyword">and</span> the fully connected layers are used to make predictions based on the extracted features.</span><br></pre></td></tr></table></figure>
<p>继续：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">answer_translate_chain = LLMChain(llm = llm, prompt = zh_to_cn_prompt)</span><br><span class="line">answer = answer_translate_chain.run(english_answer = english_answer)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>得到最终结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">卷积神经网络（CNN）是一种深度学习神经网络架构，特别适合处理和分析具有空间或时间成分的数据。CNN的主要原理是以分层的方式从数据中学习特征，从低层开始从基本特征，并逐渐增加高层的特征复杂性。CNN的主要组成部分包括卷积层、池化层和全连接层。卷积层用于从输入数据中提取特征，而池化层用于减小输入数据的大小，全连接层用于根据提取的特征进行预测。</span><br></pre></td></tr></table></figure>
<p>在这段代码中，我们使用了 Langchain 库，但是我们可以加入一些新的内容来扩展它，以便更好地满足我们的需求。我们主要使用了 Langchain 的三个包来扩展它。LLM、PromptTemplate 和 LLMChain。</p>
<p>首先，我们使用 LLM 包来回答我们提出的问题。在这里，我们使用的是 OpenAIChat。OpenAIChat 是一个最新的 gpt-3.5-turbo 模型，可以帮助我们用最好的方式回答我们的问题。</p>
<p>然后是 PromptTemplate，这个包和在第 11 讲中看到的 llama-index 的 PromptTemplate 相似。它可以定义一个提示语模板，里面可以定义一些可以动态替换的变量。例如，在代码中的 question_prompt 模板中，我们定义了一个名为 question 的变量，因为我们每次提出的问题都不一样。事实上，llama-index 中的 PromptTemplate 就是对 Langchain 的 PromptTemplate 做了一层简单的封装。</p>
<p>接下来是 LLMChain，主角。它的构造函数接收一个 LLM 和一个 PromptTemplate 作为参数。构造完成之后，可以直接调用里面的 run 方法，将 PromptTemplate 需要的变量，用 K=&gt;V 对的形式传入进去。返回的结果，就是 LLM 给我们的答案。</p>
<p>但是，现在我们似乎只是对 OpenAI 的 API 做了一层封装。我们构建了 3 个 LLMChain，然后按照顺序调用，每次拿到答案之后，再作为输入，交给下一个 LLM 调用。感觉好像更麻烦了，没有减少什么工作量呀？</p>
<p>不要着急，我们还没有真正使用 LLMChain 的“链式调用”功能。只需要加上一行小小的代码即可。我们使用一个名为 SimpleSequentialChain 的 LLMChain 类，将我们要按顺序依次调用的三个 LLMChain 放在一个数组中，将该数组传递给该类的构造函数。</p>
<p>然后，我们调用该对象的 run 方法，将我们用中文提出的问题交给它。此时，该 SimpleSequentialChain 会按照顺序开始调用数组参数 chains 中包含的其他 LLMChain。每次调用的结果都会存储在 Chain 构造时定义的 output_key 参数中。如果下一个调用的 LLMChain 中的模板内的变量与之前的 output_key 名称相同，则会用 output_key 中存储的内容替换模板内变量所在的占位符。</p>
<p>这样，我们只需要向该 SimpleSequentialChain 调用一次 run 方法，将一开始的问题交给它即可。后续根据答案去问新的问题，该 LLMChain 会自动链式搞定。我在这里将日志的 Verbose 模式打开，你在输出的过程中，可以看到该 LLMChain 调用了三次，并且可以一并看到中间两次的返回结果。这就是我们如何更好地使用 Langchain 库来满足我们的需求，同时保留原有的关键思想。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SimpleSequentialChain</span><br><span class="line"></span><br><span class="line">chinese_qa_chain = SimpleSequentialChain(</span><br><span class="line">    chains = [question_translate_chain, qa_chain, answer_translate_chain], input_key = <span class="string">&#x27;question&#x27;</span>,</span><br><span class="line">    verbose = <span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">answer = chinese_qa_chain.run(question = <span class="string">&#x27;请你作为一个机器学习的专家，介绍一下CNN的原理。&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>然后我们可以看到Verbose的日志信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new SimpleSequentialChain chain...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Please introduce the principle of CNN <span class="keyword">as</span> an expert of machine learning.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Convolutional Neural Networks (CNNs) are a <span class="built_in">type</span> of deep learning neural network used <span class="keyword">for</span> image recognition <span class="keyword">and</span> classification. They are composed of multiple layers of neurons, each layer performing a specific task. The neurons are organized <span class="keyword">in</span> a hierarchical manner, <span class="keyword">with</span> each layer taking the output <span class="keyword">from</span> the previous layer <span class="keyword">as</span> its <span class="built_in">input</span>. The first layer of neurons <span class="keyword">is</span> usually a convolutional layer that performs convolution operations on the <span class="built_in">input</span> image, extracting features <span class="keyword">from</span> it. The subsequent layers are fully connected layers that use the extracted features to classify the image. The final layer produces the output, which <span class="keyword">is</span> usually a probability distribution over the categories of the image. CNNs are powerful tools <span class="keyword">for</span> image classification, <span class="keyword">and</span> have achieved state-of-the-art results on a variety of tasks.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">卷积神经网络（CNN）是一种深度学习神经网络，用于图像识别和分类。它由多层神经元组成，每层执行特定任务。神经元以分层的方式组织，每层以上一层的输出作为输入。第一层神经元通常是卷积层，对输入图像执行卷积操作，从中提取特征。随后的层是完全连接的图层，它们使用提取的要素对影像进行分类。最后一层产生输出，这通常是图像类别的概率分布。CNN是图像分类的强大工具，并且在各种任务上都取得了最先进的结果。</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br></pre></td></tr></table></figure>
<p>当然，还得到我们的最终结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">卷积神经网络（CNN）是一种深度学习神经网络，用于图像识别和分类。它由多层神经元组成，每层执行特定任务。神经元以分层的方式组织，每层以上一层的输出作为输入。第一层神经元通常是卷积层，对输入图像执行卷积操作，从中提取特征。随后的层是完全连接的图层，它们使用提取的要素对影像进行分类。最后一层产生输出，这通常是图像类别的概率分布。CNN是图像分类的强大工具，并且在各种任务上都取得了最先进的结果。</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230602173646.png?imgNote" alt="image-20230602173646472" /><figcaption aria-hidden="true">image-20230602173646472</figcaption>
</figure>
<p>在使用链式调用时，需要注意，在一个 LLMChain 中使用 PromptTemplate 时，输入参数必须先在 LLMChain 中通过 output_key 定义，否则该变量将无值，从而导致程序报错。此外，在一些情况下，您可能需要使用 try-except 语句来处理可能出现的错误，以确保代码的稳定性。另外，建议您在代码中添加注释，以便更好地理解程序的执行流程和实现细节。</p>
<h2 id="输入多个变量">输入多个变量</h2>
<p>实际上，由于输入输出使用的是变量，这些变量是由这些参数所定义的。因此，我们不仅可以使用前一个LLMChain的输出作为后一个LLMChain的输入，还可以连续提出多个问题，并将这些问题的答案作为后续问题的输入来继续处理。这样，我们可以进一步扩展我们的模型，提取更多的信息以及更准确的答案。这个过程有点类似于人类的思考过程，因为在人类的思维中，一个问题的答案通常会引发更多的问题。</p>
<p>例如，我们可以提出这样的问题：“在中国，哪个城市是最大的城市？”然后，我们可以使用一个自然语言处理模型来回答这个问题，比如说，我们可以使用一个LLMChain模型。第一个LLMChain模型将输入中的问题转化为向量，然后将这个向量传递给下一个模型。第二个LLMChain模型将这个向量处理成一个问题的答案，然后将这个答案作为下一个问题的输入。这样，我们就可以连续提出多个问题，并将这些问题的答案作为后续问题的输入来继续处理。比如说，我们可以接下来问：“这个城市的人口是多少？”然后，我们可以再次使用LLMChain模型来回答这个问题。通过这种方式，我们可以更详细地了解一个城市的信息，同时也可以更好地理解LLMChain模型的工作原理。</p>
<p>下面我就给你看一个例子，让你更好的理解这个概念。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SequentialChain</span><br><span class="line"></span><br><span class="line">q1_prompt = PromptTemplate(</span><br><span class="line">    input_variables = [<span class="string">&#x27;year1&#x27;</span>],</span><br><span class="line">    template = <span class="string">&#x27;&#123;year1&#125;年的欧冠联赛的冠军是哪支球队，只说球队名称。&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">q2_prompt = PromptTemplate(</span><br><span class="line">    input_variables = [<span class="string">&#x27;year2&#x27;</span>],</span><br><span class="line">    template = <span class="string">&#x27;&#123;year2&#125;年的欧冠联赛的冠军是哪支球队，只说球队名称。&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">q3_prompt = PromptTemplate(</span><br><span class="line">    input_variables = [<span class="string">&#x27;team1&#x27;</span>, <span class="string">&#x27;team2&#x27;</span>],</span><br><span class="line">    template = <span class="string">&#x27;&#123;team1&#125;和&#123;team2&#125;哪只球队获得欧冠的次数多一些？&#x27;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain1 = LLMChain(llm = llm, prompt = q1_prompt, output_key = <span class="string">&#x27;team1&#x27;</span>)</span><br><span class="line">chain2 = LLMChain(llm = llm, prompt = q2_prompt, output_key = <span class="string">&#x27;team2&#x27;</span>)</span><br><span class="line">chain3 = LLMChain(llm = llm, prompt = q3_prompt)</span><br><span class="line"></span><br><span class="line">sequential_chain = SequentialChain(chains = [chain1, chain2, chain3], input_variables = [<span class="string">&#x27;year1&#x27;</span>, <span class="string">&#x27;year2&#x27;</span>], verbose = <span class="literal">True</span>)</span><br><span class="line">answer = sequential_chain.run(year1 = <span class="number">2000</span>, year2 = <span class="number">2010</span>)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>然后我们得到日志和结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new SequentialChain chain...</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">皇家马德里获得欧冠的次数多一些，共计<span class="number">13</span>次，而拜仁慕尼黑只有<span class="number">5</span>次。</span><br></pre></td></tr></table></figure>
<blockquote>
<p>有的时候需要注意，ChatGPT可能会一本正经的胡说八道。在得到结果的时候最好验证一下，比如这个问题下，ChatGPT最初告诉我的拜仁多一些，共计8次，而皇家马德里只有3次。虽然我不知道具体次数，但是我也知道皇马是欧冠之王，明显答案就不对。所以又重新生成并验证了一次。</p>
</blockquote>
<p>在这个例子里，我们定义了两个 PromptTemplate 和对应的 LLMChain。PromptTemplate 的作用是接收一个年份作为输入，回答这个年份的欧冠冠军。我们使用两个不同的 LLMChain 分别处理这两个 PromptTemplate，从而得到两支不同年份的欧冠冠军。接下来，我们将这两个队名作为输入，放到第三个问题里。这个问题会让 AI 告诉我们这两支球队哪一支获得欧冠的次数多一些。我们可以使用另一个 LLMChain 来处理这个问题，然后将其添加到我们的 SequentialChain 中。这样，我们只需要输入两个年份，就能通过三次回答得到答案。在这个过程中，我们可以使用不同的技术和算法来优化我们的模型，以获得更加准确和快速的结果。</p>
<h2 id="使用-langchain-实现自动化撰写单元测试">使用 Langchain 实现自动化撰写单元测试</h2>
<p>看到这里，让我们更深入地探讨一下通过多步提示语自动给代码写单元测试的方法。在<a href="../Use-multi-step-prompts-to-ask-AI-to-write-tests-for-you">上一讲</a>中，我们介绍了 Langchain，它可以顺序地通过多个 Prompt 调用 OpenAI 的 GPT 模型来实现这个功能。这种方法非常适合自动化测试，因为它可以帮助我们节省大量的时间和精力。</p>
<p>但是，你可能会问，如果 AST 语法解析失败怎么办？不用担心，因为现在的 Langchain 已经具备了自动重试的能力，可以轻松解决这个问题。所以，现在我们可以更加放心地使用 Langchain 进行自动化测试，从而提高我们的工作效率。</p>
<p>总之，通过多步提示语自动给代码写单元测试是一种非常实用的方法，而 Langchain 则是实现这种方法的最佳选择。希望这篇文章能够帮助大家更好地了解 Langchain 的功能和优势。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> SequentialChain</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_unit_test</span>(<span class="params">function_to_test, unit_test_package=<span class="string">&quot;pytest&quot;</span></span>):</span><br><span class="line">    <span class="comment"># 解释源代码的步骤</span></span><br><span class="line">    explain_code = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    # How to write great unit tests with &#123;unit_test_package&#125;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    In this advanced tutorial for experts, we&#x27;ll use Python 3.10 and `&#123;unit_test_package&#125;` to write a suite of unit tests to verify the behavior of the following function.</span></span><br><span class="line"><span class="string">    ```python</span></span><br><span class="line"><span class="string">    &#123;function_to_test&#125;</span></span><br><span class="line"><span class="string">    \```</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Before writing any unit tests, let&#x27;s review what each element of the function is doing exactly and what the author&#x27;s intentions may have been.</span></span><br><span class="line"><span class="string">    - First,</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    explain_code_template = PromptTemplate(</span><br><span class="line">        input_variables=[<span class="string">&quot;unit_test_package&quot;</span>, <span class="string">&quot;function_to_test&quot;</span>],</span><br><span class="line">        template=explain_code</span><br><span class="line">    )</span><br><span class="line">    explain_code_llm = OpenAI(model_name=<span class="string">&quot;text-davinci-002&quot;</span>, temperature=<span class="number">0.4</span>, max_tokens=<span class="number">1000</span>, model_kwargs=&#123;<span class="string">&quot;stop&quot;</span>: [<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n\t\n&quot;</span>, <span class="string">&quot;\n    \n&quot;</span>]&#125;)</span><br><span class="line">    explain_code_step = LLMChain(llm=explain_code_llm, prompt=explain_code_template, output_key=<span class="string">&quot;code_explanation&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建测试计划示例的步骤</span></span><br><span class="line">    test_plan = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A good unit test suite should aim to:</span></span><br><span class="line"><span class="string">    - Test the function&#x27;s behavior for a wide range of possible inputs</span></span><br><span class="line"><span class="string">    - Test edge cases that the author may not have foreseen</span></span><br><span class="line"><span class="string">    - Take advantage of the features of `&#123;unit_test_package&#125;` to make the tests easy to write and maintain</span></span><br><span class="line"><span class="string">    - Be easy to read and understand, with clean code and descriptive names</span></span><br><span class="line"><span class="string">    - Be deterministic, so that the tests always pass or fail in the same way</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    `&#123;unit_test_package&#125;` has many convenient features that make it easy to write and maintain unit tests. We&#x27;ll use them to write unit tests for the function above.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    For this particular function, we&#x27;ll want our unit tests to handle the following diverse scenarios (and under each scenario, we include a few examples as sub-bullets):</span></span><br><span class="line"><span class="string">    -</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    test_plan_template = PromptTemplate(</span><br><span class="line">        input_variables=[<span class="string">&quot;unit_test_package&quot;</span>, <span class="string">&quot;function_to_test&quot;</span>, <span class="string">&quot;code_explanation&quot;</span>],</span><br><span class="line">        template=explain_code + <span class="string">&quot;&#123;code_explanation&#125;&quot;</span> + test_plan</span><br><span class="line">    )</span><br><span class="line">    test_plan_llm = OpenAI(model_name=<span class="string">&quot;text-davinci-002&quot;</span>, temperature=<span class="number">0.4</span>, max_tokens=<span class="number">1000</span>, model_kwargs=&#123;<span class="string">&quot;stop&quot;</span>: [<span class="string">&quot;\n\n&quot;</span>, <span class="string">&quot;\n\t\n&quot;</span>, <span class="string">&quot;\n    \n&quot;</span>]&#125;)</span><br><span class="line">    test_plan_step = LLMChain(llm=test_plan_llm, prompt=test_plan_template, output_key=<span class="string">&quot;test_plan&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 撰写测试代码的步骤</span></span><br><span class="line">    starter_comment = <span class="string">&quot;Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator&quot;</span></span><br><span class="line">    prompt_to_generate_the_unit_test = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">		Before going into the individual tests, let&#x27;s first look at the complete suite of unit tests as a cohesive whole. We&#x27;ve added helpful comments to explain what each line does.</span></span><br><span class="line"><span class="string">		```python</span></span><br><span class="line"><span class="string">		import &#123;unit_test_package&#125;  # used for our unit tests</span></span><br><span class="line"><span class="string">		&#123;function_to_test&#125;</span></span><br><span class="line"><span class="string">		#&#123;starter_comment&#125;</span></span><br><span class="line"><span class="string">		&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    unit_test_template = PromptTemplate(</span><br><span class="line">        input_variables=[<span class="string">&quot;unit_test_package&quot;</span>, <span class="string">&quot;function_to_test&quot;</span>, <span class="string">&quot;code_explanation&quot;</span>, <span class="string">&quot;test_plan&quot;</span>, <span class="string">&quot;starter_comment&quot;</span>],</span><br><span class="line">        template=explain_code + <span class="string">&quot;&#123;code_explanation&#125;&quot;</span> + test_plan + <span class="string">&quot;&#123;test_plan&#125;&quot;</span> + prompt_to_generate_the_unit_test</span><br><span class="line">    )</span><br><span class="line">    unit_test_llm = OpenAI(model_name=<span class="string">&quot;text-davinci-002&quot;</span>, temperature=<span class="number">0.4</span>, max_tokens=<span class="number">1000</span>, model_kwargs=&#123;<span class="string">&quot;stop&quot;</span>: <span class="string">&quot;```&quot;</span>&#125;)</span><br><span class="line">    unit_test_step = LLMChain(llm=unit_test_llm, prompt=unit_test_template, output_key=<span class="string">&quot;unit_test&quot;</span>)</span><br><span class="line"></span><br><span class="line">    sequential_chain = SequentialChain(chains=[explain_code_step, test_plan_step, unit_test_step],</span><br><span class="line">                                       input_variables=[<span class="string">&quot;unit_test_package&quot;</span>, <span class="string">&quot;function_to_test&quot;</span>, <span class="string">&quot;starter_comment&quot;</span>],</span><br><span class="line">                                       verbose=<span class="literal">True</span>)</span><br><span class="line">    answer = sequential_chain.run(unit_test_package=unit_test_package, function_to_test=function_to_test,</span><br><span class="line">                                  starter_comment=starter_comment)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;&quot;&quot;#<span class="subst">&#123;starter_comment&#125;</span>&quot;&quot;&quot;</span> + answer</span><br><span class="line">  </span><br><span class="line">code = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">def format_time(seconds):</span></span><br><span class="line"><span class="string">    minutes, seconds = divmod(seconds, 60)</span></span><br><span class="line"><span class="string">    hours, minutes = divmod(minutes, 60)</span></span><br><span class="line"><span class="string">    if hours &gt; 0:</span></span><br><span class="line"><span class="string">        return f&quot;&#123;hours&#125;h&#123;minutes&#125;min&#123;seconds&#125;s&quot;</span></span><br><span class="line"><span class="string">    elif minutes &gt; 0:</span></span><br><span class="line"><span class="string">        return f&quot;&#123;minutes&#125;min&#123;seconds&#125;s&quot;</span></span><br><span class="line"><span class="string">    else:</span></span><br><span class="line"><span class="string">        return f&quot;&#123;seconds&#125;s&quot;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> ast</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">write_unit_test_automatically</span>(<span class="params">code, retry=<span class="number">3</span></span>):</span><br><span class="line">    unit_test_code = write_unit_test(code)</span><br><span class="line">    all_code = code + unit_test_code</span><br><span class="line">    tried = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> tried &lt; retry:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            ast.parse(all_code)</span><br><span class="line">            <span class="keyword">return</span> all_code</span><br><span class="line">        <span class="keyword">except</span> SyntaxError <span class="keyword">as</span> e:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Syntax error in generated code: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">            all_code = code + write_unit_test(code)</span><br><span class="line">            tried += <span class="number">1</span></span><br><span class="line">            </span><br><span class="line"><span class="built_in">print</span>(write_unit_test_automatically(code))</span><br></pre></td></tr></table></figure>
<p>然后我们得到结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">[1m&gt; Entering new SequentialChain chain...[0m</span><br><span class="line"></span><br><span class="line">[1m&gt; Finished chain.[0m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下部分是返回的程序                   </span></span><br><span class="line">                       </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">format_time</span>(<span class="params">seconds</span>):</span><br><span class="line">    minutes, seconds = <span class="built_in">divmod</span>(seconds, <span class="number">60</span>)</span><br><span class="line">    hours, minutes = <span class="built_in">divmod</span>(minutes, <span class="number">60</span>)</span><br><span class="line">    <span class="keyword">if</span> hours &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;hours&#125;</span>h<span class="subst">&#123;minutes&#125;</span>min<span class="subst">&#123;seconds&#125;</span>s&quot;</span></span><br><span class="line">    <span class="keyword">elif</span> minutes &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;minutes&#125;</span>min<span class="subst">&#123;seconds&#125;</span>s&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;seconds&#125;</span>s&quot;</span></span><br><span class="line"><span class="comment">#Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator.</span></span><br><span class="line"><span class="comment">#The first element of each tuple is the name of the test case, and the second element is a list of tuples.</span></span><br><span class="line"><span class="comment">#Each tuple in the list of tuples is a set of input values and expected output values for that test case.</span></span><br><span class="line"><span class="meta">@pytest.mark.parametrize(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="meta">    <span class="string">&quot;test_case, input_values, expected_output&quot;</span>,</span></span></span><br><span class="line"><span class="params"><span class="meta">    [</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for positive integers</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_int&quot;</span>, [<span class="number">1</span>], <span class="string">&quot;1s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_int&quot;</span>, [<span class="number">60</span>], <span class="string">&quot;1min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_int&quot;</span>, [<span class="number">3600</span>], <span class="string">&quot;1h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_int&quot;</span>, [<span class="number">3601</span>], <span class="string">&quot;1h1s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for negative integers</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_int&quot;</span>, [-<span class="number">1</span>], <span class="string">&quot;-1s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_int&quot;</span>, [-<span class="number">60</span>], <span class="string">&quot;-1min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_int&quot;</span>, [-<span class="number">3600</span>], <span class="string">&quot;-1h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_int&quot;</span>, [-<span class="number">3601</span>], <span class="string">&quot;-1h1s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test case for zero</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;zero&quot;</span>, [<span class="number">0</span>], <span class="string">&quot;0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for positive floats</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_float&quot;</span>, [<span class="number">1.0</span>], <span class="string">&quot;1.0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_float&quot;</span>, [<span class="number">60.0</span>], <span class="string">&quot;1.0min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_float&quot;</span>, [<span class="number">3600.0</span>], <span class="string">&quot;1.0h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;positive_float&quot;</span>, [<span class="number">3601.0</span>], <span class="string">&quot;1.0h1.0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for negative floats</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_float&quot;</span>, [-<span class="number">1.0</span>], <span class="string">&quot;-1.0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_float&quot;</span>, [-<span class="number">60.0</span>], <span class="string">&quot;-1.0min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_float&quot;</span>, [-<span class="number">3600.0</span>], <span class="string">&quot;-1.0h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;negative_float&quot;</span>, [-<span class="number">3601.0</span>], <span class="string">&quot;-1.0h1.0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for strings that can be parsed as integers</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_int&quot;</span>, [<span class="string">&quot;1&quot;</span>], <span class="string">&quot;1s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_int&quot;</span>, [<span class="string">&quot;60&quot;</span>], <span class="string">&quot;1min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_int&quot;</span>, [<span class="string">&quot;3600&quot;</span>], <span class="string">&quot;1h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_int&quot;</span>, [<span class="string">&quot;3601&quot;</span>], <span class="string">&quot;1h1s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for strings that can be parsed as floats</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_float&quot;</span>, [<span class="string">&quot;1.0&quot;</span>], <span class="string">&quot;1.0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_float&quot;</span>, [<span class="string">&quot;60.0&quot;</span>], <span class="string">&quot;1.0min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_float&quot;</span>, [<span class="string">&quot;3600.0&quot;</span>], <span class="string">&quot;1.0h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_float&quot;</span>, [<span class="string">&quot;3601.0&quot;</span>], <span class="string">&quot;1.0h1.0s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        <span class="comment"># Test cases for strings that cannot be parsed as integers or floats</span></span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_other&quot;</span>, [<span class="string">&quot;abc&quot;</span>], <span class="string">&quot;abc&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_other&quot;</span>, [<span class="string">&quot;1.0.0&quot;</span>], <span class="string">&quot;1.0.0&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_other&quot;</span>, [<span class="string">&quot;60s&quot;</span>], <span class="string">&quot;60s&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_other&quot;</span>, [<span class="string">&quot;3600min&quot;</span>], <span class="string">&quot;3600min&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">        (<span class="params"><span class="string">&quot;string_other&quot;</span>, [<span class="string">&quot;3601h&quot;</span>], <span class="string">&quot;3601h&quot;</span></span>),</span></span></span><br><span class="line"><span class="params"><span class="meta">    ],</span></span></span><br><span class="line"><span class="params"><span class="meta"></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_format_time</span>(<span class="params">test_case, input_values, expected_output</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Unit test for the format_time function.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># The input to the function is a list, so we need to unpack it before passing it to the function.</span></span><br><span class="line">    input_value, = input_values</span><br><span class="line">    output = format_time(input_value)</span><br><span class="line">    <span class="keyword">assert</span> output == expected_output</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这个代码的具体功能与<a href="../Use-multi-step-prompts-to-ask-AI-to-write-tests-for-you">上一讲</a>相同，只是我们通过 Langchain 对其进行了封装，以便更容易维护。我们使用三个 LLMChain 来解释代码、生成测试计划和最终生成测试代码。每一步的输入都是上一步的输出，其中包括上一步的 Prompt Template 和这一步 Prompt Template 的组合，以及一些变量，这些变量是上一步执行的结果作为输入变量传递而来的。最终，我们可以使用 SequentialChain 自动按照这三个步骤执行 OpenAI 的 API 调用。</p>
<p>我们使用 write_unit_test 函数来封装整个过程。对于重试，我们使用 while 循环来调用 write_unit_test。得到的结果和输入的代码拼接在一起，然后交给 AST 库进行解析。如果解析未通过，则重试整个单元测试生成的过程，直到达到我们最大的重试次数为止。</p>
<p>LangChain 的链式调用方式有助于我们通过 AI 完成更复杂的任务，并将整个任务的完成过程定义为一个固定的流程模板。在下一讲中，我们将进一步探讨如何通过链式组合多个 LLMChain 的方法来完成更复杂且更实际的工作。</p>
<h2 id="小结"><strong>小结</strong></h2>
<p>相信到这里，你已经有了更多可以利用大语言模型的好点子。在本讲中，我向您介绍了如何使用 Langchain 这个开源库，对大语言模型进行链式调用。要使用大语言模型完成复杂任务往往需要我们多次向 AI 提问，而前面问题的答案可能是后面问题输入的一部分。LangChain 通过将多个 LLMChain 组合成一个 SequentialChain 并顺序执行，大大简化了这类任务的开发工作。</p>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230602163412.png?imgNote" alt="SequentialChain" /><figcaption aria-hidden="true">SequentialChain</figcaption>
</figure>
<p>LLMChain 是一种链式调用大型语言模型的模式，可以将前面的变量和输出作为下一轮调用的变量输入。但是，这只是 Langchain 的一小部分功能。除了调用语言模型，我们还可以调用外部系统，甚至可以让 AI 做决策，决定我们的系统该做什么。在接下来的几节课中，我们将介绍更多关于 Langchain 的强大功能，并最终提供一个完整的电子商务聊天机器人。</p>
<p>留下一个<strong>思考题</strong>给你：你能够通过 Langchain 结合多个问题，并利用先前问题的答案结果来触发新的问题，从而找到你所需的答案吗？欢迎在评论区分享你的例子，并将这一节课与需要它的朋友分享。我们在下一节课再见。</p>
<p><strong>推荐阅读：</strong>就像之前介绍的 llama-index 项目一样，Langchain 项目也正在快速发展和迭代。我建议你去看看他们的<a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/">官方文档</a>，以了解他们提供的最新功能。此外，之前我们提到过的向量数据库公司 Pinecone，也制作了一份 <a target="_blank" rel="noopener" href="https://www.pinecone.io/learn/langchain/">Langchain AI 手册</a>，你也可以去看一看。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>14. 使用链式调用简化多步提示语</p><p><a href="https://hivan.me/使用链式调用简化多步提示语/">https://hivan.me/使用链式调用简化多步提示语/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-06-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-10</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">15. 使用LLMChain连接Google和计算器</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Use-AI-to-write-a-snake-game/"><span class="level-item">利用AI写一个『贪吃蛇游戏』</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/';
            this.page.identifier = '使用链式调用简化多步提示语/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">154</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">2</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">20</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#何谓链式调用"><span class="level-left"><span class="level-item">1</span><span class="level-item">何谓链式调用</span></span></a></li><li><a class="level is-mobile" href="#使用llmchain进行链式调用"><span class="level-left"><span class="level-item">2</span><span class="level-item">使用LLMChain进行链式调用</span></span></a></li><li><a class="level is-mobile" href="#输入多个变量"><span class="level-left"><span class="level-item">3</span><span class="level-item">输入多个变量</span></span></a></li><li><a class="level is-mobile" href="#使用-langchain-实现自动化撰写单元测试"><span class="level-left"><span class="level-item">4</span><span class="level-item">使用 Langchain 实现自动化撰写单元测试</span></span></a></li><li><a class="level is-mobile" href="#小结"><span class="level-left"><span class="level-item">5</span><span class="level-item">小结</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/"><span class="level-start"><span class="level-item">AI秘籍</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T06:13:06.000Z">2023-07-27</time></p><p class="title"><a href="/AI%20Cheats%20Trailer/">AI秘籍预告</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T03:30:11.000Z">2023-07-27</time></p><p class="title"><a href="/Artificial-Neural-Network/">人工神经网络</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-26T08:31:43.000Z">2023-07-26</time></p><p class="title"><a href="/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/">20. 尝试让机器拥有声音</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-21T04:47:54.000Z">2023-07-21</time></p><p class="title"><a href="/BardAPI-ChatGPT/">将 Bard API 与 ChatGPT 集成：实时数据访问</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-15T07:18:39.000Z">2023-07-15</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8Transformers%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E8%BD%AC%E6%96%87%E6%9C%AC/">使用 Transformers 进行语音转文本的完整入门指南</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>