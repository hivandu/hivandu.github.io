<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>10 利用AI索引并分析文献和图片 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Hi, 我是茶桁。 看到我这篇文章的读者们不知道有多少人是接触过ChatGPT或者其他人工智能产品的。"><meta property="og:type" content="blog"><meta property="og:title" content="10 利用AI索引并分析文献和图片"><meta property="og:url" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Hi, 我是茶桁。 看到我这篇文章的读者们不知道有多少人是接触过ChatGPT或者其他人工智能产品的。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170302.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170309.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170319.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170328.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170336.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170345.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170352.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170400.png"><meta property="og:image" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170404.png"><meta property="article:published_time" content="2023-05-17T09:02:24.000Z"><meta property="article:modified_time" content="2023-06-01T13:19:33.567Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170302.png"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/"},"headline":"10 利用AI索引并分析文献和图片","image":["https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170302.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170309.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170319.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170328.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170336.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170345.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170352.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170400.png","https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/20230601170404.png"],"datePublished":"2023-05-17T09:02:24.000Z","dateModified":"2023-06-01T13:19:33.567Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Hi, 我是茶桁。 看到我这篇文章的读者们不知道有多少人是接触过ChatGPT或者其他人工智能产品的。"}</script><link rel="canonical" href="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-05-17T09:02:24.000Z" title="5/17/2023, 5:02:24 PM">2023-05-17</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></span></div></div><h1 class="title is-3 is-size-4-mobile">10 利用AI索引并分析文献和图片</h1><div class="content"><p>Hi, 我是茶桁。</p>
<p>看到我这篇文章的读者们不知道有多少人是接触过ChatGPT或者其他人工智能产品的。</p>
<span id="more"></span>
<p>市面上目前充斥着大量的人工智能产品，从聊天，文案，脚本，音乐，绘画等方方面面都涵盖了。但是不知道有多少人遇到过以下的场景不知道该如何解决：</p>
<ol type="1">
<li><p>我需要针对一篇很长的文章（可以是论文，可以是小说）进行总结或者分析的时候，就开始无从下手。因为ChatGPT在接收长度上是有限制的，这个长度我大概测试过，如果你用的是WebGPT，那么应该中文应该是在2500字左右，多一个字都会告诉你长度超出限制。而我们一篇论文，起码来说都是5000字以上的。分两段来喂给ChatGPT当然可以，但是上下文关联有时候会遇到问题，ChatGPT也会给你胡编乱造。</p></li>
<li><p>有的时候我从客户那里接收到的是一张图片，也许是截图，也许就是拍的一张照片。那么，怎样利用ChatGPT去分析这张图片上的内容，然后根据我的需求给我相应的答案呢？</p></li>
</ol>
<p>以上这两点，估计是很多人遇到想解决的。而今天这篇文章，就是从这两点入手教你如何解决。</p>
<h3 id="大语言模型的不足"><strong>大语言模型的不足</strong></h3>
<p>让我们打开ChatGPT来问一些常识性的问题，这个问题对于大部分上过学的中国人来说，都能从课本上了解到：</p>
<p>“鲁迅先生在日本学习医学的老师是谁？”</p>
<p>结果如下图，这个“嘉泽源之助”到底是谁呢？我也不知道，得到这个答案的时候，我还特意去Google了一下，根本找不到相关资料。</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170302.png" class="" title="img">
<p>那么为什么会出现这种情况呢？这要从大语言模型的原理及它使用训练的数据集说起。</p>
<p>大语言模型利用训练样本中的文本前后关系，对接下来的文本进行概率预测。若出现类似的前后文本越多，那么概率会收敛到正确答案，回答准确；反之，训练过程随机性增大，对应的答案容易似是而非。GPT-3 的模型虽然训练语料很多，但中文语料很少，只有不到 1%。因此，若问很多中文相关的知识性或常识性问题，其回答往往不准确。</p>
<p>解决方法有两种：一是多找一些高质量的中文语料，训练一个新模型；二是找一些数据，利用 OpenAI 提供的"微调"（Fine-tune）接口，在原模型上训练一个新模型。</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170309.png" class="" title="img">
<p>如上图显示，ChatGPT只能提供2021年9月之前的新闻。要解决这个问题，需要更多的文本数据，但对于时效性要求较高的资讯类信息，这种方法并不实用。例如，要让 AI 告诉我们前一天足球赛的比分，需要不断地训练和微调模型，成本太高。不过，ChatGPT的插件已经可以获取网上信息了。</p>
<p>对比之下，我们可以看看Bing是怎么做的。</p>
<h3 id="bing的方式搜索然后提示"><strong>Bing的方式：搜索，然后提示</strong></h3>
<p>对于关注这个领域的朋友，可能会问微软是如何在Bing中加入ChatGPT问答功能的，而且效果似乎也不错。那么Bing是如何实现这一点的呢？虽然我不知道Bing是如何实现的，但如果我来做的话，我会使用搜索后提示的方法。我们可以通过搜索找到与问题相关的语料库，然后将与问题语义最接近的前几个内容作为提示，供AI参考并回答问题。</p>
<p>其实，早期的ChatGPT可以利用Chrome的一款插件（<a target="_blank" rel="noopener" href="https://chrome.google.com/webstore/detail/webchatgpt-chatgpt-with-i/lpfemeioodjbpieminkklglpmhlngfcn?utm_source=chrome-ntp-icon">WebChatGPT</a>）做到这件事，可是也必须是能在网上搜索到的，据我所知，其调用的搜索引擎应该是Google，当我输入Prompt的时候，会先调用这个插件，然后这个插件会去搜索相关信息返回到ChatGPT再从新提问，比如我问 <code>鲁迅先生的医学老师是谁</code> ：</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170319.png" class="" title="img">
<p>看到这里，有些读者应该也明白怎样做了，就是增加语料。我们将问题语义最接近的前几条内容作为提示语的一部分提供给AI，以便AI参考这些内容并回答问题。如下图，我先关闭了插件的Web access，纯喂语料来再试试：</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170328.png" class="" title="img">
<p>这也是利用大语言模型的一个常见模式。因为大语言模型其实内含了两种能力。</p>
<p>第一种能力是海量的语料中已经包含的知识信息。比如，我们前面问 AI 鱼香肉丝的做法，它能回答上来就是因为语料库中已经有了充足的相关知识。这些知识我们通常称之为"世界知识"。这些知识可以包括食材的使用、调料的配比和烹饪方法等等。</p>
<p>第二种能力是根据你输入的内容，理解和推理的能力。如果大语言模型在语料库中并没有这个问题的答案，它也能进行阅读理解。这个过程中，"知识"不是模型本身提供的，而是我们找出来，临时提供给模型的。如果不提供这个上下文，再问一次模型相同的问题，它还是答不上来的。因此，在某些情况下，我们需要提供更多的上下文，以确保模型可以正确地理解问题，给出恰当的答案。</p>
<h3 id="正餐llama_index建立第二个大脑"><strong>正餐：llama_index，建立“第二个大脑”</strong></h3>
<p>我认为，这种先搜索、后提示的方式称为 AI 的"第二大脑"模式，它是一种非常实用的方法。实现这种方法需要先将希望 AI 能够回答的知识建立为一个外部索引，这个索引就像是 AI 的"第二个大脑"。每次向 AI 提问时，它都会在这个第二大脑中查询相关资料，再运用自己的思维能力来回答问题。</p>
<p>目前，许多应用程序都是通过这种模式来实现的，如读论文、读书回答问题等。因此，我们可以自己来实现这个"第二大脑"模式。</p>
<p>但是，我们不必从零开始编写代码，因为这种模式非常常见，所以有人为它编写了一个开源 Python 包，名为 llama-index。我们可以使用这个软件包的几行代码来尝试它是否能够回答与鲁迅先生写的《藤野先生》相关的问题。</p>
<p>由于 llama-index 尚未制作好 Conda 下的包，因此即使在 Conda 下，我们仍需通过 pip 来安装。 同时，我们可以根据需要，根据 llama-index 的文档进行调整和优化，以满足我们特定的需求。</p>
<blockquote>
<p>llama-index 的Github， llama-index官方文档</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install llama-index</span><br><span class="line">pip install langchain</span><br></pre></td></tr></table></figure>
<p>我把《藤野先生》这篇文章转换成了txt文件，并放到data/mr_fujino目录下。我们的代码也很简洁。</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170336.png" class="" title="img">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import openai</span><br><span class="line">import os</span><br><span class="line">from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, StorageContext, load_index_from_storage</span><br><span class="line"></span><br><span class="line"># Set your OpenAI API key directly</span><br><span class="line">os.environ[&#x27;OPENAI_API_KEY&#x27;] = &quot;OPENAI_API_KEY&quot;</span><br><span class="line">openai.api_key = &quot;OPENAI_API_KEY&quot;</span><br><span class="line"></span><br><span class="line">documents = SimpleDirectoryReader(&#x27;./data/mr_fujino&#x27;).load_data()</span><br><span class="line">index = GPTVectorStoreIndex.from_documents(documents)</span><br><span class="line">index.storage_context.persist(&#x27;index_mr_fujino&#x27;)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意这里，必须要import os后设置os.environ[‘OPENAI_API_KEY’], 如果不这么做，而只是像遗忘一样设置openai.api_key = “”, 那么执行会报错，告诉你环境中没有OPENAI_API_KEY。</p>
</blockquote>
<blockquote>
<p>在最新的llama-index中，获取本地数据和写入本地数据都有了较大的改动，目前为止我的代码是可用的，但是一旦报错，我建议您查阅官方文档『llama-index官方文档』</p>
</blockquote>
<p>分析下代码：</p>
<ol type="1">
<li><p>首先，我们通过SimpleDirectoryReader方法将本地目录<code>mr_fujino</code>加载了进来，注意这个方法其实是一个循环方法，会讲目录内的每一个文件都当作是一篇文档。</p></li>
<li><p>然后我们将读取到的所有文档交给了GPTVectorStoreIndex方法来构建索引。将方法名称拆开来看就是<code>GPT Vector Store Index</code>， 可以看出，这是一个将文档转化成向量，然后再变成一个索引。</p></li>
<li><p>最后，我们将索引存储到本地，<code>storage_context.persist</code>这个方法就是<code>GPTVectorStoreIndex</code>方法在最近版本中更改的。之前的版本是<code>save_to_disk</code>, 并会存储成一个json文件。而现在会存储成一个目录，并在其中存储多个json文件： <img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170345.png" class="2. 1." title="img"></p></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">storage_context = StorageContext.from_defaults(persist_dir = &#x27;./index_mr_fujino/&#x27;)</span><br><span class="line"></span><br><span class="line">index = load_index_from_storage(storage_context)</span><br><span class="line">query_engine = index.as_query_engine()</span><br><span class="line">response = query_engine.query(&#x27;鲁迅先生在日本学习医学的老师是谁？&#x27;)</span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>
<p>这里我们读取到本地目录内的所有文件。然后将索引加载到内存中。再对Index索引调用Query函数，就可以得到问题的答案了。</p>
<p>可以看到，通过外部的索引，我们可以正确的获得问题的答案</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 输出答案</span><br><span class="line">鲁迅先生在日本学习医学的老师是藤野严九郎。</span><br></pre></td></tr></table></figure>
<p>似乎问题很容易结局，四行代码解决问题，再加上一行显示结果。</p>
<p>让我们再来测试一下其他的问题看看，这次我们问问鲁迅先生去哪里学的医学：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">response = query_engine.query(&quot;鲁迅先生去哪里学的医学？&quot;)</span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>
<p>回答正确。</p>
<p>接着我们来思考一个问题，我们搜索到的内容，在整个过程里面是如何交给OpenAI的呢？让我们来看看下面这段代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from llama_index import QuestionAnswerPrompt</span><br><span class="line">query_str = &quot;鲁迅先生去哪里学的医学？&quot;</span><br><span class="line">DEFAULT_TEXT_QA_PROMPT_TMPL = (</span><br><span class="line">    &quot;Context information is below. \n&quot;</span><br><span class="line">    &quot;---------------------\n&quot;</span><br><span class="line">    &quot;&#123;context_str&#125;&quot;</span><br><span class="line">    &quot;\n---------------------\n&quot;</span><br><span class="line">    &quot;Given the context information and not prior knowledge, &quot;</span><br><span class="line">    &quot;answer the question: &#123;query_str&#125;\n&quot;</span><br><span class="line">)</span><br><span class="line">QA_PROMPT = QuestionAnswerPrompt(DEFAULT_TEXT_QA_PROMPT_TMPL)</span><br><span class="line"></span><br><span class="line">query_engine = index.as_query_engine(text_qa_template = QA_PROMPT)</span><br><span class="line">response = query_engine.query(query_str)</span><br><span class="line">print(response)</span><br></pre></td></tr></table></figure>
<p>这段代码定义了一个名为<code>QA_PROMPT</code>的对象，并为其设计了一个模板，以便于后续的应用。</p>
<p>在模板中，我们提供了上下文信息（<code>Context information</code>），并支持两个变量：<code>context_str</code>和<code>query_str</code>。在实际被调用时，<code>context_str</code>会被Embedding相似度找出来的内容替换，而<code>query_str</code>则会被实际问题替换。</p>
<p>在实际提问时，我们要求AI只考虑上下文信息，而不是基于其自身的先验知识（<code>prior knowledge</code>）来回答问题。为了更好地利用AI的知识，我们需要提供更多的上下文信息，以便于AI更好地理解问题，给出更加准确的答案。另外，在模板的设计过程中，我们也需要考虑到更多的场景，以便于应对不同的问题，提高AI的应用范围和效果。</p>
<p>我们把搜索结果和问题组合成提示语，让 AI 回答问题。再问一次 AI 确认答案是否正确。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 输出结果</span><br><span class="line">鲁迅先生去仙台学的医学。</span><br></pre></td></tr></table></figure>
<p>可以看到AI又正确的回答出了我们提出的问题。</p>
<p>让我们继续调戏一下，问问不相干的问题会得到什么答案呢？比如，我们问问红楼梦里林黛玉和贾宝玉的关系。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">QA_PROMPT_TMPL = (</span><br><span class="line">    &quot;下面的“我”指的是鲁迅先生 \n&quot;</span><br><span class="line">    &quot;---------------------\n&quot;</span><br><span class="line">    &quot;&#123;context_str&#125;&quot;</span><br><span class="line">    &quot;\n---------------------\n&quot;</span><br><span class="line">    &quot;根据这些信息，请回答问题: &#123;query_str&#125;\n&quot;</span><br><span class="line">    &quot;如果您不知道的话，请回答不知道\n&quot;</span><br><span class="line">)</span><br><span class="line">QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)</span><br><span class="line"></span><br><span class="line">query_engine = index.as_query_engine(text_qa_template = QA_PROMPT)</span><br><span class="line"></span><br><span class="line">response = query_engine.query(&#x27;请问林黛玉和贾宝玉是什么关系？&#x27;)</span><br><span class="line">print(response)</span><br><span class="line"># 输出结果</span><br><span class="line">不知道</span><br></pre></td></tr></table></figure>
<p>这样的回答基本上是基于我们给到的Prompt有提到<code>如果不知道的话，就回答不知道</code>。如果给这段prompt，相信AI一定会信口胡诌一气。而我们也确确实实的发现，AI的回答是基于我们所限定的语料而没有根据<code>prior knowledge</code>来回答。</p>
<h3 id="用-llama_index-总结文章"><strong>用 llama_index 总结文章</strong></h3>
<p>还有一个常见的使用 llama-index 这样的Python 库的应用场景，就是生成文章的摘要。在前面教你如何进行文本聚类的时候，我们已经看到了可以通过合适的提示语（Prompt）做到这一点。不过，如果要总结一篇论文、甚至是一本书，每次最多只能支持 4096 个 Token 的 API 就不太够用了。</p>
<p>要解决这个问题也并不困难，我们只要进行分段小结，再对总结出来的内容再做一次小结就可以了。我们可以把一篇文章，乃至一本书，构建成一个树状的索引。每一个树里面的节点，就是它的子树下内容的摘要。最后，在整棵树的根节点，得到的就是整篇文章或者整本书的总结了。</p>
<p>当然，这个方法不仅仅适用于论文和书籍，也可以用于其他需要总结的长文本，比如新闻报道、电影剧情等。此外，我们还可以通过扩展 llama-index 的功能，使其支持更多 Token 的 API，从而处理更长的文章。最后，值得一提的是，利用 llama-index 生成文章摘要的应用场景还有很多，比如在搜索引擎、聊天机器人等领域都有着广泛的应用。</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170352.png" class="" title="img">
<p>原理清楚了，就是将文本分片建立树状结构的索引来完成全文的总结。</p>
<p>那么事实上，llama-index 内置了这样的功能，接下来，我们就看看要实现这个功能，我们该如何写代码呢？</p>
<p>在开始写代码之前，我们需要安装一下spacy这个Python库，并且下载一下对应的中文分词分句需要的模型：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install spacy</span><br><span class="line">python3 -m spacy download zh_core_web_sm</span><br></pre></td></tr></table></figure>
<p>安装完成完毕之后，那么接下来的事情就比较简单了。</p>
<p>我们使用<code>GPTListIndex</code>这个llama-index内最简单的索引结构，并做了两点优化。</p>
<ol type="1">
<li><p>首先，在索引中，我们指定了一个 LLMPredictor，使得我们在向 OpenAI 发起请求时都使用 ChatGPT 模型，因为这个模型比较快，也比较便宜。而 llama-index 默认使用的模型 text-davinci-003 的价格比 gpt-3.5-turbo 贵上十倍。</p></li>
<li><p>其次，我们定义了使用 SpacyTextSplitter 来进行中文文本的分割，因为 llama-index 默认的设置对于中文文本的支持和效果都不太好。我们选用的文章是中文的，里面的标点符号也都是中文的，所以我们使用了中文的语言模型。我们也限制了分割出来的文本段，最长不要超过 2048 个 Token，这些参数都可以根据你实际用来处理的文章内容和属性自己设置。</p></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">from langchain.chat_models import ChatOpenAI</span><br><span class="line">from langchain.text_splitter import SpacyTextSplitter</span><br><span class="line">from llama_index import GPTListIndex, LLMPredictor, ServiceContext</span><br><span class="line">from llama_index.node_parser import SimpleNodeParser</span><br><span class="line"></span><br><span class="line"># difine LLM</span><br><span class="line">llm_predictor = LLMPredictor(llm = ChatOpenAI(</span><br><span class="line">    temperature = 0,</span><br><span class="line">    model_name = &#x27;gpt-3.5-turbo&#x27;,</span><br><span class="line">    max_tokens = 1024</span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">text_splitter = SpacyTextSplitter(pipeline = &#x27;zh_core_web_sm&#x27;, chunk_size = 2048)</span><br><span class="line">parser = SimpleNodeParser(text_splitter = text_splitter)</span><br><span class="line">documents = SimpleDirectoryReader(&#x27;./data/mr_fujino/&#x27;).load_data()</span><br><span class="line">nodes = parser.get_nodes_from_documents(documents)</span><br><span class="line"></span><br><span class="line">service_context = ServiceContext.from_defaults(llm_predictor = llm_predictor)</span><br><span class="line"></span><br><span class="line">list_index = GPTListIndex(nodes = nodes, service_context = service_context)</span><br></pre></td></tr></table></figure>
<p><code>GPTListIndex</code> 构建索引时不会创建嵌入，因此索引构建快速且不消耗令牌数。它只是根据您设置的索引结构和分割方式建立了一个列表索引。然后，我们可以让 AI 小结这篇文章。由于我们想要按照树状结构进行文章的小结，因此我们设定了一个参数 <code>response_mode = "tree_summarize"</code>。这个参数会按照树状结构将整篇文章总结出来。实际上，它会将每一段文本分片并通过查询内的提示语进行小结，然后再对多个小结里的内容通过查询里的提示语继续小结。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list_response = list_index.as_query_engine(response_mode=&quot;tree_summarize&quot;)</span><br><span class="line">response = list_response.query(&quot;下面鲁迅先生以第一人称‘我’写的内容，请你用中文总结一下:&quot;)</span><br><span class="line"># response = list_index.query()</span><br><span class="line">print(response)</span><br><span class="line"># 输出结果</span><br><span class="line">鲁迅先生在日本学习医学时遇到了藤野严九郎教授，他很有学问，对学生也很关心，甚至帮助鲁迅修改讲义。但鲁迅当时不够用功，有时也很任性。鲁迅遇到了一些困难，但藤野先生一直鼓励他。最终，鲁迅决定离开医学，去学习生物学。在离开前，藤野先生给了他一张照片，并希望他能保持联系。鲁迅很久没有和一个人联系了，虽然想写信但难以下笔。他想起了藤野先生，这个人给他很多鼓励和教诲，希望中国有新的医学和学术。鲁迅收藏了他所改正的讲义，但七年前搬家时丢失了一半。他的照片还挂在鲁迅的房间里，每当鲁迅疲倦时看到他的照片就会增加勇气。</span><br></pre></td></tr></table></figure>
<p>完成，基本上，我们用了几行代码完成了整个文章的总结，返回的结果从整体上来看还是不错的。</p>
<h3 id="多模态的引入让llama-index识别图片"><strong>多模态的引入让llama-index识别图片</strong></h3>
<p>llama_index 不仅能索引文本，还能够索引图片和插图等信息，这就是所谓的多模态能力。通过一些多模态模型，将文本和图片联系起来，实现了这种能力。在课程的第三部分，我们将专门探讨这些图像的多模态模型的构建方法。</p>
<p>接下来，我们来看一个 llama_index <a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index/blob/main/examples/multimodal/Multimodal.ipynb">官方样例库提供的例子</a>。这个例子是将吃饭的小票拍下来，然后记录下吃的东西、花费的金额以及吃饭的日期等信息。这种记录方式既方便又直观，也能够帮助我们更好地管理财务和饮食。不仅如此，我们还可以利用 llama_index 来查询自己的饮食习惯和花费情况，进一步了解自己的生活方式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex</span><br><span class="line">from llama_index.readers.file.base import DEFAULT_FILE_EXTRACTOR, ImageParser</span><br><span class="line">from llama_index.response.notebook_utils import display_response, display_image</span><br><span class="line">from llama_index.indices.query.query_transform.base import ImageOutputQueryTransform</span><br><span class="line"></span><br><span class="line">image_parser = ImageParser(keep_image = True, parse_text = True)</span><br><span class="line">file_extractor = DEFAULT_FILE_EXTRACTOR</span><br><span class="line">file_extractor.update(&#123;</span><br><span class="line">    &#x27;.jpg&#x27;: image_parser,</span><br><span class="line">    &#x27;.png&#x27;: image_parser,</span><br><span class="line">    &#x27;.jpeg&#x27;: image_parser,</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"># NOTE: we add filename as metadata for all documents</span><br><span class="line">filename_fn = lambda filename: &#123;&#x27;file_name&#x27;: filename&#125;</span><br><span class="line"></span><br><span class="line">receipt_reader = SimpleDirectoryReader(</span><br><span class="line">    input_dir = &#x27;./data/receipts/&#x27;,</span><br><span class="line">    file_extractor = file_extractor,</span><br><span class="line">    file_metadata = filename_fn,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">receipt_documents = receipt_reader.load_data()</span><br></pre></td></tr></table></figure>
<p>为了更好地支持图片索引，我们引入了 <code>ImageParser</code> 这个类，它是基于 OCR 扫描的模型 Donut 构建而成。它由一个视觉编码器和一个文本解码器组成，可以将任何一张图片转换成一段文本，然后我们再通过 OpenAI 的嵌入技术将这段文本转换成一个向量。</p>
<p>现在，我们可以使用简单的 <code>SimpleDirectoryReader</code>，通过指定 <code>FileExtractor</code> 来解析对应的图片，并将其转换为向量，以进行检索。</p>
<p>此外，在提问时，我们还使用了 <code>ImageOutputQueryTransform</code>，可以在输出结果时为图片添加标签，以便在Jupyter中更好地显示。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">receipts_index = GPTVectorStoreIndex.from_documents(receipt_documents)</span><br><span class="line">response_query_engine = receipts_index.as_query_engine(query_transform = ImageOutputQueryTransform(width = 400))</span><br><span class="line">receipts_response = response_query_engine.query(</span><br><span class="line">    &quot;When was the last time I went to McDonald\&#x27;s and how much did I spend. Also show me the receipt from my visit.&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">display_response(receipts_response)</span><br></pre></td></tr></table></figure>
<p>得到的结果：</p>
<blockquote>
<p>Final Response: The last time you went to McDonald's was on 03/10/2018 at 07:39:12 PM and you spent $26.15. Here is the receipt</p>
</blockquote>
<p>在上述内容中，我们可以看到 OpenAI 的强大之处在于其对于任意文本的处理能力。通过对文本的处理，OpenAI 能够不仅展示对应的图片，还能够给出正确的答案。</p>
<p>为了更好地理解图片的内容，我们可以对其进行单独解析，以获取其中所包含的文本信息。通过这种方式，我们能够更全面地了解图片所代表的意义和含义。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_image = image_parser.parse_file(&#x27;./data/receipts/1100-receipt.jpg&#x27;)</span><br><span class="line">print(output_image.text)</span><br></pre></td></tr></table></figure>
<p>输出的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;s_menu&gt;&lt;s_nm&gt; Story&lt;/s_nm&gt;&lt;s_num&gt; 16725 Stony Platin Rd&lt;/s_nm&gt;&lt;s_num&gt; Store#:&lt;/s_nm&gt;&lt;s_num&gt; 3659&lt;/s_num&gt;&lt;s_price&gt; 700-418-8362&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Welcome to all day breakfast dormist O Md Donald&#x27;s&lt;/s_nm&gt;&lt;s_num&gt; 192&lt;/s_num&gt;&lt;s_price&gt; 192&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; QTY ITEM&lt;/s_nm&gt;&lt;s_num&gt; OTAL&lt;/s_num&gt;&lt;s_unitprice&gt; 03/10/2018&lt;/s_unitprice&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 07:39:12 PM&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Delivery&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 0.00&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; 10 McNuggets EVM&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 10.29&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Barbeque Sauce&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 1&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Barbeque Sauce&lt;/s_nm&gt;&lt;s_num&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 0.40&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; L Coke&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 0.40&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; M French Fries&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 3.99&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; HM GrChS S-Fry Yog&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;sep/&gt;&lt;s_nm&gt; Smoonya&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;sep/&gt;&lt;s_nm&gt; HM Apple Juice&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 2.89&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Cookies&lt;/s_nm&gt;&lt;s_cnt&gt; 6&lt;/s_cnt&gt;&lt;s_price&gt; 2.89&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Choc Chip Cookie&lt;/s_nm&gt;&lt;s_cnt&gt; 6&lt;/s_cnt&gt;&lt;s_price&gt; 1.19&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Baked Apple Pie&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 3.29&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; French Fries&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 2.99&lt;/s_price&gt;&lt;sep/&gt;&lt;s_nm&gt; Iced Tea&lt;/s_nm&gt;&lt;s_cnt&gt; 1&lt;/s_cnt&gt;&lt;s_price&gt; 2.99&lt;/s_price&gt;&lt;/s_menu&gt;&lt;s_sub_total&gt;&lt;s_subtotal_price&gt; 25.04&lt;/s_subtotal_price&gt;&lt;s_tax_price&gt; 1.11&lt;/s_tax_price&gt;&lt;/s_sub_total&gt;&lt;s_total&gt;&lt;s_total_price&gt; 26.15&lt;/s_total_price&gt;&lt;s_changeprice&gt; 0.00&lt;/s_changeprice&gt;&lt;s_creditcardprice&gt; 26.15&lt;/s_creditcardprice&gt;&lt;/s_total&gt;</span><br></pre></td></tr></table></figure>
<p>可以看到，这里我们使用 OCR 技术将打印好的小票转换成了可读的文本。文本结果中包含了我们去的店铺的名字和时间，以及消费的金额等信息。除此之外，我们还可以通过这样的方式将其他打印材料转换为可编辑的文本，例如收据、发票等等。</p>
<p>围绕 OpenAI 和整个大语言模型的生态，目前正在快速发展中。因此，llama-index 这个库也在不断地迭代和更新。在我使用它的过程中，我发现了各种各样的小 Bug，并且对于中文的支持也存在一些小缺陷。不过，作为开源项目，它已经拥有了一个非常不错的生态系统，特别是提供了大量的 DataConnector。这些 DataConnector 不仅支持 PDF、ePub 等电子书格式，还支持 YouTube、Notion、MongoDB 等外部的数据源和 API 接入的数据，以及本地数据库的数据。你可以在 <a target="_blank" rel="noopener" href="http://llamahub.ai/">llamahub.ai</a> 上找到社区开发者开发出的读取各种不同数据源格式的 DataConnector。（大家有看到B站吗？不知道是否对视频进行解析的，回头来试试。）</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170400.png" class="" title="img">
<h3 id="小结"><strong>小结</strong></h3>
<p>在这一讲中，我们介绍了 llama-index 这个 Python 包，它能够帮助你将外部的资料库变成索引，并且通过提供的查询接口快速向文档提问。除此之外，你也可以通过将文本分片并通过树状的方式管理索引来进行小结。虽然 llama-index 还在不断发展中，但它已经非常值得拿来使用，可以加速你开发大语言模型类的相关应用。</p>
<p>除了上述功能，llama-index 还有很多其他功能。你可以在官网上查看<a target="_blank" rel="noopener" href="https://gpt-index.readthedocs.io/en/latest/">相关文档</a>，也可以直接去<a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index">源代码</a>里查看具体实现。值得一提的是，llama-index 其实给出了一种使用大语言模型的设计模式，我称之为"第二大脑"模式。通过先将外部的资料库索引，然后每次提问的时候，先从资料库里通过搜索找到有相关性的材料，然后再通过 AI 的语义理解能力让 AI 基于搜索到的结果来回答问题。这一模式在未来可能会成为一种趋势，具有广阔的应用前景。</p>
<img src="/Use-AI-to-index-and-analyze-documents-and-images/20230601170404.png" class="" title="img">
<p>其中，前两步的索引和搜索，我们可以使用 OpenAI 的 Embedding 接口，也可以使用其它的大语言模型的 Embedding，或者传统的文本搜索技术。这些技术都有各自的优缺点，需要根据具体情况进行选择。比如，OpenAI 的 Embedding 接口可以更好地处理语义信息，但需要更大的计算资源和更长的训练时间；传统的文本搜索技术则速度更快，但精度不如大语言模型。另外，对于多模态功能的实现，我们还可以通过其他的模型来把图片变成文本进行索引，从而更好地利用多种信息资源。</p>
<p>在最后一步的问答中，OpenAI 的接口往往是必须的。这是因为问答需要更深入地理解文本语义，而传统的模型往往难以做到这一点。不过，我们也可以使用一些基于 OpenAI 的模型来自己训练问答模型，从而更好地适应自己的数据集和需求。</p>
<p>通过今天的这几个例子，希望你也能开始建立起自己的“第二大脑”资料库，能够将自己的数据集交给 AI 进行索引，获得一个专属于你自己的 AI。当然，这只是一个开始，未来还有更多的技术和应用等待我们去探索。</p>
<h3 id="课后练习"><strong>课后练习</strong></h3>
<p>在 llama-index 的生态系统中，不仅支持各种各样的 DataConnector 去加载数据，后端还支持各种形式的索引。除了在语义搜索中介绍过的 Faiss、Pinecone、Weaviate，该库还支持哪些形式的索引呢？这些索引的使用场景和优势是什么呢？你能详细解释一下吗？</p>
<p>除了进行问答和文章概括之外，llama-index 还有哪些功能可以帮助我们呢？你能提出一些例子吗？这个库的使用场景有哪些呢？</p>
<p>现在有很多应用，在用户上传文档后，会给出一系列提示，告诉用户可以向对应的书籍或论文提出什么问题。例如 <a target="_blank" rel="noopener" href="https://scispace.com/">SCISPACE</a>，你能解释一下这些提示是如何生成的吗？这个过程中使用了哪些技术？</p>
<p>期待在评论区看到你的分享！同时，也欢迎你把这节课分享给感兴趣的朋友，我们下一讲再见。</p>
<h3 id="推荐阅读"><strong>推荐阅读</strong></h3>
<p>llama-index 的功能非常强大。如果你想深入了解该库，可以查看官方文档和示例部分，以了解它可以用来做什么。</p>
<ol type="1">
<li>官方文档：<a target="_blank" rel="noopener" href="https://gpt-index.readthedocs.io/en/latest/">https://gpt-index.readthedocs.io/en/latest/</a></li>
<li>源码以及示例：<a target="_blank" rel="noopener" href="https://github.com/jerryjliu/llama_index">https://github.com/jerryjliu/llama_index</a></li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>10 利用AI索引并分析文献和图片</p><p><a href="https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/">https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-05-17</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Save-costs-with-an-open-source-model/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">11 用好开源模型节约成本</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/Implementing-semantic-retrieval-using-Embedding/"><span class="level-item">09 使用Embedding实现语义检索</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/Use-AI-to-index-and-analyze-documents-and-images/';
            this.page.identifier = 'Use-AI-to-index-and-analyze-documents-and-images/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">154</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">20</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T06:13:06.000Z">2023-07-27</time></p><p class="title"><a href="/AI%20Cheats%20Trailer/">AI秘籍预告</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T03:30:11.000Z">2023-07-27</time></p><p class="title"><a href="/Artificial-Neural-Network/">人工神经网络</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-26T08:31:43.000Z">2023-07-26</time></p><p class="title"><a href="/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/">20. 尝试让机器拥有声音</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-21T04:47:54.000Z">2023-07-21</time></p><p class="title"><a href="/BardAPI-ChatGPT/">将 Bard API 与 ChatGPT 集成：实时数据访问</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-15T07:18:39.000Z">2023-07-15</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8Transformers%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E8%BD%AC%E6%96%87%E6%9C%AC/">使用 Transformers 进行语音转文本的完整入门指南</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>