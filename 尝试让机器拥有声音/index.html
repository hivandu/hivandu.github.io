<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>20. 尝试让机器拥有声音 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="大家好，我是Hivan。 好久不见了，今天我们来讨论下如何让机器拥有声音。"><meta property="og:type" content="blog"><meta property="og:title" content="20. 尝试让机器拥有声音"><meta property="og:url" content="https://hivan.me/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="大家好，我是Hivan。 好久不见了，今天我们来讨论下如何让机器拥有声音。"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-07-26T08:31:43.000Z"><meta property="article:modified_time" content="2023-07-26T12:05:47.579Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/"},"headline":"20. 尝试让机器拥有声音","image":[],"datePublished":"2023-07-26T08:31:43.000Z","dateModified":"2023-07-26T12:05:47.579Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"大家好，我是Hivan。 好久不见了，今天我们来讨论下如何让机器拥有声音。"}</script><link rel="canonical" href="https://hivan.me/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-07-26T08:31:43.000Z" title="7/26/2023, 4:31:43 PM">2023-07-26</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></span></div></div><h1 class="title is-3 is-size-4-mobile">20. 尝试让机器拥有声音</h1><div class="content"><p>大家好，我是Hivan。</p>
<p>好久不见了，今天我们来讨论下如何让机器拥有声音。</p>
<span id="more"></span>
<p>回顾一下我们<a
href="../%E5%BF%AB%E9%80%9F%E5%80%BE%E5%90%AC%E5%92%8C%E6%80%BB%E7%BB%93%E9%9F%B3%E9%A2%91%E5%86%85%E5%AE%B9/">上一讲</a>的内容，我们已经成功使用Whisper模型使得AI能够理解我们说的话。这为我们带来了很多应用，例如让AI代替我们收听播客并总结内容。然而，这只是单向的交流模式。现在，让我们探索更深入的可能性，让AI不仅仅能够“听懂”我们的话，而且通过ChatGPT回答我们的问题，并将所有内容合成语音，用声音与我们进行双向交互。</p>
<p>这就是我们本次探索的主题：让AI说话。我们将学习如何使用云端API进行语音合成（Text-To-Speech），同时也会介绍开源模型，使您能够在本地CPU上实现这一功能，让数据安全问题不再是困扰。</p>
<p>让我们一起，给机器赋予声音吧！</p>
<h2 id="使用-azure-云进行语音合成">使用 Azure 云进行语音合成</h2>
<p>语音合成技术早已迈入成熟阶段，你所听到的许多短视频配音都借助此技术实现。无论是<a
target="_blank" rel="noopener" href="https://www.xfyun.cn/services/online_tts">科大讯飞</a>、<a
target="_blank" rel="noopener" href="https://ai.aliyun.com/nls/tts">阿里云</a>、<a
target="_blank" rel="noopener" href="https://ai.baidu.com/tech/speech/tts">百度</a>、<a
target="_blank" rel="noopener" href="https://aws.amazon.com/cn/polly/">AWS Polly</a>还是<a
target="_blank" rel="noopener" href="https://cloud.google.com/text-to-speech?hl=zh-cn">Google
Cloud</a>，国内外的大公司纷纷提供了类似的云服务。然而，今天我们将带您领略微软Azure云的语音合成API，主要是因为以下两个原因：</p>
<p>首先，微软与OpenAI的合作让Azure得以托管OpenAI相关模型。这意味着，在实际的生产环境中，我们只需与一个云服务供应商打交道即可，为使用带来极大便利。</p>
<p>其次，Azure的价格相较之下较为亲民，且提供免费的使用额度。只要您的月度字符使用量不超过50万，即可无需额外付费。</p>
<p>携手Azure云，我们踏上了探索语音合成的旅程。在启程前，您需要先注册一个Azure云账号，并开通<a
target="_blank" rel="noopener" href="https://azure.microsoft.com/zh-cn/products/cognitive-services/#overview">微软认知服务</a>。通过按照这个<a
target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/azure/ai-services/multi-service-resource?tabs=macos&amp;pivots=azportal#get-the-keys-for-your-resource">文档</a>，您将逐步完成这一过程，并获得属于自己的API
Key。以下为关键步骤的截图，以便为您提供参考。</p>
<figure>
<img
src="https://static001.geekbang.org/resource/image/e5/3c/e5b476e56ec3358e0925cacac1ee463c.png?wh=796x837"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p><strong>注：我选择了 East US 区域，因为这个区域也可以部署 OpenAI 的
ChatGPT 服务。</strong></p>
<figure>
<img
src="https://static001.geekbang.org/resource/image/73/6f/73eaa98c11abb722b0b08dd6377cd06f.png?wh=949x492"
alt="img" />
<figcaption aria-hidden="true">img</figcaption>
</figure>
<p>获取了API
Key之后，我强烈建议您将其设置为环境变量。这样一来，在您使用Notebook或者编写代码时，就能避免不小心将自己的API
Key暴露出去，从而被他人免费使用。同样地，我们还需要在环境变量中设置使用的Azure服务所在的区域，比如我们选择的是eastus区域。</p>
<p>以下是在Linux或者类Unix系统中设置环境变量的命令示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export AZURE_SPEECH_KEY=YOUR_API_KEY</span><br><span class="line">export AZURE_SPEECH_REGION=eastus</span><br></pre></td></tr></table></figure>
<p>获取了API
Key之后，我强烈建议您将其设置为环境变量。这样一来，在您使用Notebook或者编写代码时，就能避免不小心将自己的API
Key暴露出去，从而被他人免费使用。同样地，我们还需要在环境变量中设置使用的Azure服务所在的区域，比如我们选择的是eastus区域。</p>
<p>以下是在Linux或者类Unix系统中设置环境变量的命令示例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bashCopy code</span><br><span class="line">export AZURE_SPEECH_KEY=YOUR_API_KEY</span><br><span class="line">export AZURE_SPEECH_REGION=eastus</span><br></pre></td></tr></table></figure>
<p>当然，别忘了安装所需的Python包，您可以使用以下命令来安装azure-cognitiveservices-speech包：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install azure-cognitiveservices-speech</span><br></pre></td></tr></table></figure>
<p>这样，我们就为使用Azure云的语音合成API做好了准备！</p>
<h2 id="基本的语音合成">基本的语音合成</h2>
<p>当您的账号和环境设置完成后，现在我们可以开始动手尝试Azure语音合成的效果了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> azure.cognitiveservices.speech <span class="keyword">as</span> speechsdk</span><br><span class="line"></span><br><span class="line"><span class="comment"># This example requires environment variables named &quot;SPEECH_KEY&quot; and &quot;SPEECH_REGION&quot;</span></span><br><span class="line">speech_config = speechsdk.SpeechConfig(subscription=os.environ.get(<span class="string">&#x27;AZURE_SPEECH_KEY&#x27;</span>), region=os.environ.get(<span class="string">&#x27;AZURE_SPEECH_REGION&#x27;</span>))</span><br><span class="line">audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The language of the voice that speaks.</span></span><br><span class="line">speech_config.speech_synthesis_voice_name=<span class="string">&#x27;zh-CN-XiaohanNeural&#x27;</span></span><br><span class="line"></span><br><span class="line">speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;今天天气真不错，ChatGPT真好用。&quot;</span></span><br><span class="line"></span><br><span class="line">speech_synthesizer.speak_text_async(text)</span><br></pre></td></tr></table></figure>
<p>运行以上代码后，您将会听到一个女声说：“今天天气真不错，ChatGPT
真好用。”</p>
<p>这几行代码非常简单易懂：</p>
<ol type="1">
<li>我们首先通过配置读取了API
Key和Region，以确保API调用的授权和定位信息。</li>
<li>接着，我们使用配置参数<code>speech_synthesis_voice_name</code>来指定合成语音所使用的声音。这个参数可以让我们选择不同的声音，包括不同的语言和不同的人物角色。在Azure的"Language
and voice support"文档中，您可以找到对应的声音列表。</li>
<li>通过调用<code>speak_text_async</code>函数，我们能够异步地请求API服务，并直接播放合成的语音。</li>
</ol>
<p>通过更改<code>speech_synthesis_voice_name</code>参数，我们还可以选择其他声音，例如男声，以获得不同的语音合成效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">speech_config.speech_synthesis_voice_name=<span class="string">&#x27;zh-CN-YunfengNeural&#x27;</span></span><br><span class="line">speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)</span><br><span class="line">speech_synthesizer.speak_text_async(text)</span><br></pre></td></tr></table></figure>
<h2 id="指定语音的风格与角色">指定语音的风格与角色</h2>
<p>如果您仔细查看了<a
target="_blank" rel="noopener" href="https://learn.microsoft.com/en-us/azure/ai-services/speech-service/language-support?tabs=tts#prebuilt-neural-voices">"Language
and voice
support"文档</a>，您会发现其中提供了大量的<code>voice_name</code>选项。而且在很多<code>voice_name</code>中，我们还可以选择额外的两个参数，即<code>Styles</code>和<code>Roles</code>，它们分别代表了合成语音的语气和对应的角色。通过这两个参数，我们能够让AI在许多场景中扮演不同的角色，实现丰富多样的表现效果。</p>
<p>举个例子，下面的示例代码演绎了一段母子之间有关买玩具的对话。您可以尝试运行这段代码，亲身体验其效果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ssml = <span class="string">&quot;&quot;&quot;&lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;</span></span><br><span class="line"><span class="string">       xmlns:mstts=&quot;https://www.w3.org/2001/mstts&quot; xml:lang=&quot;zh-CN&quot;&gt;</span></span><br><span class="line"><span class="string">    &lt;voice name=&quot;zh-CN-YunyeNeural&quot;&gt;</span></span><br><span class="line"><span class="string">        儿子看见母亲走了过来，说到：</span></span><br><span class="line"><span class="string">        &lt;mstts:express-as role=&quot;Boy&quot; style=&quot;cheerful&quot;&gt;</span></span><br><span class="line"><span class="string">            “妈妈，我想要买个新玩具”</span></span><br><span class="line"><span class="string">        &lt;/mstts:express-as&gt;</span></span><br><span class="line"><span class="string">    &lt;/voice&gt;</span></span><br><span class="line"><span class="string">    &lt;voice name=&quot;zh-CN-XiaomoNeural&quot;&gt;</span></span><br><span class="line"><span class="string">        母亲放下包，说：</span></span><br><span class="line"><span class="string">        &lt;mstts:express-as role=&quot;SeniorFemale&quot; style=&quot;angry&quot;&gt;</span></span><br><span class="line"><span class="string">            “我看你长得像个玩具。”</span></span><br><span class="line"><span class="string">        &lt;/mstts:express-as&gt;</span></span><br><span class="line"><span class="string">    &lt;/voice&gt;</span></span><br><span class="line"><span class="string">&lt;/speak&gt;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()</span><br></pre></td></tr></table></figure>
<p>在Azure中，我们并不是通过在API中配置一些参数来指定文本的角色和语气，而是通过使用一种名为SSML格式的XML文件来实现。SSML代表Speech
Synthesis Markup
Language，即语音合成标记语言。这并非是Azure云的专有格式，而是由W3C制定的标准，因此同样的XML格式不仅可以在Azure云中使用，也可以在Google
Cloud等其他平台中使用。</p>
<p>通过SSML中元素的属性配置，我们可以指定不同文本段的<code>voice_name</code>、<code>role</code>和<code>style</code>。例如，在上述示例中，我们使用了两个<code>voice</code>元素，分别代表了两个不同人物的声音。<code>voice</code>元素内的<code>name</code>属性用于指定该段声音的<code>voice_name</code>。而在<code>voice</code>元素内部，我们还可以嵌套<code>mstss:express-as</code>元素，在其中指定<code>role</code>和<code>style</code>。通过这样的设置，一个<code>voice_name</code>就可以在不同的场景片段中以不同的语气和角色进行语音合成。这为我们创造更加生动多样的合成效果提供了便利。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">ssml = <span class="string">&quot;&quot;&quot;&lt;speak version=&quot;1.0&quot; xmlns=&quot;http://www.w3.org/2001/10/synthesis&quot;</span></span><br><span class="line"><span class="string">       xmlns:mstts=&quot;https://www.w3.org/2001/mstts&quot; xml:lang=&quot;en-US&quot;&gt;</span></span><br><span class="line"><span class="string">    &lt;voice name=&quot;en-US-JennyNeural&quot;&gt;</span></span><br><span class="line"><span class="string">        &lt;mstts:express-as style=&quot;excited&quot;&gt;</span></span><br><span class="line"><span class="string">            That&#x27;d be just amazing!</span></span><br><span class="line"><span class="string">        &lt;/mstts:express-as&gt;</span></span><br><span class="line"><span class="string">        &lt;mstts:express-as style=&quot;friendly&quot;&gt;</span></span><br><span class="line"><span class="string">            What&#x27;s next?</span></span><br><span class="line"><span class="string">        &lt;/mstts:express-as&gt;</span></span><br><span class="line"><span class="string">    &lt;/voice&gt;</span></span><br><span class="line"><span class="string">&lt;/speak&gt;&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">speech_synthesis_result = speech_synthesizer.speak_ssml_async(ssml).get()</span><br></pre></td></tr></table></figure>
<p>根据我的实际使用经验，中文的语气和角色效果并不十分明显。然而，对于英文文本，使用不同的参数效果则十分显著。建议您可以根据文档中的说明，尝试不同的参数组合，以达到更满意的语音合成效果。</p>
<p>除了<code>style</code>和<code>role</code>，SSML格式还支持许多其他丰富的参数配置。您可以查阅<a
target="_blank" rel="noopener" href="https://www.w3.org/TR/speech-synthesis/">Azure文档中的协议标准</a>，进一步了解并尝试这些参数。</p>
<p>总之，SSML为我们提供了更多定制化语音合成的选项，您可以根据需求来灵活调整，实现更加优质的合成结果。</p>
<h2 id="指定语音的输出方式">指定语音的输出方式</h2>
<p>到目前为止，我们一直使用异步调用的方式，直接将语音播放出来。然而，在许多情况下，我们可能需要将合成的语音存储下来。下面的代码演示了如何实现这一功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">speech_config.speech_synthesis_language=<span class="string">&#x27;zh-CN&#x27;</span></span><br><span class="line">speech_config.speech_synthesis_voice_name=<span class="string">&#x27;zh-CN-XiaohanNeural&#x27;</span></span><br><span class="line"></span><br><span class="line">audio_config = speechsdk.audio.AudioOutputConfig(filename=<span class="string">&quot;./data/tts.wav&quot;</span>)</span><br><span class="line"></span><br><span class="line">speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;今天天气真不错，ChatGPT真好用&quot;</span></span><br><span class="line">speech_synthesizer.speak_text_async(text)</span><br></pre></td></tr></table></figure>
<p>为了将语音合成的输出保存为.wav文件，我们只需将之前设置为<code>use_default_speaker=True</code>的<code>AudioOutputConfig</code>更改为指定一个.wav文件作为输出路径即可。随后，调用<code>speak_text_async</code>函数，语音合成的结果将会保存至指定的.wav文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>当然，您也可以选择将语音暂时保存在内存中，而不是直接存储到文件系统中。另外，如果您更习惯使用MP3格式，您同样可以将输出内容保存为MP3文件。灵活的输出选项使您能够根据具体需求选择最适合的方式处理语音合成结果。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio48Khz192KBitRateMonoMp3)</span><br><span class="line"></span><br><span class="line">speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=<span class="literal">None</span>)</span><br><span class="line">result = speech_synthesizer.speak_text_async(text).get()</span><br><span class="line">stream =speechsdk.AudioDataStream(result)</span><br><span class="line"></span><br><span class="line">stream.save_to_wav_file(<span class="string">&quot;data/tts.mp3&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>通过在<code>speech_config</code>参数中设置<code>synthesis_output_format</code>，我们可以轻松地指定输出格式。在上面的代码示例中，我们将输出格式设定为48kHz采样率、192K码率的MP3格式。同时，我们将<code>AudioConfig</code>设置为<code>None</code>，这样在调用<code>speak_text_async</code>函数后，会得到对应的<code>SpeechSynthesisResult</code>对象。接着，我们将该对象放入<code>AudioDataStream</code>中，使得我们可以按需对这个<code>AudioDataStream</code>进行处理。在这里，我们直接将它存储为一个MP3文件作为例子展示。这样，您可以根据具体需求对语音合成的结果进行处理并保存。</p>
<h2 id="使用开源模型进行语音合成">使用开源模型进行语音合成</h2>
<p>虽然通过Azure云的API，我们可以轻松地进行语音合成，而且速度也很快。但是由于数据安全问题，有时候我们更希望能够在自己的服务器上进行语音合成。当然，这是完全可行的，有许多开源项目支持语音合成。</p>
<p>在这里，为了尝试不同效果，我们可以试试百度开源的PaddleSpeech语音合成功能。</p>
<p>首先，我们需要安装PaddleSpeech相关的Python包。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">%pip install paddlepaddle</span><br><span class="line">%pip install paddlespeech</span><br></pre></td></tr></table></figure>
<p>接下来，我们可以利用PaddleSpeech自带的TTSExecutor，将相应的文本内容转换为WAV文件。值得注意的是，在这个过程中，PaddleSpeech需要下载对应的模型，因此在首次运行时可能需要一定的时间。</p>
<p>使用PaddleSpeech进行语音合成的过程如下：首先，将文本传入TTSExecutor，它会将文本转换为语音。在此过程中，PaddleSpeech会自动下载所需的模型。一旦模型下载完成，文本将被转换为WAV文件，供您进一步使用。</p>
<p>这样，我们就可以在自己的服务器上尝试PaddleSpeech的语音合成功能，并将文本转换成相应的WAV文件。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddlespeech.cli.tts.infer <span class="keyword">import</span> TTSExecutor</span><br><span class="line"></span><br><span class="line">tts_executor = TTSExecutor()</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;今天的天气很不错，我们用开源模型做语音合成。&quot;</span></span><br><span class="line">output_file = <span class="string">&quot;data/paddlespeech.wav&quot;</span></span><br><span class="line">tts_executor(text=text, output=output_file)</span><br></pre></td></tr></table></figure>
<p>使用PaddleSpeech的TTSExecutor，我们可以将您的文本输入转换成WAV文件。然而，要在Python中播放对应的声音，我们还需要借助PyAudio这个包。首先，我们需要安装PyAudio所依赖的portaudio库，然后再安装PyAudio包。</p>
<p>对于Mac用户，您可以通过Homebrew来安装portaudio。请按照以下步骤进行操作：</p>
<ol type="1">
<li>打开终端（Terminal）应用程序。</li>
<li>输入以下命令并按下回车键：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install portaudio</span><br></pre></td></tr></table></figure>
<p>安装完成后，您就可以在Python中使用PyAudio来播放PaddleSpeech转换后的语音文件。通过这一完整流程，我们可以实现语音合成并在Python中播放对应的声音。</p>
<p>对于Ubuntu或者Debian用户，您可以通过apt-get命令来安装portaudio。请按照以下步骤进行操作：</p>
<ol type="1">
<li>打开终端（Terminal）应用程序。</li>
<li>输入以下命令并按下回车键：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install portaudio19-dev</span><br></pre></td></tr></table></figure>
<p>安装完成后，再进行PyAudio包的安装。这样，您就可以在Python中使用PyAudio来播放PaddleSpeech转换后的语音文件，而不会遇到缺少依赖的错误。通过这一完整流程，我们可以实现语音合成并在Python中播放对应的声音。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyaudio</span><br></pre></td></tr></table></figure>
<p>通过 PyAudio，我们可以直接播放 WAV
文件的内容了。对应的代码我放在下面了，其实我不太熟悉 PyAudio
库，但是这样简单的代码直接让 ChatGPT
帮我写，一次就能运行成功。仔细阅读这段代码后，也不难理解其含义。实际上，代码创建了一个PyAudio的流(Stream)，然后从我们的WAV文件中不断读取数据，并将其写入该流中，从而实现声音的播放。如果您将<code>stream.write(data)</code>这一行注释掉，您会发现在整个程序运行过程中将没有声音输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> wave</span><br><span class="line"><span class="keyword">import</span> pyaudio</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">play_wav_audio</span>(<span class="params">wav_file</span>):</span><br><span class="line">	  chunk = <span class="number">1024</span></span><br><span class="line">    <span class="comment"># open the wave file</span></span><br><span class="line">    wf = wave.<span class="built_in">open</span>(wav_file, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># instantiate PyAudio</span></span><br><span class="line">    p = pyaudio.PyAudio()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># open a stream</span></span><br><span class="line">    stream = p.<span class="built_in">open</span>(<span class="built_in">format</span>=p.get_format_from_width(wf.getsampwidth()),</span><br><span class="line">                    channels=wf.getnchannels(),</span><br><span class="line">                    rate=wf.getframerate(),</span><br><span class="line">                    output=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read data from the wave file and play it</span></span><br><span class="line">    data = wf.readframes(chunk)</span><br><span class="line">    <span class="keyword">while</span> data:</span><br><span class="line">        stream.write(data)</span><br><span class="line">        data = wf.readframes(chunk)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># close the stream and terminate PyAudio</span></span><br><span class="line">    stream.stop_stream()</span><br><span class="line">    stream.close()</span><br><span class="line">    p.terminate()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  play_wav_audio(output_file)</span><br></pre></td></tr></table></figure>
<p>不过，需要注意的是，我们调用PaddleSpeech的代码中，默认参数存在一个小问题：它只支持中文的语音合成。如果您的文本中包含英文，运行后您会发现合成的语音中只有中文，而没有英文部分。这可能导致在处理带有多种语言的文本时出现不完整的语音合成结果。为了解决这个问题，我们需要在代码中对相应的参数进行适当的调整，以支持多语言的语音合成功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tts_executor = TTSExecutor()</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;今天的天气很不错，我们用Paddle Speech做语音合成。&quot;</span></span><br><span class="line">output_file = <span class="string">&quot;data/paddlespeech_missing.wav&quot;</span></span><br><span class="line">tts_executor(text=text, output=output_file)</span><br><span class="line"></span><br><span class="line">play_wav_audio(output_file)</span><br></pre></td></tr></table></figure>
<p>运行以上代码后，您可能会发现PaddleSpeech在语音合成过程中丢失了文本内容。</p>
<p>这是因为PaddleSpeech默认情况下使用的是一个只支持中文的模型。但是，我们可以通过一些参数来指定使用的模型，从而实现中英文混合的语音合成。</p>
<p>以下是相应的代码示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tts_executor = TTSExecutor()</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;早上好, how are you? 百度Paddle Speech一样能做中英文混合的语音合成。&quot;</span></span><br><span class="line">output_file = <span class="string">&quot;data/paddlespeech_mix.wav&quot;</span></span><br><span class="line">tts_executor(text=text, output=output_file, </span><br><span class="line">             am=<span class="string">&quot;fastspeech2_mix&quot;</span>, voc=<span class="string">&quot;hifigan_csmsc&quot;</span>, </span><br><span class="line">             lang=<span class="string">&quot;mix&quot;</span>, spk_id=<span class="number">174</span>)</span><br><span class="line"></span><br><span class="line">play_wav_audio(output_file)</span><br></pre></td></tr></table></figure>
<ul>
<li><p>在上面的代码中，我们增加了4个参数来实现中英文混合的语音合成功能。</p>
<ul>
<li><code>am</code>是acoustic
model的缩写，即我们使用的声学模型。在这里，我们选择的是fastspeech2_mix。fastspeech2是一个基于Transformer的语音合成模型，具有高速和高质量的特点。而带有<code>mix</code>的fastspeech2_mix表示该模型支持中英文混合生成。</li>
<li><code>voc</code>是vocoder的缩写，代表音码器。声学模型将文本转换为声音波形信号，但我们还需要通过音码器将声学模型生成的波形转换为可播放的音频。在这里，我们选择的是HiFiGAN_csMSC，它是一种高保真的音码器，基于对抗生成网络（GAN）技术实现。它的训练数据来自HiFiSinger和csMSC，而模型的名称正是由这些关键词组合而成。</li>
<li><code>lang</code>代表模型支持的语言，在这里我们自然选择<code>mix</code>。</li>
<li><code>spk_id</code>类似于之前在Azure中看到的<code>voice_name</code>，不同的<code>spk_id</code>代表不同的人物角色，即不同的说话人声音。</li>
</ul>
<p>通过运行这段代码，我们能够顺利生成中英文混合的语音内容。如果您想了解更多关于PaddleSpeech的语音合成功能，以及支持的各种模型和应用场景，可以参阅其GitHub上的<a
target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/demos/text_to_speech/README_cn.md">Demo文档</a>。</p></li>
</ul>
<h2 id="小结">小结</h2>
<p>在这一讲中，我们学会了两种语音合成的方式。一种是使用Azure云提供的API，另一种是使用百度开源的PaddleSpeech。Azure云的语音合成不仅能简单地将文本转换为语音，还可以通过SSML（Speech
Synthesis Markup
Language）这个W3C标准下的XML标记语言，指定不同的声音（voice_name）、语气（style）和角色（role）。这些功能都非常实用，能够满足我们在不同场景下的语音合成需求。</p>
<p>而PaddleSpeech提供了一个开源解决方案，并且支持中英文混合的语音合成。在PaddleSpeech背后的模型选择中，我们使用了基于Transformer的fastspeech2模型。可以看到，目前Transformer类型的模型在各个领域都占据了主流地位。</p>
<p>通过这一学习，我们的AI现在已经拥有了语音的能力。在下一讲中，我将使用我们已经学到的知识，搭建一个可以通过语音与你聊天的机器人。而且更进一步地，我们还将为它赋予你的虚拟形象。希望你和我一样，对下一讲充满期待！</p>
<h2 id="思考题">思考题</h2>
<p>最后，我给你留下一个思考题。PaddleSpeech不仅可以用于语音合成，还可以用于语音识别。你能尝试使用它来进行语音识别吗？和OpenAI
Whisper相比，你觉得它们两个的效果哪个更好？欢迎你分享你的体验和感受，也欢迎你将本讲分享给需要的朋友。我们下一讲再见！</p>
<h2 id="推荐阅读">推荐阅读</h2>
<p>在PaddleSpeech的<a
target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleSpeech/blob/develop/README_cn.md">中文文档</a>中，包含了丰富的使用PaddleSpeech这个开源库的场景和方法，如果你有兴趣，可以前往查阅。此外，在百度的PaddlePaddle社区也提供了专门的<a
target="_blank" rel="noopener" href="https://aistudio.baidu.com/aistudio/course/introduce/25130">语音相关课程</a>，如果你希望深入了解更多内容，也可以参与这些课程的学习。通过这些资源，你将能够更全面地掌握PaddleSpeech的应用和语音技术的知识。祝你在学习和探索中取得更多进步！</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>20. 尝试让机器拥有声音</p><p><a href="https://hivan.me/尝试让机器拥有声音/">https://hivan.me/尝试让机器拥有声音/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-07-26</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-07-26</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Artificial-Neural-Network/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">人工神经网络</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/BardAPI-ChatGPT/"><span class="level-item">将 Bard API 与 ChatGPT 集成：实时数据访问</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/';
            this.page.identifier = '尝试让机器拥有声音/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">154</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">20</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T06:13:06.000Z">2023-07-27</time></p><p class="title"><a href="/AI%20Cheats%20Trailer/">《AI秘籍》预告</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T03:30:11.000Z">2023-07-27</time></p><p class="title"><a href="/Artificial-Neural-Network/">人工神经网络</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-26T08:31:43.000Z">2023-07-26</time></p><p class="title"><a href="/%E5%B0%9D%E8%AF%95%E8%AE%A9%E6%9C%BA%E5%99%A8%E6%8B%A5%E6%9C%89%E5%A3%B0%E9%9F%B3/">20. 尝试让机器拥有声音</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-21T04:47:54.000Z">2023-07-21</time></p><p class="title"><a href="/BardAPI-ChatGPT/">将 Bard API 与 ChatGPT 集成：实时数据访问</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-15T07:18:39.000Z">2023-07-15</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8Transformers%E8%BF%9B%E8%A1%8C%E8%AF%AD%E9%9F%B3%E8%BD%AC%E6%96%87%E6%9C%AC/">使用 Transformers 进行语音转文本的完整入门指南</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>