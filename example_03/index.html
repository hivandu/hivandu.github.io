<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Machine Learning Part-01 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Linear Regression Example Implement Linear Regression for Boston House Price Problem"><meta property="og:type" content="blog"><meta property="og:title" content="Machine Learning Part-01"><meta property="og:url" content="https://hivan.me/example_03/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Linear Regression Example Implement Linear Regression for Boston House Price Problem"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2021-09-02T12:59:46.685Z"><meta property="article:modified_time" content="2023-06-02T04:10:35.122Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI,人工智能,代码,大语言模型"><meta property="twitter:card" content="summary"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/example_03/"},"headline":"Machine Learning Part-01","image":[],"datePublished":"2021-09-02T12:59:46.685Z","dateModified":"2023-06-02T04:10:35.122Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Linear Regression Example Implement Linear Regression for Boston House Price Problem"}</script><link rel="canonical" href="https://hivan.me/example_03/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-09-02T12:59:46.685Z" title="9/2/2021, 8:59:46 PM">2021-09-02</time>发表</span></div></div><h1 class="title is-3 is-size-4-mobile">Machine Learning Part-01</h1><div class="content"><h2 id="linear-regression-example">Linear Regression Example</h2>
<p>Implement Linear Regression for Boston House Price Problem
<span id="more"></span> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_boston<br><span class="hljs-keyword">from</span> matplotlib.animation <span class="hljs-keyword">import</span> FuncAnimation<br><span class="hljs-keyword">import</span> re<br></code></pre></td></tr></table></figure></p>
<h2 id="part-01-linear-regression">Part-01: Linear Regression</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><code class="hljs python">housing_price = load_boston()<br>dataframe = pd.DataFrame(housing_price[<span class="hljs-string">&#x27;data&#x27;</span>])<br>dataframe.columns = housing_price[<span class="hljs-string">&#x27;feature_names&#x27;</span>]<br>dataframe[<span class="hljs-string">&#x27;price&#x27;</span>] = housing_price[<span class="hljs-string">&#x27;target&#x27;</span>]<br><br><span class="hljs-comment"># sns.heatmap(dataframe.corr(), annot=True, fmt=&#x27;.1f&#x27;)</span><br><span class="hljs-comment"># plt.show()</span><br><br><span class="hljs-built_in">print</span>(dataframe.columns)<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Index([&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;,</span><br><span class="hljs-string">       &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;, &#x27;price&#x27;],</span><br><span class="hljs-string">      dtype=&#x27;object&#x27;)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>rm = dataframe[<span class="hljs-string">&#x27;RM&#x27;</span>]<br>lst = dataframe[<span class="hljs-string">&#x27;LSTAT&#x27;</span>]<br>target = dataframe[<span class="hljs-string">&#x27;price&#x27;</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model</span>(<span class="hljs-params">x, w, b</span>):<br>    <span class="hljs-keyword">return</span> np.dot(x, w.T) + b<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">yhat, y</span>):<br>    <span class="hljs-keyword">return</span> np.mean( (yhat - y) ** <span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_w</span>(<span class="hljs-params">x1, x2, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> np.array([<span class="hljs-number">2</span> *np.mean((yhat - y) * x1), <span class="hljs-number">2</span> * np.mean((yhat - y)  * x2)])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_b</span>(<span class="hljs-params">x1, x2, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * np.mean((yhat - y))<br><br>w = np.random.random_sample((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(w)<br>b = <span class="hljs-number">0</span><br>alpha = <span class="hljs-number">1e-5</span><br><br>epoch = <span class="hljs-number">200</span><br>history = []<br><br>history_k_b_loss = []<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[[0.76646144 0.3095512 ]]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>    losses = []<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)):<br>        random_index = random.choice(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)))<br><br>        x1, x2 = rm[random_index], lst[random_index]<br>        y = target[random_index]<br><br>        yhat = model(np.array([x1, x2]), w, b)<br>        loss_v = loss(yhat, y)<br><br>        w = w - partial_w(x1, x2, y, yhat) * alpha<br>        b = b - partial_b(x1, x2, y, yhat) * alpha<br><br>        losses.append(loss_v)<br><br>        history_k_b_loss.append((w, b, loss_v))<br><br>        <span class="hljs-keyword">if</span> batch % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch: &#123;&#125;, Batch: &#123;&#125;, loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(e, batch, np.mean(losses)))<br><br>    history.append(np.mean(losses))<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Epoch: 0, Batch: 0, loss: 151.86271856102778</span><br><span class="hljs-string">Epoch: 0, Batch: 100, loss: 263.5872813250959</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">Epoch: 199, Batch: 500, loss: 28.308274447364248</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>````<br><br><br><br><span class="hljs-comment">## Logstic Regression</span><br><br>```python<br>housing_price = load_boston()<br>dataframe = pd.DataFrame(housing_price[<span class="hljs-string">&#x27;data&#x27;</span>])<br>dataframe.columns = housing_price[<span class="hljs-string">&#x27;feature_names&#x27;</span>]<br>dataframe[<span class="hljs-string">&#x27;price&#x27;</span>] = housing_price[<span class="hljs-string">&#x27;target&#x27;</span>]<br><br>rm = dataframe[<span class="hljs-string">&#x27;RM&#x27;</span>]<br>lst = dataframe[<span class="hljs-string">&#x27;LSTAT&#x27;</span>]<br>price = dataframe[<span class="hljs-string">&#x27;price&#x27;</span>]<br><span class="hljs-built_in">print</span>(np.percentile(price, <span class="hljs-number">66</span>))<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">23.53</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># plt.hist(target)</span><br><span class="hljs-comment"># plt.show()</span><br><br>dataframe[<span class="hljs-string">&#x27;expensive&#x27;</span>] = dataframe[<span class="hljs-string">&#x27;price&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">int</span>(p &gt; np.percentile(price, <span class="hljs-number">66</span>)))<br>expensive = dataframe[<span class="hljs-string">&#x27;expensive&#x27;</span>]<br><br><span class="hljs-comment"># print(dataframe.head())</span><br><span class="hljs-built_in">print</span>(dataframe[<span class="hljs-string">&#x27;expensive&#x27;</span>])<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">0      1</span><br><span class="hljs-string">1      0</span><br><span class="hljs-string">      ..</span><br><span class="hljs-string">505    0</span><br><span class="hljs-string">Name: expensive, Length: 506, dtype: int64</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">logistic</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model</span>(<span class="hljs-params">x, w, b</span>):<br>    <span class="hljs-keyword">return</span> logistic(np.dot(x, w.T) + b)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">yhat, y</span>):<br>    <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span> * np.<span class="hljs-built_in">sum</span>(y*np.log(yhat) + (<span class="hljs-number">1</span> - y) * np.log(<span class="hljs-number">1</span> - yhat))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_w</span>(<span class="hljs-params">x1, x2, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> np.array([np.<span class="hljs-built_in">sum</span>((yhat - y) * x1), np.<span class="hljs-built_in">sum</span>((yhat - y) * x2)])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_b</span>(<span class="hljs-params">x1, x2, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>(yhat - y)<br>  <br>w = np.random.random_sample((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br><span class="hljs-built_in">print</span>(w)<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[[0.69565948 0.90768813]]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>b = <span class="hljs-number">0</span><br>alpha = <span class="hljs-number">1e-5</span><br><br>epoch = <span class="hljs-number">200</span><br>history = []<br>history_k_b_loss = []<br><br><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>    losses = []<br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)):<br>        random_index = random.choice(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)))<br><br>        x1, x2 = rm[random_index], lst[random_index]<br>        y = expensive[random_index]<br><br>        yhat = model(np.array([x1, x2]), w, b)<br>        loss_v = loss(yhat, y)<br><br>        w = w - partial_w(x1, x2, y, yhat) * alpha<br>        b = b - partial_b(x1, x2, y, yhat) * alpha<br><br>        losses.append(loss_v)<br><br>        history_k_b_loss.append((w, b, loss_v))<br><br>        <span class="hljs-keyword">if</span> batch % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch: &#123;&#125;, Batch: &#123;&#125;, loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(e, batch, np.mean(losses)))<br><br>    history.append(np.mean(losses))<br>    <br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Epoch: 0, Batch: 0, loss: 3.14765267665445e-06</span><br><span class="hljs-string">Epoch: 0, Batch: 100, loss: 13.555508645878497</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">Epoch: 199, Batch: 500, loss: 0.31372698791846687</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>predicated = [model(np.array([x1, x2]), w, b) <span class="hljs-keyword">for</span> x1, x2 <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(rm, lst)]<br>true = expensive<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">accuracy</span>(<span class="hljs-params">y, yhat</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i == j <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(y, yhat)) / <span class="hljs-built_in">len</span>(y)<br>  <br><span class="hljs-built_in">print</span>(accuracy(true, predicated))<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">0.0</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h2 id="decision-boundary">decision boundary</h2>
<p>Linear Regression: Regression is implemented, including the
definition of linear functions, why use linear functions, the meaning of
loss, the meaning of gradient descent, stochastic gradient descent Use
Boston house price dataset. The data set of Beijing housing prices in
2020, why didn’t I use the data set of Beijing housing prices? Boston:
room size, subway, highway, crime rate have a more obvious relationship,
so it is easier to observe the relationship Beijing's housing prices:!
Far and near! Room Condition ==》 School District! ! ! ! =&gt; Very
expensive Haidian District</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_boston<br><br>dataset = load_boston()<br>data = dataset[<span class="hljs-string">&#x27;data&#x27;</span>]<br>target = dataset[<span class="hljs-string">&#x27;target&#x27;</span>]<br>columns = dataset[<span class="hljs-string">&#x27;feature_names&#x27;</span>]<br><br>dataframe = pd.DataFrame(data)<br>dataframe.columns = columns<br>dataframe[<span class="hljs-string">&#x27;price&#x27;</span>] = target<br><br><span class="hljs-comment"># print(dataframe.corr()) # show the correlation of dataframe variables</span><br><span class="hljs-comment"># correlation =&gt; If one value increases, it will cause another value to increase, and the correlation coefficient is closer to 1 if it increases in a certain proportion.</span><br><span class="hljs-comment"># correlation =&gt; 0 means there is no relationship between the two</span><br><span class="hljs-comment"># correlation =&gt; -1 One value increases, the other value must decrease, and the decrease is in equal proportion</span><br><br><span class="hljs-comment"># sns.heatmap(dataframe.corr())</span><br><span class="hljs-comment"># plt.show()</span><br><br><span class="hljs-comment"># RM: The average number of bedrooms in the community</span><br><span class="hljs-comment"># LSTAT: Percentage of low-income people around</span><br><br>rm = dataframe[<span class="hljs-string">&#x27;RM&#x27;</span>]<br>lstat = dataframe[<span class="hljs-string">&#x27;LSTAT&#x27;</span>]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">linear</span>(<span class="hljs-params">x, w, b</span>):<br>    <span class="hljs-comment"># vectorized model</span><br>    <span class="hljs-keyword">return</span> np.dot(x, w.T) + b<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">yhat, y</span>):<br>    <span class="hljs-comment"># numpy broadcast numpy广播方法</span><br>    <span class="hljs-keyword">return</span> np.mean( (yhat - y) ** <span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_w</span>(<span class="hljs-params">x, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> np.array([<span class="hljs-number">2</span> * np.mean((yhat - y) * x[<span class="hljs-number">0</span>]), <span class="hljs-number">2</span> * np.mean((yhat - y) * x[<span class="hljs-number">1</span>])])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_b</span>(<span class="hljs-params">x, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> * np.mean((yhat - y))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">optimize</span>(<span class="hljs-params">w, b, x, y, yhat, pw, pb, learning_rate</span>):<br>    w = w + -<span class="hljs-number">1</span> * pw(x, y, yhat) * learning_rate<br>    b = b + -<span class="hljs-number">1</span> * pb(x, y, yhat) * learning_rate<br><br>    <span class="hljs-keyword">return</span> w, b<br>  <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model_to_be_train, target, loss, pw, pb</span>):<br><br>    w = np.random.random_sample((<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)) <span class="hljs-comment"># w normal</span><br>    b = np.random.random() <span class="hljs-comment"># 0 深度学习的时候会和大家详细解释</span><br>    learning_rate = <span class="hljs-number">1e-5</span><br>    epoch = <span class="hljs-number">200</span><br>    losses = []<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>        batch_loss = []<br>        <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)):<br>            <span class="hljs-comment"># batch training</span><br>            index = random.choice(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)))<br>            rm_x, lstat_x = rm[index], lstat[index]<br>            x = np.array([rm_x, lstat_x])<br>            y = target[index]<br><br>            yhat = model_to_be_train(x, w, b)<br>            loss_v = loss(yhat, y)<br><br>            batch_loss.append(loss_v)<br><br>            w, b = optimize(w, b, x, y, yhat, pw, pb, learning_rate)<br><br>            <span class="hljs-keyword">if</span> batch % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch: &#123;&#125; Batch: &#123;&#125;, loss: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i, batch, loss_v))<br>        losses.append(np.mean(batch_loss))<br><br>    <span class="hljs-keyword">return</span> model_to_be_train, w, b, losses<br>  <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br>    target = dataframe[<span class="hljs-string">&#x27;price&#x27;</span>]<br><br>    model, w, b, losses = train(linear, target, loss, partial_w, partial_b)<br>    plt.plot(losses)<br>    predicate = model(np.array([<span class="hljs-number">19</span>, <span class="hljs-number">7</span>]), w, b)<br>    <span class="hljs-built_in">print</span>(predicate)<br><br>    plt.show()<br>    <br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Epoch: 0 Batch: 0, loss: 165.0318036522631</span><br><span class="hljs-string">Epoch: 0 Batch: 100, loss: 1936.2111196826459</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">Epoch: 199 Batch: 500, loss: 0.024829543832110872</span><br><span class="hljs-string">[88.74340551]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p><img
src="https://qiniu.hivan.me/lilithimage-20210831104443642.png?imglilith"
alt="image-20210831104443642" /></p>
<h2 id="logstic-regression">Logstic Regression</h2>
<p>Linear Regression: Regression is implemented, including the
definition of linear functions, why use linear functions, the meaning of
loss, the meaning of gradient descent, stochastic gradient descent Use
Boston house price dataset. The data set of Beijing housing prices in
2020, why didn’t I use the data set of Beijing housing prices? Boston:
room size, subway, highway, crime rate have a more obvious relationship,
so it is easier to observe the relationship Beijing's housing prices:!
Far and near! Room Condition ==》 School District! ! ! ! =&gt; Very
expensive Haidian District Harder than deep learning:</p>
<pre><code>   1. compiler
   2. programming language &amp; automata
   3. computer graphic
   4. complexity system
   5. computing complexity
   6. operating system</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_boston<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>dataset = load_boston()<br>data = dataset[<span class="hljs-string">&#x27;data&#x27;</span>]<br>target = dataset[<span class="hljs-string">&#x27;target&#x27;</span>]<br>columns = dataset[<span class="hljs-string">&#x27;feature_names&#x27;</span>]<br><br>dataframe = pd.DataFrame(data)<br>dataframe.columns = columns<br>dataframe[<span class="hljs-string">&#x27;price&#x27;</span>] = target<br><br><span class="hljs-comment"># print(dataframe.corr()) # show the correlation of dataframe variables</span><br><span class="hljs-comment"># correlation =&gt; If one value increases, it will cause another value to increase, and the correlation coefficient is closer to 1 if it increases in a certain proportion.</span><br><span class="hljs-comment"># correlation =&gt; 0 means there is no relationship between the two</span><br><span class="hljs-comment"># correlation =&gt; -1 One value increases, the other value must decrease, and the decrease is in equal proportion</span><br><br><span class="hljs-comment"># sns.heatmap(dataframe.corr())</span><br><span class="hljs-comment"># plt.show()</span><br><br><span class="hljs-comment"># RM: The average number of bedrooms in the community</span><br><span class="hljs-comment"># LSTAT: Percentage of low-income people around</span><br><br>rm = dataframe[<span class="hljs-string">&#x27;RM&#x27;</span>]<br>lstat = dataframe[<span class="hljs-string">&#x27;LSTAT&#x27;</span>]<br>price = dataframe[<span class="hljs-string">&#x27;price&#x27;</span>]<br>greater_then_most = np.percentile(price, <span class="hljs-number">66</span>)<br>dataframe[<span class="hljs-string">&#x27;expensive&#x27;</span>] = dataframe[<span class="hljs-string">&#x27;price&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">int</span>(p&gt; greater_then_most))<br>target = dataframe[<span class="hljs-string">&#x27;expensive&#x27;</span>]<br><br><span class="hljs-built_in">print</span>(dataframe[:<span class="hljs-number">20</span>])<br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">       CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \</span><br><span class="hljs-string">0   0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   </span><br><span class="hljs-string">1   0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   </span><br><span class="hljs-string">2   0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   </span><br><span class="hljs-string">3   0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   </span><br><span class="hljs-string">4   0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   </span><br><span class="hljs-string">5   0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   </span><br><span class="hljs-string">6   0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   </span><br><span class="hljs-string">7   0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   </span><br><span class="hljs-string">8   0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   </span><br><span class="hljs-string">9   0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   </span><br><span class="hljs-string">10  0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467  5.0  311.0   </span><br><span class="hljs-string">11  0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267  5.0  311.0   </span><br><span class="hljs-string">12  0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509  5.0  311.0   </span><br><span class="hljs-string">13  0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075  4.0  307.0   </span><br><span class="hljs-string">14  0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619  4.0  307.0   </span><br><span class="hljs-string">15  0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986  4.0  307.0   </span><br><span class="hljs-string">16  1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986  4.0  307.0   </span><br><span class="hljs-string">17  0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579  4.0  307.0   </span><br><span class="hljs-string">18  0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965  4.0  307.0   </span><br><span class="hljs-string">19  0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965  4.0  307.0   </span><br><span class="hljs-string"></span><br><span class="hljs-string">    PTRATIO       B  LSTAT  price  expensive  </span><br><span class="hljs-string">0      15.3  396.90   4.98   24.0          1  </span><br><span class="hljs-string">1      17.8  396.90   9.14   21.6          0  </span><br><span class="hljs-string">2      17.8  392.83   4.03   34.7          1  </span><br><span class="hljs-string">3      18.7  394.63   2.94   33.4          1  </span><br><span class="hljs-string">4      18.7  396.90   5.33   36.2          1  </span><br><span class="hljs-string">5      18.7  394.12   5.21   28.7          1  </span><br><span class="hljs-string">6      15.2  395.60  12.43   22.9          0  </span><br><span class="hljs-string">7      15.2  396.90  19.15   27.1          1  </span><br><span class="hljs-string">8      15.2  386.63  29.93   16.5          0  </span><br><span class="hljs-string">9      15.2  386.71  17.10   18.9          0  </span><br><span class="hljs-string">10     15.2  392.52  20.45   15.0          0  </span><br><span class="hljs-string">11     15.2  396.90  13.27   18.9          0  </span><br><span class="hljs-string">12     15.2  390.50  15.71   21.7          0  </span><br><span class="hljs-string">13     21.0  396.90   8.26   20.4          0  </span><br><span class="hljs-string">14     21.0  380.02  10.26   18.2          0  </span><br><span class="hljs-string">15     21.0  395.62   8.47   19.9          0  </span><br><span class="hljs-string">16     21.0  386.85   6.58   23.1          0  </span><br><span class="hljs-string">17     21.0  386.75  14.67   17.5          0  </span><br><span class="hljs-string">18     21.0  288.99  11.69   20.2          0  </span><br><span class="hljs-string">19     21.0  390.95  11.28   18.2          0  </span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">model</span>(<span class="hljs-params">x, w, b</span>):<br>    <span class="hljs-keyword">return</span> sigmoid(np.dot(x, w.T) + b)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">loss</span>(<span class="hljs-params">yhat, y</span>):<br>    <span class="hljs-keyword">return</span> -np.<span class="hljs-built_in">sum</span>(y*np.log(yhat) + (<span class="hljs-number">1</span> - y)*np.log(<span class="hljs-number">1</span> - yhat))<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_w</span>(<span class="hljs-params">x, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> np.array([np.<span class="hljs-built_in">sum</span>((yhat - y) * x[<span class="hljs-number">0</span>]), np.<span class="hljs-built_in">sum</span>((yhat - y) * x[<span class="hljs-number">1</span>])])<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">partial_b</span>(<span class="hljs-params">x, y, yhat</span>):<br>    <span class="hljs-keyword">return</span> np.<span class="hljs-built_in">sum</span>((yhat - y))<br>  <br><br>model, w, b, losses = train(model, target,loss, partial_w, partial_b)<br><br>random_test_indices = np.random.choice(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(rm)), size=<span class="hljs-number">100</span>)<br>decision_boundary = <span class="hljs-number">0.5</span><br><br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Epoch: 0 Batch: 0, loss: 5.380792320433632</span><br><span class="hljs-string">Epoch: 0 Batch: 100, loss: 4.821708458450062</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">Epoch: 199 Batch: 500, loss: 0.052809537616594626</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> random_test_indices:<br>    x1, x2, y = rm[i], lstat[i], target[i]<br>    predicate = model(np.array([x1, x2]), w, b)<br>    predicate_label = <span class="hljs-built_in">int</span>(predicate &gt; decision_boundary)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;RM: &#123;&#125;, LSTAT: &#123;&#125;, EXPENSIVE: &#123;&#125;, Predicated: &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(x1, x2, y, predicate_label))<br>    <br> <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">RM: 5.701, LSTAT: 18.35, EXPENSIVE: 0, Predicated: 0</span><br><span class="hljs-string">RM: 4.973, LSTAT: 12.64, EXPENSIVE: 0, Predicated: 0</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">RM: 6.678, LSTAT: 6.27, EXPENSIVE: 1, Predicated: 1</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h3 id="one-thing-left-is-to-check-the-accuracy-of-our-model">One thing
left is to check the accuracy of our model! !</h3>
<p>How to measure the quality of the model: 1. accuracy</p>
<ol start="2" type="1">
<li><p>precision</p></li>
<li><p>recall</p></li>
<li><p>f1, f2 score</p></li>
<li><p>AUC-ROC curve</p></li>
</ol>
<p>Introduce a very very important concept: -&gt; over-fitting and
under-fitting (over-fitting and under-fitting) The entire machine
learning process is constantly adjusting over-fitting and
under-fitting!</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Machine Learning Part-01</p><p><a href="https://hivan.me/example_03/">https://hivan.me/example_03/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-09-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-02</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/example_02/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Initial exploration of machine learning</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/cnbloggercon-20/"><span class="level-item">CnBloggerCon 2012</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/example_03/';
            this.page.identifier = 'example_03/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">168</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">20</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/"><span class="level-start"><span class="level-item">AI秘籍</span></span><span class="level-end"><span class="level-item tag">28</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-04T09:20:55.000Z">2023-09-04</time></p><p class="title"><a href="/calculus-8/">13. 微积分 - 牛顿-莱布尼兹公式、泰勒展开</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-24T07:43:45.000Z">2023-08-24</time></p><p class="title"><a href="/Math-Introduction/">茶桁的AI秘籍 - 人工智能数学基础篇 导言</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Math/">Math</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-22T05:21:59.000Z">2023-08-22</time></p><p class="title"><a href="/AI-Python-Pandas/">27. Pandas</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-21T00:41:45.000Z">2023-08-21</time></p><p class="title"><a href="/AI-Python-numpy/">26. NumPy</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-19T12:42:01.000Z">2023-08-19</time></p><p class="title"><a href="/AI-Python-matplotlib/">25. matplotlib</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>