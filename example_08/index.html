<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>RNN - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Simple RNN"><meta property="og:type" content="blog"><meta property="og:title" content="RNN"><meta property="og:url" content="https://hivan.me/example_08/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Simple RNN"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901183345054.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184030073.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184239175.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184333044.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184546617.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184606015.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184620638.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184826841.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184915753.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184958237.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901185025707.png?img"><meta property="article:published_time" content="2021-09-02T12:59:46.686Z"><meta property="article:modified_time" content="2023-06-02T04:11:12.696Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI,人工智能,代码,大语言模型"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://qiniu.hivan.me/MAMTimage-20210901183345054.png?img"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/example_08/"},"headline":"RNN","image":[],"datePublished":"2021-09-02T12:59:46.686Z","dateModified":"2023-06-02T04:11:12.696Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Simple RNN"}</script><link rel="canonical" href="https://hivan.me/example_08/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-09-02T12:59:46.686Z" title="9/2/2021, 8:59:46 PM">2021-09-02</time>发表</span><span class="level-item"><time dateTime="2023-06-02T04:11:12.696Z" title="6/2/2023, 12:11:12 PM">2023-06-02</time>更新</span><span class="level-item">18 分钟读完 (大约2679个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">RNN</h1><div class="content"><h2 id="simple-rnn">Simple RNN</h2>
<span id="more"></span>
<h3 id="define-function">Define function</h3>
<p>Import the required libraries</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># alphabet small + capital letters + &quot;.,;&#x27;&quot;</span></span><br><span class="line">ALL_LETTERS = string.ascii_letters + <span class="string">&quot;.,;&#x27;&quot;</span></span><br><span class="line">N_LETTERS = <span class="built_in">len</span>(ALL_LETTERS)</span><br></pre></td></tr></table></figure>
<p>Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">unicode_to_ascii</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span></span><br><span class="line">        <span class="keyword">and</span> c <span class="keyword">in</span> ALL_LETTERS</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="comment"># Build the category_lines dictionary, a list of names per language</span></span><br><span class="line">    category_lines = &#123;&#125;</span><br><span class="line">    all_categories = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_files</span>(<span class="params">path</span>):</span><br><span class="line">        <span class="keyword">return</span> glob.glob(path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Read a file and split into lines</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_lines</span>(<span class="params">filename</span>):</span><br><span class="line">        lines = io.<span class="built_in">open</span>(filename, encoding = <span class="string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> [unicode_to_ascii(line) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> find_files(<span class="string">&#x27;~/data/course_data/names/*.txt&#x27;</span>):</span><br><span class="line">        category = os.path.splitext(os.path.basename(filename))[<span class="number">0</span>]</span><br><span class="line">        all_categories.append(category)</span><br><span class="line"></span><br><span class="line">        lines = read_lines(filename)</span><br><span class="line">        category_lines[category] = lines</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> category_lines, all_categories</span><br></pre></td></tr></table></figure>
<p>To represent a single letter, we use a “one-hot vector” of size &lt;1 x n_letters&gt;. A one-hot vector is filled with 0s except for a 1 at index of the current letter, e.g. "b" = &lt;0 1 0 0 0 ...&gt;.</p>
<p>To make a word we join a bunch of those into a 2D matrix &lt;line_length x 1 x n_letters&gt;.</p>
<p>That extra 1 dimension is because PyTorch assumes everything is in batches - we’re just using a batch size of 1 here.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find letter index from all_letters, e.g. &quot;a&quot; = 0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">letter_to_index</span>(<span class="params">letter</span>):</span><br><span class="line">    <span class="keyword">return</span> ALL_LETTERS.find(letter)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">letter_to_tensor</span>(<span class="params">letter</span>):</span><br><span class="line">    tensor = torch.zeros(<span class="number">1</span>, N_LETTERS)</span><br><span class="line">    tensor[<span class="number">0</span>][letter_to_index(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,</span></span><br><span class="line"><span class="comment"># or an array of one-hot letter vectors</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">line_to_tensor</span>(<span class="params">line</span>):</span><br><span class="line">    tensor = torch.zeros(<span class="built_in">len</span>(line), <span class="number">1</span>, N_LETTERS)</span><br><span class="line">    <span class="keyword">for</span> i, letter <span class="keyword">in</span> <span class="built_in">enumerate</span>(line):</span><br><span class="line">        tensor[i][<span class="number">0</span>][letter_to_index(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_training_example</span>(<span class="params">category_lines, all_categories</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">random_choice</span>(<span class="params">a</span>):</span><br><span class="line">        random_idx = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(a) - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> a[random_idx]</span><br><span class="line"></span><br><span class="line">    category = random_choice(all_categories)</span><br><span class="line">    line = random_choice(category_lines[category])</span><br><span class="line">    category_tensor = torch.tensor([all_categories.index(category)], dtype = torch.long)</span><br><span class="line">    line_tensor = line_to_tensor(line)</span><br><span class="line">    <span class="keyword">return</span> category, line, category_tensor, line_tensor</span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(ALL_LETTERS)</span><br><span class="line">    <span class="built_in">print</span>(unicode_to_ascii(<span class="string">&#x27;Ślusàrski&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    category_lines, all_categories = load_data()</span><br><span class="line">    <span class="built_in">print</span>(category_lines[<span class="string">&#x27;Italian&#x27;</span>][:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(letter_to_tensor(<span class="string">&#x27;J&#x27;</span>))  <span class="comment"># [1, 57]</span></span><br><span class="line">    <span class="built_in">print</span>(line_to_tensor(<span class="string">&#x27;Jones&#x27;</span>).size())  <span class="comment"># [5, 1, 57]</span></span><br><span class="line">    </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,;&#x27;</span></span><br><span class="line"><span class="string">Slusarski</span></span><br><span class="line"><span class="string">[&#x27;Abandonato&#x27;, &#x27;Abatangelo&#x27;, &#x27;Abatantuono&#x27;, &#x27;Abate&#x27;, &#x27;Abategiovanni&#x27;]</span></span><br><span class="line"><span class="string">tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,</span></span><br><span class="line"><span class="string">         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,</span></span><br><span class="line"><span class="string">         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,</span></span><br><span class="line"><span class="string">         0., 0.]])</span></span><br><span class="line"><span class="string">torch.Size([5, 1, 56])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="second-example">Second Example</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import the required libraries</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RNN</span>(nn.Module):</span><br><span class="line">    <span class="comment"># implement RNN from scratch rather than using nn.RNN</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(RNN, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)</span><br><span class="line">        self.i2o = nn.Linear(input_size + hidden_size, output_size)</span><br><span class="line">        self.softmax = nn.LogSoftmax(dim = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_tensor, hidden_tensor</span>):</span><br><span class="line">        combined = torch.cat((input_tensor, hidden_tensor), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        hidden = self.i2h(combined)</span><br><span class="line">        output = self.i2o(combined)</span><br><span class="line">        output = self.softmax(output)</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, self.hidden_size)</span><br><span class="line"></span><br><span class="line">category_lines, all_categories = load_data()</span><br><span class="line">n_categories = <span class="built_in">len</span>(all_categories)</span><br><span class="line"></span><br><span class="line">n_hidden = <span class="number">128</span></span><br><span class="line">rnn = RNN(N_LETTERS, n_hidden, n_categories)</span><br><span class="line"></span><br><span class="line"><span class="comment"># one step</span></span><br><span class="line">input_tensor = letter_to_tensor(<span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">hidden_tensor = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(input_tensor, hidden_tensor)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br><span class="line"><span class="built_in">print</span>(next_hidden.size())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">torch.Size([1, 18])</span></span><br><span class="line"><span class="string">torch.Size([1, 128])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># whole sequence/name</span></span><br><span class="line">input_tensor = line_to_tensor(<span class="string">&#x27;Albert&#x27;</span>)</span><br><span class="line">hidden_tensor = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(input_tensor[<span class="number">0</span>], hidden_tensor)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br><span class="line"><span class="built_in">print</span>(next_hidden.size())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">torch.Size([1, 18])</span></span><br><span class="line"><span class="string">torch.Size([1, 128])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">category_from_output</span>(<span class="params">output</span>):</span><br><span class="line">    category_idx = torch.argmax(output).item()</span><br><span class="line">    <span class="keyword">return</span> all_categories[category_idx]</span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(category_from_output(output))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">German</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">learning_rate = <span class="number">0.005</span></span><br><span class="line">optimizer = torch.optim.SGD(rnn.parameters(), lr = learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">line_to_tensor, category_tensor</span>):</span><br><span class="line">    hidden = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line">        output, hidden = rnn(line_to_tensor[i], hidden)</span><br><span class="line">    </span><br><span class="line">    loss = criterion(output, category_tensor)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output, loss.item()</span><br><span class="line">  </span><br><span class="line">current_loss = <span class="number">0</span></span><br><span class="line">all_losses = []</span><br><span class="line">plot_steps, print_steps = <span class="number">1000</span>, <span class="number">5000</span></span><br><span class="line">n_iters = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)</span><br><span class="line"></span><br><span class="line">    output, loss = train(line_tensor, category_tensor)</span><br><span class="line">    current_loss += loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % plot_steps == <span class="number">0</span>:</span><br><span class="line">        all_losses.append(current_loss / plot_steps)</span><br><span class="line">        current_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % print_steps == <span class="number">0</span>:</span><br><span class="line">        guess = category_from_output(output)</span><br><span class="line">        corrent = <span class="string">&#x27;CORRECT&#x27;</span> <span class="keyword">if</span> guess == category <span class="keyword">else</span> <span class="string">f&#x27;WRONG (<span class="subst">&#123;category&#125;</span>)&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> <span class="subst">&#123;(i+<span class="number">1</span>) / n_iters *<span class="number">100</span>&#125;</span> <span class="subst">&#123;loss:<span class="number">.4</span>f&#125;</span> <span class="subst">&#123;line&#125;</span> / <span class="subst">&#123;guess&#125;</span> <span class="subst">&#123;corrent&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">5000 5.0 2.5063 Bureau / Scottish WRONG (French)</span></span><br><span class="line"><span class="string">10000 10.0 1.4726 Bitar / Arabic CORRECT</span></span><br><span class="line"><span class="string">15000 15.0 1.9405 Bazilevitch / Russian CORRECT</span></span><br><span class="line"><span class="string">20000 20.0 1.5565 Dupont / French CORRECT</span></span><br><span class="line"><span class="string">25000 25.0 0.1202 Majewski / Polish CORRECT</span></span><br><span class="line"><span class="string">30000 30.0 1.1579 Kucharova / Czech CORRECT</span></span><br><span class="line"><span class="string">35000 35.0 1.0075 Sheng / Chinese CORRECT</span></span><br><span class="line"><span class="string">40000 40.0 0.8343 Masih / Arabic CORRECT</span></span><br><span class="line"><span class="string">45000 45.0 0.5371 Fan / Chinese CORRECT</span></span><br><span class="line"><span class="string">50000 50.0 0.3260 Vinh / Vietnamese CORRECT</span></span><br><span class="line"><span class="string">55000 55.00000000000001 2.5464 Pahlke / Polish WRONG (German)</span></span><br><span class="line"><span class="string">60000 60.0 1.5921 Clark / Scottish CORRECT</span></span><br><span class="line"><span class="string">65000 65.0 4.3648 Paulis / Greek WRONG (Dutch)</span></span><br><span class="line"><span class="string">70000 70.0 1.3289 Thian / Vietnamese WRONG (Chinese)</span></span><br><span class="line"><span class="string">75000 75.0 2.2715 Kelly / English WRONG (Irish)</span></span><br><span class="line"><span class="string">80000 80.0 1.0069 Siu / Korean WRONG (Chinese)</span></span><br><span class="line"><span class="string">85000 85.0 0.8168 Kan / Chinese CORRECT</span></span><br><span class="line"><span class="string">90000 90.0 0.2283 Dinh / Vietnamese CORRECT</span></span><br><span class="line"><span class="string">95000 95.0 2.0048 Abbascia / Japanese WRONG (Italian)</span></span><br><span class="line"><span class="string">100000 100.0 0.6310 O&#x27;Shea / Irish CORRECT</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(all_losses)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901183345054.png?img" alt="image-20210901183345054" /><figcaption aria-hidden="true">image-20210901183345054</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">input_line</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;\n &gt; <span class="subst">&#123;input_line&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        line_tensor = line_to_tensor(input_line)</span><br><span class="line"></span><br><span class="line">        hidden = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line">            output, hidden = rnn(line_tensor[i], hidden)</span><br><span class="line"></span><br><span class="line">        guess = category_from_output(output)</span><br><span class="line">        <span class="built_in">print</span>(guess)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    sentence = <span class="built_in">input</span>(<span class="string">&#x27;Input: &#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> sentence == <span class="string">&#x27;quit&#x27;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    predict(sentence)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> &gt; Chinese</span></span><br><span class="line"><span class="string">Irish</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> &gt; English</span></span><br><span class="line"><span class="string">English</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> &gt; Japanese</span></span><br><span class="line"><span class="string">French</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> &gt; French</span></span><br><span class="line"><span class="string">German</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="lstm-modeling-trigonometric-functions">LSTM Modeling trigonometric functions</h2>
<h3 id="use-lstm-to-fit-sine-and-cosine-functions">Use LSTM to fit sine and cosine functions</h3>
<ol type="1">
<li>Use numpy to build time series data based on sine function</li>
<li>Use keras to build a simple regression network, mainly using the LSTM network structure to fit the periodicity of the sine function, and visualize the fitted sine function image and the real function image</li>
</ol>
<h4 id="related-knowledge-points">Related knowledge points</h4>
<ol type="1">
<li>Time series data construction and forecasting</li>
<li>Time series model building, training, evaluation and visualization based on keras LSTM</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import necessary libraries</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build data</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build a model</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Input</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="comment"># Printing progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualization</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>
<h4 id="construct-a-data-set">1. Construct a data set</h4>
<p>This module will use numpy to construct time series data. There are two main steps:</p>
<ol type="1">
<li>Define the sine function (cosine function)</li>
<li>Select historical data window size to construct time series data</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ground_func</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    sine / cosine function</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: numpy.ndarray</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        sin(x) or cos(x)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y = np.sin(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_data</span>(<span class="params">sequence_data, n_steps</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use sine function data to build X, y</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        sine_data: numpy.ndarray</span></span><br><span class="line"><span class="string">        n_steps: history data window size</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        X: numpy.ndarray, y: numpy.ndarray</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># init</span></span><br><span class="line">    X, y = [], []</span><br><span class="line"></span><br><span class="line">    seq_len = <span class="built_in">len</span>(sequence_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(seq_len), total=seq_len):</span><br><span class="line">        end_idx = start_idx + n_steps</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> end_idx &gt;= seq_len:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        cur_x = sequence_data[start_idx: end_idx]</span><br><span class="line">        cur_y = sequence_data[end_idx]</span><br><span class="line"></span><br><span class="line">        X.append(cur_x)</span><br><span class="line">        y.append(cur_y)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    X = X.reshape(*X.shape, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Construct the original sine/cosine function sequence</span></span><br><span class="line">xaxis = np.arange(-<span class="number">50</span> * np.pi, <span class="number">50</span> * np.pi, <span class="number">0.1</span>)</span><br><span class="line">sequence_data = ground_func(xaxis)</span><br><span class="line"><span class="built_in">len</span>(sequence_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Take 1000 data for visualization</span></span><br><span class="line">plt.figure(figsize = (<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">plt.plot(xaxis[:<span class="number">1000</span>], sequence_data[:<span class="number">1000</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184030073.png?img" alt="image-20210901184030073" /><figcaption aria-hidden="true">image-20210901184030073</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">20</span></span><br><span class="line">X, y = build_data(sequence_data, n_steps)</span><br><span class="line">X.shape, y.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> 99%|█████████▉| 3122/3142 [00:00&lt;00:00, 1557955.63it/s]</span></span><br><span class="line"><span class="string">((3122, 20, 1), (3122,))</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="build-the-model">2. Build the model</h4>
<p>This module builds a timing model based on the LSTM and Dense layer in keras. The following points need to be noted: 1. Choose the right hidden size 2. Choose a suitable activation function, such as relu, tanh 3. The optimizer chooses sgd, adam, etc. 3. The loss function chooses cross entropy loss function (cross_entropy) or mean square error (mse), etc.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Build a LSTM model fit sine/cosine function.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    hints: </span></span><br><span class="line"><span class="string">        1. a LSTM fit time pattern (ref: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)</span></span><br><span class="line"><span class="string">        2. a Dense for regression (ref: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Input(shape = (<span class="number">20</span>, <span class="number">1</span>)))</span><br><span class="line">    model.add(LSTM(<span class="number">32</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;adam&#x27;</span>, loss = <span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize the model and print related information</span></span><br><span class="line">model = create_model()</span><br><span class="line">model.summary()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Instructions for updating:</span></span><br><span class="line"><span class="string">Call initializer instance with the dtype argument instead of passing it to the constructor</span></span><br><span class="line"><span class="string">Model: &quot;sequential&quot;</span></span><br><span class="line"><span class="string">_________________________________________________________________</span></span><br><span class="line"><span class="string">Layer (type)                 Output Shape              Param #   </span></span><br><span class="line"><span class="string">=================================================================</span></span><br><span class="line"><span class="string">lstm (LSTM)                  (None, 32)                4352      </span></span><br><span class="line"><span class="string">_________________________________________________________________</span></span><br><span class="line"><span class="string">dense (Dense)                (None, 1)                 33        </span></span><br><span class="line"><span class="string">=================================================================</span></span><br><span class="line"><span class="string">Total params: 4,385</span></span><br><span class="line"><span class="string">Trainable params: 4,385</span></span><br><span class="line"><span class="string">Non-trainable params: 0</span></span><br><span class="line"><span class="string">_________________________________________________________________</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="model-training">3. Model training</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Try to change epochs and add callbacks, such as EarlyStopping (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)</span></span><br><span class="line">history = model.fit(X, y, batch_size = <span class="number">32</span>, epochs = <span class="number">25</span>, verbose = <span class="number">1</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>], label=<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend(loc =<span class="string">&#x27;upper right&#x27;</span>) <span class="comment"># draw the loss image</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Instructions for updating:</span></span><br><span class="line"><span class="string">Use tf.where in 2.0, which has the same broadcast rule as np.where</span></span><br><span class="line"><span class="string">Epoch 1/25</span></span><br><span class="line"><span class="string">3122/3122 [==============================] - 4s 1ms/sample - loss: 0.1433</span></span><br><span class="line"><span class="string">Epoch 2/25</span></span><br><span class="line"><span class="string">3122/3122 [==============================] - 3s 879us/sample - loss: 0.0072</span></span><br><span class="line"><span class="string">show more (open the raw output data in a text editor) ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Epoch 25/25</span></span><br><span class="line"><span class="string">3122/3122 [==============================] - 3s 858us/sample - loss: 2.2191e-05</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184239175.png?img" alt="image-20210901184239175" /><figcaption aria-hidden="true">image-20210901184239175</figcaption>
</figure>
<h4 id="forecast">4. Forecast</h4>
<p>This module uses a function different from the training data to construct test data to verify the generalization performance of the model. The main steps are as follows: 1. Define a new function (sine/cosine) 2. Use the trained model to make predictions 3. Visually compare model prediction results with real values</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_func</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    sine/cosine function, different from ground_func above.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: numpy.ndarray</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        sin(x) or cos(x)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y = np.cos(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line">  </span><br><span class="line">test_xaxis = np.arange(<span class="number">0</span>, <span class="number">10</span> * np.pi, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">test_sequence_data = test_func(test_xaxis)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the initial n_steps of historical data to start forecasting, and the subsequent data will use the predicted data as historical data for further forecasting</span></span><br><span class="line">y_preds = test_sequence_data[:n_steps]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step by step forecast</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(test_xaxis)-n_steps)):</span><br><span class="line">    model_input = y_preds[i: i+n_steps]</span><br><span class="line">    model_input = model_input.reshape((<span class="number">1</span>, n_steps, <span class="number">1</span>))</span><br><span class="line">    y_pred = model.predict(model_input, verbose = <span class="number">0</span>)</span><br><span class="line">    y_pred = np.append(y_preds, y_pred)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(test_xaxis[n_steps:], y_preds[n_steps:], label =<span class="string">&#x27;predictions&#x27;</span>)</span><br><span class="line">plt.plot(test_xaxis, test_sequence_data, label =<span class="string">&#x27;ground truth&#x27;</span>)</span><br><span class="line">plt.plot(test_xaxis[:n_steps], y_preds[:n_steps], label =<span class="string">&#x27;initial sequence&#x27;</span>, color =<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend(loc =<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.ylim(-<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">100%|██████████| 295/295 [00:01&lt;00:00, 183.91it/s]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184333044.png?img" alt="image-20210901184333044" /><figcaption aria-hidden="true">image-20210901184333044</figcaption>
</figure>
<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>
<p><a target="_blank" rel="noopener" href="https://github.com/hivandu/practise/blob/master/AI_core_competence/Basic%20ability/ex08_Recurrent_Neural_Networks.ipynb">source</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">timeserise_revenue = pd.read_csv(<span class="string">&#x27;~/data/course_data/time_serise_revenue.csv&#x27;</span>)</span><br><span class="line">sales_data = pd.read_csv(<span class="string">&#x27;~/data/course_data/time_serise_sale.csv&#x27;</span>)</span><br><span class="line">timeserise_revenue.head()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	Unnamed: 0	day_1	day_2	day_3	day_4	day_5	day_6	day_7	day_8	day_9	...	day_51	day_52	day_53	day_54	day_55	day_56	day_57	day_58	day_59	day_60</span></span><br><span class="line"><span class="string">0	0	2.622866	2.657832	2.771121	2.815845	2.876267	2.859229	2.844758	2.793797	2.736443	...	1.228701	1.290414	1.474886	1.563295	1.736197	1.797285	1.978940	2.198979	2.277908	2.403300</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">4	4	1.702631	1.825995	2.038047	2.194083	2.313903	2.417883	2.567613	2.650782	2.729691	...	1.258760	1.137150	1.109007	1.104999	1.150137	1.204513	1.221350	1.327023	1.387304	1.557363</span></span><br><span class="line"><span class="string">5 rows × 61 columns</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_from_table</span>(<span class="params">sample_size, dataframe</span>):</span><br><span class="line">    sample_row = dataframe.sample().values[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    begin_column = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(sample_row) - sample_size - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (sample_row[begin_column: begin_column + sample_size],</span><br><span class="line">            sample_row[begin_column + <span class="number">1</span>: begin_column + sample_size + <span class="number">1</span>])</span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math, random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment"># Generating a noisy multi-sin wave</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FullyConnected</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x_size, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(FullyConnected, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.linear_with_tanh = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">10</span>, self.hidden_size),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(self.hidden_size, self.hidden_size),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(self.hidden_size, output_size)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        yhat = self.linear_with_tanh(x)</span><br><span class="line">        <span class="keyword">return</span> yhat</span><br><span class="line">      </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleRNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x_size, hidden_size, n_layers, batch_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        <span class="comment"># self.inp = nn.Linear(1, hidden_size)</span></span><br><span class="line">        self.rnn = nn.RNN(x_size, hidden_size, n_layers, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size) <span class="comment"># 10 in and 10 out</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, hidden=<span class="literal">None</span></span>):</span><br><span class="line">        hidden = self.__init__hidden()</span><br><span class="line">        <span class="comment"># print(&#x27;Forward hidden &#123;&#125;&#x27;.format(hidden.shape))</span></span><br><span class="line">        <span class="comment"># print(&#x27;Forward inps &#123;&#125;&#x27;.format(inputs.shape))</span></span><br><span class="line">        output, hidden = self.rnn(inputs.<span class="built_in">float</span>(), hidden.<span class="built_in">float</span>())</span><br><span class="line">        <span class="comment"># print(&#x27;Out1 &#123;&#125;&#x27;.format(output.shape))</span></span><br><span class="line">        output = self.out(output.<span class="built_in">float</span>())</span><br><span class="line">        <span class="comment"># print(&#x27;Forward outputs &#123;&#125;&#x27;.format(output.shape))</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__hidden</span>(<span class="params">self</span>):</span><br><span class="line">        hidden = torch.zeros(self.n_layers, self.batch_size, self.hidden_size, dtype = torch.float64)</span><br><span class="line">        <span class="keyword">return</span> hidden</span><br><span class="line">      </span><br><span class="line"><span class="comment"># Set dataset</span></span><br><span class="line">source_data = sales_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully Connected Model</span></span><br><span class="line">n_epochs = <span class="number">100</span></span><br><span class="line">n_iters= <span class="number">50</span></span><br><span class="line">hidden_size = <span class="number">2</span> <span class="comment"># try to change this parameters</span></span><br><span class="line">n_layers = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">seq_length = <span class="number">10</span></span><br><span class="line">n_sample_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">x_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">fc_model = FullyConnected(x_size, hidden_size, output_size = seq_length)</span><br><span class="line">fc_model = fc_model.double()</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(fc_model.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">losses = np.zeros(n_epochs)</span><br><span class="line"></span><br><span class="line">plt.imshow(fc_model.state_dict()[<span class="string">&#x27;linear_with_tanh.0.weight&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184546617.png?img" alt="image-20210901184546617" /><figcaption aria-hidden="true">image-20210901184546617</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="keyword">for</span> iter_ <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">        _inputs, _targets = sample_from_table(n_sample_size, source_data)</span><br><span class="line"></span><br><span class="line">        inputs = Variable(torch.from_numpy(np.array([_inputs[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _inputs[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _inputs[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _inputs[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _inputs[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)))</span><br><span class="line"></span><br><span class="line">        targets = Variable(torch.from_numpy(np.array([_targets[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _targets[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _targets[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _targets[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _targets[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)))</span><br><span class="line">        </span><br><span class="line">        outputs = fc_model(inputs.double())</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        losses[epoch] += loss</span><br><span class="line">        <span class="keyword">if</span> iter_ % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            plt.clf()</span><br><span class="line">            plt.ion()</span><br><span class="line">            plt.title(<span class="string">&#x27;Epoch &#123;&#125;, iter &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, iter_))</span><br><span class="line">            plt.plot(torch.flatten(outputs.detach()), <span class="string">&#x27;r-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Output&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(targets), <span class="string">&#x27;c-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Label&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(inputs), <span class="string">&#x27;g-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Input&#x27;</span>)</span><br><span class="line">            plt.draw()</span><br><span class="line">            plt.pause(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184606015.png?img" alt="image-20210901184606015" /><figcaption aria-hidden="true">image-20210901184606015</figcaption>
</figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184620638.png?img" alt="image-20210901184620638" /><figcaption aria-hidden="true">image-20210901184620638</figcaption>
</figure>
<blockquote>
<p>A total of 5 * 99 pictures were rendered in the middle, so I won’t show them one by one.</p>
</blockquote>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184826841.png?img" alt="image-20210901184826841" /><figcaption aria-hidden="true">image-20210901184826841</figcaption>
</figure>
<h3 id="rnn-model">RNN Model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">100</span></span><br><span class="line">n_iters = <span class="number">50</span></span><br><span class="line">hidden_size = <span class="number">2</span> <span class="comment"># try to change this parameters</span></span><br><span class="line">n_layers = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">seq_length = <span class="number">10</span></span><br><span class="line">n_sample_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">x_size = <span class="number">1</span></span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">rnn_model = SimpleRNN(x_size, hidden_size, n_layers, <span class="built_in">int</span>(n_sample_size / seq_length), output_size)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(rnn_model.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">losses = np.zeros(n_epochs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">        _inputs, _targets = sample_from_table(n_sample_size, source_data)</span><br><span class="line"></span><br><span class="line">        inputs = Variable(torch.from_numpy(np.array([_inputs[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _inputs[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _inputs[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _inputs[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _inputs[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)).unsqueeze(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        targets = Variable(torch.from_numpy(np.array([_targets[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _targets[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _targets[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _targets[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _targets[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)).unsqueeze(<span class="number">2</span>).<span class="built_in">float</span>())  <span class="comment"># [49] </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(&#x27;Inputs &#123;&#125;, targets &#123;&#125;&#x27;.format(inputs.shape, targets.shape))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Use teacher forcing 50% of the time</span></span><br><span class="line">        <span class="comment"># force = random.random() &lt; 0.5</span></span><br><span class="line">        outputs, hidden = rnn_model(inputs.double(), <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        losses[epoch] += loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">iter</span> % <span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">            plt.clf()</span><br><span class="line">            plt.ion()</span><br><span class="line">            plt.title(<span class="string">&#x27;Epoch &#123;&#125;, iter &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, <span class="built_in">iter</span>))</span><br><span class="line">            plt.plot(torch.flatten(outputs.detach()), <span class="string">&#x27;r-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Output&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(targets), <span class="string">&#x27;c-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Label&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(inputs), <span class="string">&#x27;g-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Input&#x27;</span>)</span><br><span class="line">            plt.draw()</span><br><span class="line">            plt.pause(<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if epoch &gt; 0:</span></span><br><span class="line"><span class="comment">#     print(epoch, loss)</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184915753.png?img" alt="image-20210901184915753" /><figcaption aria-hidden="true">image-20210901184915753</figcaption>
</figure>
<blockquote>
<p>A total of 5 * 99 pictures were rendered in the middle, so I won’t show them one by one.</p>
</blockquote>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901184958237.png?img" alt="image-20210901184958237" /><figcaption aria-hidden="true">image-20210901184958237</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(losses[<span class="number">20</span>:])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/MAMTimage-20210901185025707.png?img" alt="image-20210901185025707" /><figcaption aria-hidden="true">image-20210901185025707</figcaption>
</figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>RNN</p><p><a href="https://hivan.me/example_08/">https://hivan.me/example_08/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-09-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-02</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/example_06/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Machine Learning Part-04</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/example_03/"><span class="level-item">Machine Learning Part-01</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/example_08/';
            this.page.identifier = 'example_08/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">139</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">14</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-02T09:14:18.000Z">2023-06-02</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/">使用链式调用简化多步提示语</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-28T09:50:41.000Z">2023-05-28</time></p><p class="title"><a href="/Use-AI-to-write-a-snake-game/">利用AI写一个『贪吃蛇游戏』</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-28T09:17:32.000Z">2023-05-28</time></p><p class="title"><a href="/Use-multi-step-prompts-to-ask-AI-to-write-tests-for-you/">13 使用多步提示语让AI帮你写测试</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-26T09:15:54.000Z">2023-05-26</time></p><p class="title"><a href="/AI-create-a-excel-plugin/">12 AI帮你写个小插件，轻松处理Excel文件</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-20T09:14:42.000Z">2023-05-20</time></p><p class="title"><a href="/Save-costs-with-an-open-source-model/">11 用好开源模型节约成本</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>