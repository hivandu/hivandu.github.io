<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>茶桁.MAMT</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="RNNSimple RNN">
<meta property="og:type" content="article">
<meta property="og:title" content="茶桁.MAMT">
<meta property="og:url" content="https://hivan.me/example_08/index.html">
<meta property="og:site_name" content="茶桁.MAMT">
<meta property="og:description" content="RNNSimple RNN">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901183345054.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184030073.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184239175.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184333044.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184546617.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184606015.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184620638.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184826841.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184915753.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901184958237.png?img">
<meta property="og:image" content="http://qiniu.hivan.me/MAMTimage-20210901185025707.png?img">
<meta property="article:published_time" content="2021-09-02T12:59:46.686Z">
<meta property="article:modified_time" content="2023-06-01T07:59:21.653Z">
<meta property="article:author" content="Hivan Du">
<meta property="article:tag" content="AI,人工智能,代码,大语言模型">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://qiniu.hivan.me/MAMTimage-20210901183345054.png?img">
  
    <link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">茶桁.MAMT</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">ChaHeng Notes，codding and writting ~</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://hivan.me"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-example_08" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/example_08/" class="article-date">
  <time class="dt-published" datetime="2021-09-02T12:59:46.686Z" itemprop="datePublished">2021-09-02</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="Simple-RNN"><a href="#Simple-RNN" class="headerlink" title="Simple RNN"></a>Simple RNN</h2><span id="more"></span>
<h3 id="Define-function"><a href="#Define-function" class="headerlink" title="Define function"></a>Define function</h3><p>Import the required libraries</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> unicodedata</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> random</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># alphabet small + capital letters + &quot;.,;&#x27;&quot;</span></span><br><span class="line">ALL_LETTERS = string.ascii_letters + <span class="string">&quot;.,;&#x27;&quot;</span></span><br><span class="line">N_LETTERS = <span class="built_in">len</span>(ALL_LETTERS)</span><br></pre></td></tr></table></figure>

<p>Turn a Unicode string to plain ASCII, thanks to <a target="_blank" rel="noopener" href="https://stackoverflow.com/a/518232/2809427">https://stackoverflow.com/a/518232/2809427</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">unicode_to_ascii</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;&#x27;</span>.join(</span><br><span class="line">        c <span class="keyword">for</span> c <span class="keyword">in</span> unicodedata.normalize(<span class="string">&#x27;NFD&#x27;</span>, s)</span><br><span class="line">        <span class="keyword">if</span> unicodedata.category(c) != <span class="string">&#x27;Mn&#x27;</span></span><br><span class="line">        <span class="keyword">and</span> c <span class="keyword">in</span> ALL_LETTERS</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>():</span><br><span class="line">    <span class="comment"># Build the category_lines dictionary, a list of names per language</span></span><br><span class="line">    category_lines = &#123;&#125;</span><br><span class="line">    all_categories = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">find_files</span>(<span class="params">path</span>):</span><br><span class="line">        <span class="keyword">return</span> glob.glob(path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Read a file and split into lines</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">read_lines</span>(<span class="params">filename</span>):</span><br><span class="line">        lines = io.<span class="built_in">open</span>(filename, encoding = <span class="string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> [unicode_to_ascii(line) <span class="keyword">for</span> line <span class="keyword">in</span> lines]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> find_files(<span class="string">&#x27;~/data/course_data/names/*.txt&#x27;</span>):</span><br><span class="line">        category = os.path.splitext(os.path.basename(filename))[<span class="number">0</span>]</span><br><span class="line">        all_categories.append(category)</span><br><span class="line"></span><br><span class="line">        lines = read_lines(filename)</span><br><span class="line">        category_lines[category] = lines</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> category_lines, all_categories</span><br></pre></td></tr></table></figure>

<p>To represent a single letter, we use a “one-hot vector” of  size &lt;1 x n_letters&gt;. A one-hot vector is filled with 0s except for a 1 at index of the current letter, e.g. “b” &#x3D; &lt;0 1 0 0 0 …&gt;.</p>
<p>To make a word we join a bunch of those into a 2D matrix &lt;line_length x 1 x n_letters&gt;.</p>
<p>That extra 1 dimension is because PyTorch assumes everything is in batches - we’re just using a batch size of 1 here.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find letter index from all_letters, e.g. &quot;a&quot; = 0</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">letter_to_index</span>(<span class="params">letter</span>):</span><br><span class="line">    <span class="keyword">return</span> ALL_LETTERS.find(letter)</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">letter_to_tensor</span>(<span class="params">letter</span>):</span><br><span class="line">    tensor = torch.zeros(<span class="number">1</span>, N_LETTERS)</span><br><span class="line">    tensor[<span class="number">0</span>][letter_to_index(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,</span></span><br><span class="line"><span class="comment"># or an array of one-hot letter vectors</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">line_to_tensor</span>(<span class="params">line</span>):</span><br><span class="line">    tensor = torch.zeros(<span class="built_in">len</span>(line), <span class="number">1</span>, N_LETTERS)</span><br><span class="line">    <span class="keyword">for</span> i, letter <span class="keyword">in</span> <span class="built_in">enumerate</span>(line):</span><br><span class="line">        tensor[i][<span class="number">0</span>][letter_to_index(letter)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tensor</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">random_training_example</span>(<span class="params">category_lines, all_categories</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">random_choice</span>(<span class="params">a</span>):</span><br><span class="line">        random_idx = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(a) - <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> a[random_idx]</span><br><span class="line"></span><br><span class="line">    category = random_choice(all_categories)</span><br><span class="line">    line = random_choice(category_lines[category])</span><br><span class="line">    category_tensor = torch.tensor([all_categories.index(category)], dtype = torch.long)</span><br><span class="line">    line_tensor = line_to_tensor(line)</span><br><span class="line">    <span class="keyword">return</span> category, line, category_tensor, line_tensor</span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="built_in">print</span>(ALL_LETTERS)</span><br><span class="line">    <span class="built_in">print</span>(unicode_to_ascii(<span class="string">&#x27;Ślusàrski&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    category_lines, all_categories = load_data()</span><br><span class="line">    <span class="built_in">print</span>(category_lines[<span class="string">&#x27;Italian&#x27;</span>][:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(letter_to_tensor(<span class="string">&#x27;J&#x27;</span>))  <span class="comment"># [1, 57]</span></span><br><span class="line">    <span class="built_in">print</span>(line_to_tensor(<span class="string">&#x27;Jones&#x27;</span>).size())  <span class="comment"># [5, 1, 57]</span></span><br><span class="line">    </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,;&#x27;</span></span><br><span class="line"><span class="string">Slusarski</span></span><br><span class="line"><span class="string">[&#x27;Abandonato&#x27;, &#x27;Abatangelo&#x27;, &#x27;Abatantuono&#x27;, &#x27;Abate&#x27;, &#x27;Abategiovanni&#x27;]</span></span><br><span class="line"><span class="string">tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,</span></span><br><span class="line"><span class="string">         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,</span></span><br><span class="line"><span class="string">         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,</span></span><br><span class="line"><span class="string">         0., 0.]])</span></span><br><span class="line"><span class="string">torch.Size([5, 1, 56])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>



<h3 id="Second-Example"><a href="#Second-Example" class="headerlink" title="Second Example"></a>Second Example</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import the required libraries</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RNN</span>(nn.Module):</span><br><span class="line">    <span class="comment"># implement RNN from scratch rather than using nn.RNN</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(RNN, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)</span><br><span class="line">        self.i2o = nn.Linear(input_size + hidden_size, output_size)</span><br><span class="line">        self.softmax = nn.LogSoftmax(dim = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, input_tensor, hidden_tensor</span>):</span><br><span class="line">        combined = torch.cat((input_tensor, hidden_tensor), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        hidden = self.i2h(combined)</span><br><span class="line">        output = self.i2o(combined)</span><br><span class="line">        output = self.softmax(output)</span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">init_hidden</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.zeros(<span class="number">1</span>, self.hidden_size)</span><br><span class="line"></span><br><span class="line">category_lines, all_categories = load_data()</span><br><span class="line">n_categories = <span class="built_in">len</span>(all_categories)</span><br><span class="line"></span><br><span class="line">n_hidden = <span class="number">128</span></span><br><span class="line">rnn = RNN(N_LETTERS, n_hidden, n_categories)</span><br><span class="line"></span><br><span class="line"><span class="comment"># one step</span></span><br><span class="line">input_tensor = letter_to_tensor(<span class="string">&#x27;A&#x27;</span>)</span><br><span class="line">hidden_tensor = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(input_tensor, hidden_tensor)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br><span class="line"><span class="built_in">print</span>(next_hidden.size())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">torch.Size([1, 18])</span></span><br><span class="line"><span class="string">torch.Size([1, 128])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># whole sequence/name</span></span><br><span class="line">input_tensor = line_to_tensor(<span class="string">&#x27;Albert&#x27;</span>)</span><br><span class="line">hidden_tensor = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">output, next_hidden = rnn(input_tensor[<span class="number">0</span>], hidden_tensor)</span><br><span class="line"><span class="built_in">print</span>(output.size())</span><br><span class="line"><span class="built_in">print</span>(next_hidden.size())</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">torch.Size([1, 18])</span></span><br><span class="line"><span class="string">torch.Size([1, 128])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">category_from_output</span>(<span class="params">output</span>):</span><br><span class="line">    category_idx = torch.argmax(output).item()</span><br><span class="line">    <span class="keyword">return</span> all_categories[category_idx]</span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(category_from_output(output))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">German</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">learning_rate = <span class="number">0.005</span></span><br><span class="line">optimizer = torch.optim.SGD(rnn.parameters(), lr = learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">line_to_tensor, category_tensor</span>):</span><br><span class="line">    hidden = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line">        output, hidden = rnn(line_to_tensor[i], hidden)</span><br><span class="line">    </span><br><span class="line">    loss = criterion(output, category_tensor)</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output, loss.item()</span><br><span class="line">  </span><br><span class="line">current_loss = <span class="number">0</span></span><br><span class="line">all_losses = []</span><br><span class="line">plot_steps, print_steps = <span class="number">1000</span>, <span class="number">5000</span></span><br><span class="line">n_iters = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)</span><br><span class="line"></span><br><span class="line">    output, loss = train(line_tensor, category_tensor)</span><br><span class="line">    current_loss += loss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % plot_steps == <span class="number">0</span>:</span><br><span class="line">        all_losses.append(current_loss / plot_steps)</span><br><span class="line">        current_loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % print_steps == <span class="number">0</span>:</span><br><span class="line">        guess = category_from_output(output)</span><br><span class="line">        corrent = <span class="string">&#x27;CORRECT&#x27;</span> <span class="keyword">if</span> guess == category <span class="keyword">else</span> <span class="string">f&#x27;WRONG (<span class="subst">&#123;category&#125;</span>)&#x27;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;i+<span class="number">1</span>&#125;</span> <span class="subst">&#123;(i+<span class="number">1</span>) / n_iters *<span class="number">100</span>&#125;</span> <span class="subst">&#123;loss:<span class="number">.4</span>f&#125;</span> <span class="subst">&#123;line&#125;</span> / <span class="subst">&#123;guess&#125;</span> <span class="subst">&#123;corrent&#125;</span>&#x27;</span>)</span><br><span class="line">        </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">5000 5.0 2.5063 Bureau / Scottish WRONG (French)</span></span><br><span class="line"><span class="string">10000 10.0 1.4726 Bitar / Arabic CORRECT</span></span><br><span class="line"><span class="string">15000 15.0 1.9405 Bazilevitch / Russian CORRECT</span></span><br><span class="line"><span class="string">20000 20.0 1.5565 Dupont / French CORRECT</span></span><br><span class="line"><span class="string">25000 25.0 0.1202 Majewski / Polish CORRECT</span></span><br><span class="line"><span class="string">30000 30.0 1.1579 Kucharova / Czech CORRECT</span></span><br><span class="line"><span class="string">35000 35.0 1.0075 Sheng / Chinese CORRECT</span></span><br><span class="line"><span class="string">40000 40.0 0.8343 Masih / Arabic CORRECT</span></span><br><span class="line"><span class="string">45000 45.0 0.5371 Fan / Chinese CORRECT</span></span><br><span class="line"><span class="string">50000 50.0 0.3260 Vinh / Vietnamese CORRECT</span></span><br><span class="line"><span class="string">55000 55.00000000000001 2.5464 Pahlke / Polish WRONG (German)</span></span><br><span class="line"><span class="string">60000 60.0 1.5921 Clark / Scottish CORRECT</span></span><br><span class="line"><span class="string">65000 65.0 4.3648 Paulis / Greek WRONG (Dutch)</span></span><br><span class="line"><span class="string">70000 70.0 1.3289 Thian / Vietnamese WRONG (Chinese)</span></span><br><span class="line"><span class="string">75000 75.0 2.2715 Kelly / English WRONG (Irish)</span></span><br><span class="line"><span class="string">80000 80.0 1.0069 Siu / Korean WRONG (Chinese)</span></span><br><span class="line"><span class="string">85000 85.0 0.8168 Kan / Chinese CORRECT</span></span><br><span class="line"><span class="string">90000 90.0 0.2283 Dinh / Vietnamese CORRECT</span></span><br><span class="line"><span class="string">95000 95.0 2.0048 Abbascia / Japanese WRONG (Italian)</span></span><br><span class="line"><span class="string">100000 100.0 0.6310 O&#x27;Shea / Irish CORRECT</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(all_losses)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901183345054.png?img" alt="image-20210901183345054"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">input_line</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;\n &gt; <span class="subst">&#123;input_line&#125;</span>&#x27;</span>)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        line_tensor = line_to_tensor(input_line)</span><br><span class="line"></span><br><span class="line">        hidden = rnn.init_hidden()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(line_tensor.size()[<span class="number">0</span>]):</span><br><span class="line">            output, hidden = rnn(line_tensor[i], hidden)</span><br><span class="line"></span><br><span class="line">        guess = category_from_output(output)</span><br><span class="line">        <span class="built_in">print</span>(guess)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    sentence = <span class="built_in">input</span>(<span class="string">&#x27;Input: &#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> sentence == <span class="string">&#x27;quit&#x27;</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    predict(sentence)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> &gt; Chinese</span></span><br><span class="line"><span class="string">Irish</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> &gt; English</span></span><br><span class="line"><span class="string">English</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> &gt; Japanese</span></span><br><span class="line"><span class="string">French</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> &gt; French</span></span><br><span class="line"><span class="string">German</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>



<h2 id="LSTM-Modeling-trigonometric-functions"><a href="#LSTM-Modeling-trigonometric-functions" class="headerlink" title="LSTM Modeling trigonometric functions"></a>LSTM Modeling trigonometric functions</h2><h3 id="Use-LSTM-to-fit-sine-and-cosine-functions"><a href="#Use-LSTM-to-fit-sine-and-cosine-functions" class="headerlink" title="Use LSTM to fit sine and cosine functions"></a>Use LSTM to fit sine and cosine functions</h3><ol>
<li>Use numpy to build time series data based on sine function</li>
<li>Use keras to build a simple regression network, mainly using the LSTM network structure to fit the periodicity of the sine function, and visualize the fitted sine function image and the real function image</li>
</ol>
<h4 id="Related-knowledge-points"><a href="#Related-knowledge-points" class="headerlink" title="Related knowledge points"></a>Related knowledge points</h4><ol>
<li>Time series data construction and forecasting</li>
<li>Time series model building, training, evaluation and visualization based on keras LSTM</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import necessary libraries</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Build data</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build a model</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Input</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="comment"># Printing progress bar</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualization</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<h4 id="1-Construct-a-data-set"><a href="#1-Construct-a-data-set" class="headerlink" title="1. Construct a data set"></a>1. Construct a data set</h4><p>This module will use numpy to construct time series data. There are two main steps:</p>
<ol>
<li>Define the sine function (cosine function)</li>
<li>Select historical data window size to construct time series data</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ground_func</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    sine / cosine function</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: numpy.ndarray</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        sin(x) or cos(x)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y = np.sin(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build_data</span>(<span class="params">sequence_data, n_steps</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Use sine function data to build X, y</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        sine_data: numpy.ndarray</span></span><br><span class="line"><span class="string">        n_steps: history data window size</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        X: numpy.ndarray, y: numpy.ndarray</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># init</span></span><br><span class="line">    X, y = [], []</span><br><span class="line"></span><br><span class="line">    seq_len = <span class="built_in">len</span>(sequence_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> start_idx <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(seq_len), total=seq_len):</span><br><span class="line">        end_idx = start_idx + n_steps</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> end_idx &gt;= seq_len:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        cur_x = sequence_data[start_idx: end_idx]</span><br><span class="line">        cur_y = sequence_data[end_idx]</span><br><span class="line"></span><br><span class="line">        X.append(cur_x)</span><br><span class="line">        y.append(cur_y)</span><br><span class="line"></span><br><span class="line">    X = np.array(X)</span><br><span class="line">    y = np.array(y)</span><br><span class="line"></span><br><span class="line">    X = X.reshape(*X.shape, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> X, y</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Construct the original sine/cosine function sequence</span></span><br><span class="line">xaxis = np.arange(-<span class="number">50</span> * np.pi, <span class="number">50</span> * np.pi, <span class="number">0.1</span>)</span><br><span class="line">sequence_data = ground_func(xaxis)</span><br><span class="line"><span class="built_in">len</span>(sequence_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Take 1000 data for visualization</span></span><br><span class="line">plt.figure(figsize = (<span class="number">20</span>, <span class="number">8</span>))</span><br><span class="line">plt.plot(xaxis[:<span class="number">1000</span>], sequence_data[:<span class="number">1000</span>])</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184030073.png?img" alt="image-20210901184030073"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">n_steps = <span class="number">20</span></span><br><span class="line">X, y = build_data(sequence_data, n_steps)</span><br><span class="line">X.shape, y.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> 99%|█████████▉| 3122/3142 [00:00&lt;00:00, 1557955.63it/s]</span></span><br><span class="line"><span class="string">((3122, 20, 1), (3122,))</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="2-Build-the-model"><a href="#2-Build-the-model" class="headerlink" title="2. Build the model"></a>2. Build the model</h4><p>This module builds a timing model based on the LSTM and Dense layer in keras. The following points need to be noted:</p>
<ol>
<li>Choose the right hidden size</li>
<li>Choose a suitable activation function, such as relu, tanh</li>
<li>The optimizer chooses sgd, adam, etc.</li>
<li>The loss function chooses cross entropy loss function (cross_entropy) or mean square error (mse), etc.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">create_model</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Build a LSTM model fit sine/cosine function.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    hints: </span></span><br><span class="line"><span class="string">        1. a LSTM fit time pattern (ref: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)</span></span><br><span class="line"><span class="string">        2. a Dense for regression (ref: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model = Sequential()</span><br><span class="line">    model.add(Input(shape = (<span class="number">20</span>, <span class="number">1</span>)))</span><br><span class="line">    model.add(LSTM(<span class="number">32</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.add(Dense(<span class="number">1</span>, activation=<span class="string">&#x27;tanh&#x27;</span>))</span><br><span class="line">    model.<span class="built_in">compile</span>(optimizer = <span class="string">&#x27;adam&#x27;</span>, loss = <span class="string">&#x27;mse&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize the model and print related information</span></span><br><span class="line">model = create_model()</span><br><span class="line">model.summary()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Instructions for updating:</span></span><br><span class="line"><span class="string">Call initializer instance with the dtype argument instead of passing it to the constructor</span></span><br><span class="line"><span class="string">Model: &quot;sequential&quot;</span></span><br><span class="line"><span class="string">_________________________________________________________________</span></span><br><span class="line"><span class="string">Layer (type)                 Output Shape              Param #   </span></span><br><span class="line"><span class="string">=================================================================</span></span><br><span class="line"><span class="string">lstm (LSTM)                  (None, 32)                4352      </span></span><br><span class="line"><span class="string">_________________________________________________________________</span></span><br><span class="line"><span class="string">dense (Dense)                (None, 1)                 33        </span></span><br><span class="line"><span class="string">=================================================================</span></span><br><span class="line"><span class="string">Total params: 4,385</span></span><br><span class="line"><span class="string">Trainable params: 4,385</span></span><br><span class="line"><span class="string">Non-trainable params: 0</span></span><br><span class="line"><span class="string">_________________________________________________________________</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3-Model-training"><a href="#3-Model-training" class="headerlink" title="3. Model training"></a>3. Model training</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Try to change epochs and add callbacks, such as EarlyStopping (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)</span></span><br><span class="line">history = model.fit(X, y, batch_size = <span class="number">32</span>, epochs = <span class="number">25</span>, verbose = <span class="number">1</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>], label=<span class="string">&#x27;loss&#x27;</span>)</span><br><span class="line">plt.legend(loc =<span class="string">&#x27;upper right&#x27;</span>) <span class="comment"># draw the loss image</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Instructions for updating:</span></span><br><span class="line"><span class="string">Use tf.where in 2.0, which has the same broadcast rule as np.where</span></span><br><span class="line"><span class="string">Epoch 1/25</span></span><br><span class="line"><span class="string">3122/3122 [==============================] - 4s 1ms/sample - loss: 0.1433</span></span><br><span class="line"><span class="string">Epoch 2/25</span></span><br><span class="line"><span class="string">3122/3122 [==============================] - 3s 879us/sample - loss: 0.0072</span></span><br><span class="line"><span class="string">show more (open the raw output data in a text editor) ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Epoch 25/25</span></span><br><span class="line"><span class="string">3122/3122 [==============================] - 3s 858us/sample - loss: 2.2191e-05</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184239175.png?img" alt="image-20210901184239175"></p>
<h4 id="4-Forecast"><a href="#4-Forecast" class="headerlink" title="4. Forecast"></a>4. Forecast</h4><p>This module uses a function different from the training data to construct test data to verify the generalization performance of the model. The main steps are as follows:</p>
<ol>
<li>Define a new function (sine&#x2F;cosine)</li>
<li>Use the trained model to make predictions</li>
<li>Visually compare model prediction results with real values</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">test_func</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    sine/cosine function, different from ground_func above.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: numpy.ndarray</span></span><br><span class="line"><span class="string">    return:</span></span><br><span class="line"><span class="string">        sin(x) or cos(x)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    y = np.cos(x)</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line">  </span><br><span class="line">test_xaxis = np.arange(<span class="number">0</span>, <span class="number">10</span> * np.pi, <span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">test_sequence_data = test_func(test_xaxis)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use the initial n_steps of historical data to start forecasting, and the subsequent data will use the predicted data as historical data for further forecasting</span></span><br><span class="line">y_preds = test_sequence_data[:n_steps]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step by step forecast</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(<span class="built_in">len</span>(test_xaxis)-n_steps)):</span><br><span class="line">    model_input = y_preds[i: i+n_steps]</span><br><span class="line">    model_input = model_input.reshape((<span class="number">1</span>, n_steps, <span class="number">1</span>))</span><br><span class="line">    y_pred = model.predict(model_input, verbose = <span class="number">0</span>)</span><br><span class="line">    y_pred = np.append(y_preds, y_pred)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">10</span>,<span class="number">8</span>))</span><br><span class="line">plt.plot(test_xaxis[n_steps:], y_preds[n_steps:], label =<span class="string">&#x27;predictions&#x27;</span>)</span><br><span class="line">plt.plot(test_xaxis, test_sequence_data, label =<span class="string">&#x27;ground truth&#x27;</span>)</span><br><span class="line">plt.plot(test_xaxis[:n_steps], y_preds[:n_steps], label =<span class="string">&#x27;initial sequence&#x27;</span>, color =<span class="string">&#x27;red&#x27;</span>)</span><br><span class="line">plt.legend(loc =<span class="string">&#x27;upper left&#x27;</span>)</span><br><span class="line">plt.ylim(-<span class="number">2</span>,<span class="number">2</span>)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">100%|██████████| 295/295 [00:01&lt;00:00, 183.91it/s]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184333044.png?img" alt="image-20210901184333044"></p>
<h2 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h2><p><a target="_blank" rel="noopener" href="https://github.com/hivandu/practise/blob/master/AI_core_competence/Basic%20ability/ex08_Recurrent_Neural_Networks.ipynb">source</a> </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># load data</span></span><br><span class="line">timeserise_revenue = pd.read_csv(<span class="string">&#x27;~/data/course_data/time_serise_revenue.csv&#x27;</span>)</span><br><span class="line">sales_data = pd.read_csv(<span class="string">&#x27;~/data/course_data/time_serise_sale.csv&#x27;</span>)</span><br><span class="line">timeserise_revenue.head()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	Unnamed: 0	day_1	day_2	day_3	day_4	day_5	day_6	day_7	day_8	day_9	...	day_51	day_52	day_53	day_54	day_55	day_56	day_57	day_58	day_59	day_60</span></span><br><span class="line"><span class="string">0	0	2.622866	2.657832	2.771121	2.815845	2.876267	2.859229	2.844758	2.793797	2.736443	...	1.228701	1.290414	1.474886	1.563295	1.736197	1.797285	1.978940	2.198979	2.277908	2.403300</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">4	4	1.702631	1.825995	2.038047	2.194083	2.313903	2.417883	2.567613	2.650782	2.729691	...	1.258760	1.137150	1.109007	1.104999	1.150137	1.204513	1.221350	1.327023	1.387304	1.557363</span></span><br><span class="line"><span class="string">5 rows × 61 columns</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_from_table</span>(<span class="params">sample_size, dataframe</span>):</span><br><span class="line">    sample_row = dataframe.sample().values[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    begin_column = random.randint(<span class="number">0</span>, <span class="built_in">len</span>(sample_row) - sample_size - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (sample_row[begin_column: begin_column + sample_size],</span><br><span class="line">            sample_row[begin_column + <span class="number">1</span>: begin_column + sample_size + <span class="number">1</span>])</span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math, random</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="comment"># Generating a noisy multi-sin wave</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FullyConnected</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x_size, hidden_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(FullyConnected, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line"></span><br><span class="line">        self.linear_with_tanh = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">10</span>, self.hidden_size),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(self.hidden_size, self.hidden_size),</span><br><span class="line">            nn.Tanh(),</span><br><span class="line">            nn.Linear(self.hidden_size, output_size)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        yhat = self.linear_with_tanh(x)</span><br><span class="line">        <span class="keyword">return</span> yhat</span><br><span class="line">      </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleRNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x_size, hidden_size, n_layers, batch_size, output_size</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.n_layers = n_layers</span><br><span class="line">        self.batch_size = batch_size</span><br><span class="line">        <span class="comment"># self.inp = nn.Linear(1, hidden_size)</span></span><br><span class="line">        self.rnn = nn.RNN(x_size, hidden_size, n_layers, batch_first=<span class="literal">True</span>)</span><br><span class="line">        self.out = nn.Linear(hidden_size, output_size) <span class="comment"># 10 in and 10 out</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, hidden=<span class="literal">None</span></span>):</span><br><span class="line">        hidden = self.__init__hidden()</span><br><span class="line">        <span class="comment"># print(&#x27;Forward hidden &#123;&#125;&#x27;.format(hidden.shape))</span></span><br><span class="line">        <span class="comment"># print(&#x27;Forward inps &#123;&#125;&#x27;.format(inputs.shape))</span></span><br><span class="line">        output, hidden = self.rnn(inputs.<span class="built_in">float</span>(), hidden.<span class="built_in">float</span>())</span><br><span class="line">        <span class="comment"># print(&#x27;Out1 &#123;&#125;&#x27;.format(output.shape))</span></span><br><span class="line">        output = self.out(output.<span class="built_in">float</span>())</span><br><span class="line">        <span class="comment"># print(&#x27;Forward outputs &#123;&#125;&#x27;.format(output.shape))</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> output, hidden</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__hidden</span>(<span class="params">self</span>):</span><br><span class="line">        hidden = torch.zeros(self.n_layers, self.batch_size, self.hidden_size, dtype = torch.float64)</span><br><span class="line">        <span class="keyword">return</span> hidden</span><br><span class="line">      </span><br><span class="line"><span class="comment"># Set dataset</span></span><br><span class="line">source_data = sales_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fully Connected Model</span></span><br><span class="line">n_epochs = <span class="number">100</span></span><br><span class="line">n_iters= <span class="number">50</span></span><br><span class="line">hidden_size = <span class="number">2</span> <span class="comment"># try to change this parameters</span></span><br><span class="line">n_layers = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">seq_length = <span class="number">10</span></span><br><span class="line">n_sample_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">x_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">fc_model = FullyConnected(x_size, hidden_size, output_size = seq_length)</span><br><span class="line">fc_model = fc_model.double()</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(fc_model.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">losses = np.zeros(n_epochs)</span><br><span class="line"></span><br><span class="line">plt.imshow(fc_model.state_dict()[<span class="string">&#x27;linear_with_tanh.0.weight&#x27;</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184546617.png?img" alt="image-20210901184546617"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="keyword">for</span> iter_ <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">        _inputs, _targets = sample_from_table(n_sample_size, source_data)</span><br><span class="line"></span><br><span class="line">        inputs = Variable(torch.from_numpy(np.array([_inputs[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _inputs[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _inputs[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _inputs[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _inputs[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)))</span><br><span class="line"></span><br><span class="line">        targets = Variable(torch.from_numpy(np.array([_targets[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _targets[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _targets[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _targets[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _targets[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)))</span><br><span class="line">        </span><br><span class="line">        outputs = fc_model(inputs.double())</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        losses[epoch] += loss</span><br><span class="line">        <span class="keyword">if</span> iter_ % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            plt.clf()</span><br><span class="line">            plt.ion()</span><br><span class="line">            plt.title(<span class="string">&#x27;Epoch &#123;&#125;, iter &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, iter_))</span><br><span class="line">            plt.plot(torch.flatten(outputs.detach()), <span class="string">&#x27;r-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Output&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(targets), <span class="string">&#x27;c-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Label&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(inputs), <span class="string">&#x27;g-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Input&#x27;</span>)</span><br><span class="line">            plt.draw()</span><br><span class="line">            plt.pause(<span class="number">0.05</span>)</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184606015.png?img" alt="image-20210901184606015"></p>
<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184620638.png?img" alt="image-20210901184620638"></p>
<blockquote>
<p>A total of 5 * 99 pictures were rendered in the middle, so I won’t show them one by one.</p>
</blockquote>
<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184826841.png?img" alt="image-20210901184826841"></p>
<h3 id="RNN-Model"><a href="#RNN-Model" class="headerlink" title="RNN Model"></a>RNN Model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">n_epochs = <span class="number">100</span></span><br><span class="line">n_iters = <span class="number">50</span></span><br><span class="line">hidden_size = <span class="number">2</span> <span class="comment"># try to change this parameters</span></span><br><span class="line">n_layers = <span class="number">2</span></span><br><span class="line">batch_size = <span class="number">5</span></span><br><span class="line">seq_length = <span class="number">10</span></span><br><span class="line">n_sample_size = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">x_size = <span class="number">1</span></span><br><span class="line">output_size = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">rnn_model = SimpleRNN(x_size, hidden_size, n_layers, <span class="built_in">int</span>(n_sample_size / seq_length), output_size)</span><br><span class="line"></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = optim.SGD(rnn_model.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">losses = np.zeros(n_epochs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">iter</span> <span class="keyword">in</span> <span class="built_in">range</span>(n_iters):</span><br><span class="line">        _inputs, _targets = sample_from_table(n_sample_size, source_data)</span><br><span class="line"></span><br><span class="line">        inputs = Variable(torch.from_numpy(np.array([_inputs[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _inputs[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _inputs[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _inputs[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _inputs[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)).unsqueeze(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">        targets = Variable(torch.from_numpy(np.array([_targets[<span class="number">0</span>:<span class="number">10</span>],</span><br><span class="line">                                                    _targets[<span class="number">10</span>:<span class="number">20</span>],</span><br><span class="line">                                                    _targets[<span class="number">20</span>:<span class="number">30</span>],</span><br><span class="line">                                                    _targets[<span class="number">30</span>:<span class="number">40</span>],</span><br><span class="line">                                                    _targets[<span class="number">40</span>:<span class="number">50</span>]],</span><br><span class="line">                                                    dtype = np.double)).unsqueeze(<span class="number">2</span>).<span class="built_in">float</span>())  <span class="comment"># [49] </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(&#x27;Inputs &#123;&#125;, targets &#123;&#125;&#x27;.format(inputs.shape, targets.shape))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Use teacher forcing 50% of the time</span></span><br><span class="line">        <span class="comment"># force = random.random() &lt; 0.5</span></span><br><span class="line">        outputs, hidden = rnn_model(inputs.double(), <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        losses[epoch] += loss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">iter</span> % <span class="number">10</span> ==<span class="number">0</span>:</span><br><span class="line">            plt.clf()</span><br><span class="line">            plt.ion()</span><br><span class="line">            plt.title(<span class="string">&#x27;Epoch &#123;&#125;, iter &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch, <span class="built_in">iter</span>))</span><br><span class="line">            plt.plot(torch.flatten(outputs.detach()), <span class="string">&#x27;r-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Output&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(targets), <span class="string">&#x27;c-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Label&#x27;</span>)</span><br><span class="line">            plt.plot(torch.flatten(inputs), <span class="string">&#x27;g-&#x27;</span>, linewidth = <span class="number">1</span>, label = <span class="string">&#x27;Input&#x27;</span>)</span><br><span class="line">            plt.draw()</span><br><span class="line">            plt.pause(<span class="number">0.05</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># if epoch &gt; 0:</span></span><br><span class="line"><span class="comment">#     print(epoch, loss)</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184915753.png?img" alt="image-20210901184915753"></p>
<blockquote>
<p>A total of 5 * 99 pictures were rendered in the middle, so I won’t show them one by one.</p>
</blockquote>
<p><img src="http://qiniu.hivan.me/MAMTimage-20210901184958237.png?img" alt="image-20210901184958237"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(losses[<span class="number">20</span>:])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/MAMTimage-20210901185025707.png?img" alt="image-20210901185025707"></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hivan.me/example_08/" data-id="clid1n2wi004c2nj7fmntdx1c" data-title="" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/example_09/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          (no title)
        
      </div>
    </a>
  
  
    <a href="/example_06/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title"></div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/develop/">develop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/software/">software</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ChatGPT/" rel="tag">ChatGPT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chrome/" rel="tag">Chrome</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gmail/" rel="tag">Gmail</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google/" rel="tag">Google</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google-Plus/" rel="tag">Google Plus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gplus/" rel="tag">Gplus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mac/" rel="tag">Mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mail/" rel="tag">Mail</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Model/" rel="tag">Model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NFC/" rel="tag">NFC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/O2O/" rel="tag">O2O</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PS/" rel="tag">PS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QQ/" rel="tag">QQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SNS/" rel="tag">SNS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Stable-Diffusion/" rel="tag">Stable Diffusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Translate/" rel="tag">Translate</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/allove/" rel="tag">allove</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/app/" rel="tag">app</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/avn/" rel="tag">avn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/" rel="tag">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bluehost/" rel="tag">bluehost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/" rel="tag">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/css/" rel="tag">css</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/device/" rel="tag">device</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/feed/" rel="tag">feed</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flickr/" rel="tag">flickr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/forward/" rel="tag">forward</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gmail/" rel="tag">gmail</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/habari/" rel="tag">habari</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ifttt/" rel="tag">ifttt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/install/" rel="tag">install</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ireader/" rel="tag">ireader</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/istef/" rel="tag">istef</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/javascript/" rel="tag">javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/location/" rel="tag">location</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/more/" rel="tag">more</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/net/" rel="tag">net</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nitrous/" rel="tag">nitrous</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node/" rel="tag">node</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pageflakes/" rel="tag">pageflakes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/picasaweb/" rel="tag">picasaweb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plugin/" rel="tag">plugin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reader/" rel="tag">reader</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/research/" rel="tag">research</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/search/" rel="tag">search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sms/" rel="tag">sms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/telnet/" rel="tag">telnet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/twitter/" rel="tag">twitter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/url/" rel="tag">url</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/version/" rel="tag">version</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/windows-8/" rel="tag">windows 8</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wordpress/" rel="tag">wordpress</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%96%E7%95%8C%E6%9D%AF/" rel="tag">世界杯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E5%8D%9A/" rel="tag">微博</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E5%8C%BA/" rel="tag">时区</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A4%BE%E4%BA%A4/" rel="tag">社交</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8A%B1%E5%84%BF%E5%BC%80%E4%BA%86/" rel="tag">花儿开了</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A1%A8%E6%83%85/" rel="tag">表情</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/" rel="tag">过滤器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%9B%E5%BA%A6/" rel="tag">进度</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 20px;">AI</a> <a href="/tags/ChatGPT/" style="font-size: 10px;">ChatGPT</a> <a href="/tags/Chrome/" style="font-size: 10px;">Chrome</a> <a href="/tags/Gmail/" style="font-size: 10px;">Gmail</a> <a href="/tags/Google/" style="font-size: 18px;">Google</a> <a href="/tags/Google-Plus/" style="font-size: 10px;">Google Plus</a> <a href="/tags/Gplus/" style="font-size: 10px;">Gplus</a> <a href="/tags/Mac/" style="font-size: 10px;">Mac</a> <a href="/tags/Mail/" style="font-size: 10px;">Mail</a> <a href="/tags/Model/" style="font-size: 10px;">Model</a> <a href="/tags/NFC/" style="font-size: 10px;">NFC</a> <a href="/tags/O2O/" style="font-size: 10px;">O2O</a> <a href="/tags/PS/" style="font-size: 10px;">PS</a> <a href="/tags/Python/" style="font-size: 16px;">Python</a> <a href="/tags/QQ/" style="font-size: 10px;">QQ</a> <a href="/tags/SNS/" style="font-size: 10px;">SNS</a> <a href="/tags/Stable-Diffusion/" style="font-size: 12px;">Stable Diffusion</a> <a href="/tags/Tool/" style="font-size: 10px;">Tool</a> <a href="/tags/Translate/" style="font-size: 10px;">Translate</a> <a href="/tags/allove/" style="font-size: 10px;">allove</a> <a href="/tags/app/" style="font-size: 10px;">app</a> <a href="/tags/avn/" style="font-size: 10px;">avn</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/bluehost/" style="font-size: 10px;">bluehost</a> <a href="/tags/code/" style="font-size: 10px;">code</a> <a href="/tags/css/" style="font-size: 10px;">css</a> <a href="/tags/device/" style="font-size: 10px;">device</a> <a href="/tags/feed/" style="font-size: 10px;">feed</a> <a href="/tags/flickr/" style="font-size: 10px;">flickr</a> <a href="/tags/forward/" style="font-size: 10px;">forward</a> <a href="/tags/gmail/" style="font-size: 10px;">gmail</a> <a href="/tags/habari/" style="font-size: 16px;">habari</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/ifttt/" style="font-size: 12px;">ifttt</a> <a href="/tags/install/" style="font-size: 10px;">install</a> <a href="/tags/ireader/" style="font-size: 10px;">ireader</a> <a href="/tags/istef/" style="font-size: 10px;">istef</a> <a href="/tags/javascript/" style="font-size: 10px;">javascript</a> <a href="/tags/location/" style="font-size: 10px;">location</a> <a href="/tags/more/" style="font-size: 10px;">more</a> <a href="/tags/net/" style="font-size: 10px;">net</a> <a href="/tags/nitrous/" style="font-size: 10px;">nitrous</a> <a href="/tags/node/" style="font-size: 10px;">node</a> <a href="/tags/pageflakes/" style="font-size: 10px;">pageflakes</a> <a href="/tags/picasaweb/" style="font-size: 10px;">picasaweb</a> <a href="/tags/plugin/" style="font-size: 10px;">plugin</a> <a href="/tags/reader/" style="font-size: 10px;">reader</a> <a href="/tags/research/" style="font-size: 10px;">research</a> <a href="/tags/search/" style="font-size: 10px;">search</a> <a href="/tags/sms/" style="font-size: 10px;">sms</a> <a href="/tags/telnet/" style="font-size: 10px;">telnet</a> <a href="/tags/twitter/" style="font-size: 12px;">twitter</a> <a href="/tags/url/" style="font-size: 10px;">url</a> <a href="/tags/version/" style="font-size: 10px;">version</a> <a href="/tags/windows-8/" style="font-size: 10px;">windows 8</a> <a href="/tags/wordpress/" style="font-size: 14px;">wordpress</a> <a href="/tags/%E4%B8%96%E7%95%8C%E6%9D%AF/" style="font-size: 10px;">世界杯</a> <a href="/tags/%E5%BE%AE%E5%8D%9A/" style="font-size: 10px;">微博</a> <a href="/tags/%E6%97%B6%E5%8C%BA/" style="font-size: 10px;">时区</a> <a href="/tags/%E7%A4%BE%E4%BA%A4/" style="font-size: 10px;">社交</a> <a href="/tags/%E8%8A%B1%E5%84%BF%E5%BC%80%E4%BA%86/" style="font-size: 10px;">花儿开了</a> <a href="/tags/%E8%A1%A8%E6%83%85/" style="font-size: 10px;">表情</a> <a href="/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/" style="font-size: 10px;">过滤器</a> <a href="/tags/%E8%BF%9B%E5%BA%A6/" style="font-size: 10px;">进度</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">四月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">三月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">十二月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">八月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/03/">三月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/07/">七月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/04/">四月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/01/">一月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/11/">十一月 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/10/">十月 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/07/">七月 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/12/">十二月 2010</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/04/">四月 2010</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/10/">十月 2009</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/02/">二月 2009</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2008/06/">六月 2008</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/10/">十月 2006</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/09/">九月 2006</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/06/">六月 2006</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/Use-AI-to-write-a-snake-game/">利用AI写一个『贪吃蛇游戏』</a>
          </li>
        
          <li>
            <a href="/Use-multi-step-prompts-to-ask-AI-to-write-tests-for-you/">13 使用多步提示语让AI帮你写测试</a>
          </li>
        
          <li>
            <a href="/AI-create-a-excel-plugin/">12 AI帮你写个小插件，轻松处理Excel文件</a>
          </li>
        
          <li>
            <a href="/Save-costs-with-an-open-source-model/">11 用好开源模型节约成本</a>
          </li>
        
          <li>
            <a href="/Use-AI-to-index-and-analyze-documents-and-images/">10 利用AI索引并分析文献和图片</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Hivan Du<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>