<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>RNN - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Simple RNN"><meta property="og:type" content="blog"><meta property="og:title" content="RNN"><meta property="og:url" content="https://hivan.me/example_08/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Simple RNN"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901183345054.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184030073.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184239175.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184333044.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184546617.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184606015.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184620638.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184826841.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184915753.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901184958237.png?img"><meta property="og:image" content="https://qiniu.hivan.me/MAMTimage-20210901185025707.png?img"><meta property="article:published_time" content="2021-09-02T12:59:46.686Z"><meta property="article:modified_time" content="2023-06-02T04:11:12.696Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI,人工智能,代码,大语言模型"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://qiniu.hivan.me/MAMTimage-20210901183345054.png?img"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/example_08/"},"headline":"RNN","image":[],"datePublished":"2021-09-02T12:59:46.686Z","dateModified":"2023-06-02T04:11:12.696Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Simple RNN"}</script><link rel="canonical" href="https://hivan.me/example_08/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-09-02T12:59:46.686Z" title="9/2/2021, 8:59:46 PM">2021-09-02</time>发表</span></div></div><h1 class="title is-3 is-size-4-mobile">RNN</h1><div class="content"><h2 id="simple-rnn">Simple RNN</h2>
<span id="more"></span>
<h3 id="define-function">Define function</h3>
<p>Import the required libraries</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> io<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> unicodedata<br><span class="hljs-keyword">import</span> string<br><span class="hljs-keyword">import</span> glob<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> random<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># alphabet small + capital letters + &quot;.,;&#x27;&quot;</span><br>ALL_LETTERS = string.ascii_letters + <span class="hljs-string">&quot;.,;&#x27;&quot;</span><br>N_LETTERS = <span class="hljs-built_in">len</span>(ALL_LETTERS)<br></code></pre></td></tr></table></figure>
<p>Turn a Unicode string to plain ASCII, thanks to
https://stackoverflow.com/a/518232/2809427</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">unicode_to_ascii</span>(<span class="hljs-params">s</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;&#x27;</span>.join(<br>        c <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> unicodedata.normalize(<span class="hljs-string">&#x27;NFD&#x27;</span>, s)<br>        <span class="hljs-keyword">if</span> unicodedata.category(c) != <span class="hljs-string">&#x27;Mn&#x27;</span><br>        <span class="hljs-keyword">and</span> c <span class="hljs-keyword">in</span> ALL_LETTERS<br>    )<br></code></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_data</span>():<br>    <span class="hljs-comment"># Build the category_lines dictionary, a list of names per language</span><br>    category_lines = &#123;&#125;<br>    all_categories = []<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">find_files</span>(<span class="hljs-params">path</span>):<br>        <span class="hljs-keyword">return</span> glob.glob(path)<br><br>    <span class="hljs-comment"># Read a file and split into lines</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">read_lines</span>(<span class="hljs-params">filename</span>):<br>        lines = io.<span class="hljs-built_in">open</span>(filename, encoding = <span class="hljs-string">&#x27;utf-8&#x27;</span>).read().strip().split(<span class="hljs-string">&#x27;\n&#x27;</span>)<br>        <span class="hljs-keyword">return</span> [unicode_to_ascii(line) <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines]<br><br>    <span class="hljs-keyword">for</span> filename <span class="hljs-keyword">in</span> find_files(<span class="hljs-string">&#x27;~/data/course_data/names/*.txt&#x27;</span>):<br>        category = os.path.splitext(os.path.basename(filename))[<span class="hljs-number">0</span>]<br>        all_categories.append(category)<br><br>        lines = read_lines(filename)<br>        category_lines[category] = lines<br><br>    <span class="hljs-keyword">return</span> category_lines, all_categories<br></code></pre></td></tr></table></figure>
<p>To represent a single letter, we use a “one-hot vector” of size &lt;1
x n_letters&gt;. A one-hot vector is filled with 0s except for a 1 at
index of the current letter, e.g. "b" = &lt;0 1 0 0 0 ...&gt;.</p>
<p>To make a word we join a bunch of those into a 2D matrix
&lt;line_length x 1 x n_letters&gt;.</p>
<p>That extra 1 dimension is because PyTorch assumes everything is in
batches - we’re just using a batch size of 1 here.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Find letter index from all_letters, e.g. &quot;a&quot; = 0</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">letter_to_index</span>(<span class="hljs-params">letter</span>):<br>    <span class="hljs-keyword">return</span> ALL_LETTERS.find(letter)<br>  <br><span class="hljs-comment"># Just for demonstration, turn a letter into a &lt;1 x n_letters&gt; Tensor</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">letter_to_tensor</span>(<span class="hljs-params">letter</span>):<br>    tensor = torch.zeros(<span class="hljs-number">1</span>, N_LETTERS)<br>    tensor[<span class="hljs-number">0</span>][letter_to_index(letter)] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> tensor<br>  <br><span class="hljs-comment"># Turn a line into a &lt;line_length x 1 x n_letters&gt;,</span><br><span class="hljs-comment"># or an array of one-hot letter vectors</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">line_to_tensor</span>(<span class="hljs-params">line</span>):<br>    tensor = torch.zeros(<span class="hljs-built_in">len</span>(line), <span class="hljs-number">1</span>, N_LETTERS)<br>    <span class="hljs-keyword">for</span> i, letter <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(line):<br>        tensor[i][<span class="hljs-number">0</span>][letter_to_index(letter)] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> tensor<br>  <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_training_example</span>(<span class="hljs-params">category_lines, all_categories</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">random_choice</span>(<span class="hljs-params">a</span>):<br>        random_idx = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(a) - <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> a[random_idx]<br><br>    category = random_choice(all_categories)<br>    line = random_choice(category_lines[category])<br>    category_tensor = torch.tensor([all_categories.index(category)], dtype = torch.long)<br>    line_tensor = line_to_tensor(line)<br>    <span class="hljs-keyword">return</span> category, line, category_tensor, line_tensor<br>  <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    <span class="hljs-built_in">print</span>(ALL_LETTERS)<br>    <span class="hljs-built_in">print</span>(unicode_to_ascii(<span class="hljs-string">&#x27;Ślusàrski&#x27;</span>))<br><br>    category_lines, all_categories = load_data()<br>    <span class="hljs-built_in">print</span>(category_lines[<span class="hljs-string">&#x27;Italian&#x27;</span>][:<span class="hljs-number">5</span>])<br><br>    <span class="hljs-built_in">print</span>(letter_to_tensor(<span class="hljs-string">&#x27;J&#x27;</span>))  <span class="hljs-comment"># [1, 57]</span><br>    <span class="hljs-built_in">print</span>(line_to_tensor(<span class="hljs-string">&#x27;Jones&#x27;</span>).size())  <span class="hljs-comment"># [5, 1, 57]</span><br>    <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ.,;&#x27;</span><br><span class="hljs-string">Slusarski</span><br><span class="hljs-string">[&#x27;Abandonato&#x27;, &#x27;Abatangelo&#x27;, &#x27;Abatantuono&#x27;, &#x27;Abate&#x27;, &#x27;Abategiovanni&#x27;]</span><br><span class="hljs-string">tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,</span><br><span class="hljs-string">         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,</span><br><span class="hljs-string">         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,</span><br><span class="hljs-string">         0., 0.]])</span><br><span class="hljs-string">torch.Size([5, 1, 56])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h3 id="second-example">Second Example</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Import the required libraries</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RNN</span>(nn.Module):<br>    <span class="hljs-comment"># implement RNN from scratch rather than using nn.RNN</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(RNN, self).__init__()<br>        <br>        self.hidden_size = hidden_size<br>        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)<br>        self.i2o = nn.Linear(input_size + hidden_size, output_size)<br>        self.softmax = nn.LogSoftmax(dim = <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_tensor, hidden_tensor</span>):<br>        combined = torch.cat((input_tensor, hidden_tensor), <span class="hljs-number">1</span>)<br><br>        hidden = self.i2h(combined)<br>        output = self.i2o(combined)<br>        output = self.softmax(output)<br>        <span class="hljs-keyword">return</span> output, hidden<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_hidden</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> torch.zeros(<span class="hljs-number">1</span>, self.hidden_size)<br><br>category_lines, all_categories = load_data()<br>n_categories = <span class="hljs-built_in">len</span>(all_categories)<br><br>n_hidden = <span class="hljs-number">128</span><br>rnn = RNN(N_LETTERS, n_hidden, n_categories)<br><br><span class="hljs-comment"># one step</span><br>input_tensor = letter_to_tensor(<span class="hljs-string">&#x27;A&#x27;</span>)<br>hidden_tensor = rnn.init_hidden()<br><br>output, next_hidden = rnn(input_tensor, hidden_tensor)<br><span class="hljs-built_in">print</span>(output.size())<br><span class="hljs-built_in">print</span>(next_hidden.size())<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">torch.Size([1, 18])</span><br><span class="hljs-string">torch.Size([1, 128])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># whole sequence/name</span><br>input_tensor = line_to_tensor(<span class="hljs-string">&#x27;Albert&#x27;</span>)<br>hidden_tensor = rnn.init_hidden()<br><br>output, next_hidden = rnn(input_tensor[<span class="hljs-number">0</span>], hidden_tensor)<br><span class="hljs-built_in">print</span>(output.size())<br><span class="hljs-built_in">print</span>(next_hidden.size())<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">torch.Size([1, 18])</span><br><span class="hljs-string">torch.Size([1, 128])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">category_from_output</span>(<span class="hljs-params">output</span>):<br>    category_idx = torch.argmax(output).item()<br>    <span class="hljs-keyword">return</span> all_categories[category_idx]<br>  <br><span class="hljs-built_in">print</span>(category_from_output(output))<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">German</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>criterion = nn.NLLLoss()<br>learning_rate = <span class="hljs-number">0.005</span><br>optimizer = torch.optim.SGD(rnn.parameters(), lr = learning_rate)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">line_to_tensor, category_tensor</span>):<br>    hidden = rnn.init_hidden()<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(line_tensor.size()[<span class="hljs-number">0</span>]):<br>        output, hidden = rnn(line_to_tensor[i], hidden)<br>    <br>    loss = criterion(output, category_tensor)<br><br>    optimizer.zero_grad()<br>    loss.backward()<br>    optimizer.step()<br><br>    <span class="hljs-keyword">return</span> output, loss.item()<br>  <br>current_loss = <span class="hljs-number">0</span><br>all_losses = []<br>plot_steps, print_steps = <span class="hljs-number">1000</span>, <span class="hljs-number">5000</span><br>n_iters = <span class="hljs-number">100000</span><br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iters):<br>    category, line, category_tensor, line_tensor = random_training_example(category_lines, all_categories)<br><br>    output, loss = train(line_tensor, category_tensor)<br>    current_loss += loss<br><br>    <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % plot_steps == <span class="hljs-number">0</span>:<br>        all_losses.append(current_loss / plot_steps)<br>        current_loss = <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">if</span> (i + <span class="hljs-number">1</span>) % print_steps == <span class="hljs-number">0</span>:<br>        guess = category_from_output(output)<br>        corrent = <span class="hljs-string">&#x27;CORRECT&#x27;</span> <span class="hljs-keyword">if</span> guess == category <span class="hljs-keyword">else</span> <span class="hljs-string">f&#x27;WRONG (<span class="hljs-subst">&#123;category&#125;</span>)&#x27;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;i+<span class="hljs-number">1</span>&#125;</span> <span class="hljs-subst">&#123;(i+<span class="hljs-number">1</span>) / n_iters *<span class="hljs-number">100</span>&#125;</span> <span class="hljs-subst">&#123;loss:<span class="hljs-number">.4</span>f&#125;</span> <span class="hljs-subst">&#123;line&#125;</span> / <span class="hljs-subst">&#123;guess&#125;</span> <span class="hljs-subst">&#123;corrent&#125;</span>&#x27;</span>)<br>        <br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">5000 5.0 2.5063 Bureau / Scottish WRONG (French)</span><br><span class="hljs-string">10000 10.0 1.4726 Bitar / Arabic CORRECT</span><br><span class="hljs-string">15000 15.0 1.9405 Bazilevitch / Russian CORRECT</span><br><span class="hljs-string">20000 20.0 1.5565 Dupont / French CORRECT</span><br><span class="hljs-string">25000 25.0 0.1202 Majewski / Polish CORRECT</span><br><span class="hljs-string">30000 30.0 1.1579 Kucharova / Czech CORRECT</span><br><span class="hljs-string">35000 35.0 1.0075 Sheng / Chinese CORRECT</span><br><span class="hljs-string">40000 40.0 0.8343 Masih / Arabic CORRECT</span><br><span class="hljs-string">45000 45.0 0.5371 Fan / Chinese CORRECT</span><br><span class="hljs-string">50000 50.0 0.3260 Vinh / Vietnamese CORRECT</span><br><span class="hljs-string">55000 55.00000000000001 2.5464 Pahlke / Polish WRONG (German)</span><br><span class="hljs-string">60000 60.0 1.5921 Clark / Scottish CORRECT</span><br><span class="hljs-string">65000 65.0 4.3648 Paulis / Greek WRONG (Dutch)</span><br><span class="hljs-string">70000 70.0 1.3289 Thian / Vietnamese WRONG (Chinese)</span><br><span class="hljs-string">75000 75.0 2.2715 Kelly / English WRONG (Irish)</span><br><span class="hljs-string">80000 80.0 1.0069 Siu / Korean WRONG (Chinese)</span><br><span class="hljs-string">85000 85.0 0.8168 Kan / Chinese CORRECT</span><br><span class="hljs-string">90000 90.0 0.2283 Dinh / Vietnamese CORRECT</span><br><span class="hljs-string">95000 95.0 2.0048 Abbascia / Japanese WRONG (Italian)</span><br><span class="hljs-string">100000 100.0 0.6310 O&#x27;Shea / Irish CORRECT</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>plt.figure()<br>plt.plot(all_losses)<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901183345054.png?img"
alt="image-20210901183345054" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">input_line</span>):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;\n &gt; <span class="hljs-subst">&#123;input_line&#125;</span>&#x27;</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        line_tensor = line_to_tensor(input_line)<br><br>        hidden = rnn.init_hidden()<br><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(line_tensor.size()[<span class="hljs-number">0</span>]):<br>            output, hidden = rnn(line_tensor[i], hidden)<br><br>        guess = category_from_output(output)<br>        <span class="hljs-built_in">print</span>(guess)<br>        <br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    sentence = <span class="hljs-built_in">input</span>(<span class="hljs-string">&#x27;Input: &#x27;</span>)<br>    <span class="hljs-keyword">if</span> sentence == <span class="hljs-string">&#x27;quit&#x27;</span>:<br>        <span class="hljs-keyword">break</span><br>    predict(sentence)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"> &gt; Chinese</span><br><span class="hljs-string">Irish</span><br><span class="hljs-string"></span><br><span class="hljs-string"> &gt; English</span><br><span class="hljs-string">English</span><br><span class="hljs-string"></span><br><span class="hljs-string"> &gt; Japanese</span><br><span class="hljs-string">French</span><br><span class="hljs-string"></span><br><span class="hljs-string"> &gt; French</span><br><span class="hljs-string">German</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h2 id="lstm-modeling-trigonometric-functions">LSTM Modeling
trigonometric functions</h2>
<h3 id="use-lstm-to-fit-sine-and-cosine-functions">Use LSTM to fit sine
and cosine functions</h3>
<ol type="1">
<li>Use numpy to build time series data based on sine function</li>
<li>Use keras to build a simple regression network, mainly using the
LSTM network structure to fit the periodicity of the sine function, and
visualize the fitted sine function image and the real function
image</li>
</ol>
<h4 id="related-knowledge-points">Related knowledge points</h4>
<ol type="1">
<li>Time series data construction and forecasting</li>
<li>Time series model building, training, evaluation and visualization
based on keras LSTM</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Import necessary libraries</span><br><br><span class="hljs-comment"># Build data</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-comment"># Build a model</span><br><span class="hljs-keyword">from</span> tensorflow.keras.models <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Input<br><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> LSTM<br><span class="hljs-keyword">from</span> tensorflow.keras.layers <span class="hljs-keyword">import</span> Dense<br><br><span class="hljs-comment"># Printing progress bar</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-comment"># Visualization</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br>%matplotlib inline<br></code></pre></td></tr></table></figure>
<h4 id="construct-a-data-set">1. Construct a data set</h4>
<p>This module will use numpy to construct time series data. There are
two main steps:</p>
<ol type="1">
<li>Define the sine function (cosine function)</li>
<li>Select historical data window size to construct time series
data</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">ground_func</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    sine / cosine function</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: numpy.ndarray</span><br><span class="hljs-string">    return:</span><br><span class="hljs-string">        sin(x) or cos(x)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    y = np.sin(x)<br>    <span class="hljs-keyword">return</span> y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">build_data</span>(<span class="hljs-params">sequence_data, n_steps</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Use sine function data to build X, y</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        sine_data: numpy.ndarray</span><br><span class="hljs-string">        n_steps: history data window size</span><br><span class="hljs-string">    return:</span><br><span class="hljs-string">        X: numpy.ndarray, y: numpy.ndarray</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># init</span><br>    X, y = [], []<br><br>    seq_len = <span class="hljs-built_in">len</span>(sequence_data)<br><br>    <span class="hljs-keyword">for</span> start_idx <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(seq_len), total=seq_len):<br>        end_idx = start_idx + n_steps<br><br>        <span class="hljs-keyword">if</span> end_idx &gt;= seq_len:<br>            <span class="hljs-keyword">break</span><br><br>        cur_x = sequence_data[start_idx: end_idx]<br>        cur_y = sequence_data[end_idx]<br><br>        X.append(cur_x)<br>        y.append(cur_y)<br><br>    X = np.array(X)<br>    y = np.array(y)<br><br>    X = X.reshape(*X.shape, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> X, y<br>  <br><span class="hljs-comment"># Construct the original sine/cosine function sequence</span><br>xaxis = np.arange(-<span class="hljs-number">50</span> * np.pi, <span class="hljs-number">50</span> * np.pi, <span class="hljs-number">0.1</span>)<br>sequence_data = ground_func(xaxis)<br><span class="hljs-built_in">len</span>(sequence_data)<br><br><span class="hljs-comment"># Take 1000 data for visualization</span><br>plt.figure(figsize = (<span class="hljs-number">20</span>, <span class="hljs-number">8</span>))<br>plt.plot(xaxis[:<span class="hljs-number">1000</span>], sequence_data[:<span class="hljs-number">1000</span>])<br><br><br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184030073.png?img"
alt="image-20210901184030073" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">n_steps = <span class="hljs-number">20</span><br>X, y = build_data(sequence_data, n_steps)<br>X.shape, y.shape<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string"> 99%|█████████▉| 3122/3142 [00:00&lt;00:00, 1557955.63it/s]</span><br><span class="hljs-string">((3122, 20, 1), (3122,))</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h4 id="build-the-model">2. Build the model</h4>
<p>This module builds a timing model based on the LSTM and Dense layer
in keras. The following points need to be noted: 1. Choose the right
hidden size 2. Choose a suitable activation function, such as relu, tanh
3. The optimizer chooses sgd, adam, etc. 3. The loss function chooses
cross entropy loss function (cross_entropy) or mean square error (mse),
etc.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_model</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Build a LSTM model fit sine/cosine function.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    hints: </span><br><span class="hljs-string">        1. a LSTM fit time pattern (ref: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)</span><br><span class="hljs-string">        2. a Dense for regression (ref: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    model = Sequential()<br>    model.add(Input(shape = (<span class="hljs-number">20</span>, <span class="hljs-number">1</span>)))<br>    model.add(LSTM(<span class="hljs-number">32</span>, activation=<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    model.add(Dense(<span class="hljs-number">1</span>, activation=<span class="hljs-string">&#x27;tanh&#x27;</span>))<br>    model.<span class="hljs-built_in">compile</span>(optimizer = <span class="hljs-string">&#x27;adam&#x27;</span>, loss = <span class="hljs-string">&#x27;mse&#x27;</span>)<br><br>    <span class="hljs-keyword">return</span> model<br><br><span class="hljs-comment"># Initialize the model and print related information</span><br>model = create_model()<br>model.summary()<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Instructions for updating:</span><br><span class="hljs-string">Call initializer instance with the dtype argument instead of passing it to the constructor</span><br><span class="hljs-string">Model: &quot;sequential&quot;</span><br><span class="hljs-string">_________________________________________________________________</span><br><span class="hljs-string">Layer (type)                 Output Shape              Param #   </span><br><span class="hljs-string">=================================================================</span><br><span class="hljs-string">lstm (LSTM)                  (None, 32)                4352      </span><br><span class="hljs-string">_________________________________________________________________</span><br><span class="hljs-string">dense (Dense)                (None, 1)                 33        </span><br><span class="hljs-string">=================================================================</span><br><span class="hljs-string">Total params: 4,385</span><br><span class="hljs-string">Trainable params: 4,385</span><br><span class="hljs-string">Non-trainable params: 0</span><br><span class="hljs-string">_________________________________________________________________</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br></code></pre></td></tr></table></figure>
<h4 id="model-training">3. Model training</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Try to change epochs and add callbacks, such as EarlyStopping (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)</span><br>history = model.fit(X, y, batch_size = <span class="hljs-number">32</span>, epochs = <span class="hljs-number">25</span>, verbose = <span class="hljs-number">1</span>)<br>plt.plot(history.history[<span class="hljs-string">&#x27;loss&#x27;</span>], label=<span class="hljs-string">&#x27;loss&#x27;</span>)<br>plt.legend(loc =<span class="hljs-string">&#x27;upper right&#x27;</span>) <span class="hljs-comment"># draw the loss image</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Instructions for updating:</span><br><span class="hljs-string">Use tf.where in 2.0, which has the same broadcast rule as np.where</span><br><span class="hljs-string">Epoch 1/25</span><br><span class="hljs-string">3122/3122 [==============================] - 4s 1ms/sample - loss: 0.1433</span><br><span class="hljs-string">Epoch 2/25</span><br><span class="hljs-string">3122/3122 [==============================] - 3s 879us/sample - loss: 0.0072</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">Epoch 25/25</span><br><span class="hljs-string">3122/3122 [==============================] - 3s 858us/sample - loss: 2.2191e-05</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184239175.png?img"
alt="image-20210901184239175" /></p>
<h4 id="forecast">4. Forecast</h4>
<p>This module uses a function different from the training data to
construct test data to verify the generalization performance of the
model. The main steps are as follows: 1. Define a new function
(sine/cosine) 2. Use the trained model to make predictions 3. Visually
compare model prediction results with real values</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_func</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    sine/cosine function, different from ground_func above.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: numpy.ndarray</span><br><span class="hljs-string">    return:</span><br><span class="hljs-string">        sin(x) or cos(x)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    y = np.cos(x)<br>    <span class="hljs-keyword">return</span> y<br>  <br>test_xaxis = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10</span> * np.pi, <span class="hljs-number">0.1</span>)<br><br>test_sequence_data = test_func(test_xaxis)<br><br><span class="hljs-comment"># Use the initial n_steps of historical data to start forecasting, and the subsequent data will use the predicted data as historical data for further forecasting</span><br>y_preds = test_sequence_data[:n_steps]<br><br><span class="hljs-comment"># Step by step forecast</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(test_xaxis)-n_steps)):<br>    model_input = y_preds[i: i+n_steps]<br>    model_input = model_input.reshape((<span class="hljs-number">1</span>, n_steps, <span class="hljs-number">1</span>))<br>    y_pred = model.predict(model_input, verbose = <span class="hljs-number">0</span>)<br>    y_pred = np.append(y_preds, y_pred)<br><br>plt.figure(figsize = (<span class="hljs-number">10</span>,<span class="hljs-number">8</span>))<br>plt.plot(test_xaxis[n_steps:], y_preds[n_steps:], label =<span class="hljs-string">&#x27;predictions&#x27;</span>)<br>plt.plot(test_xaxis, test_sequence_data, label =<span class="hljs-string">&#x27;ground truth&#x27;</span>)<br>plt.plot(test_xaxis[:n_steps], y_preds[:n_steps], label =<span class="hljs-string">&#x27;initial sequence&#x27;</span>, color =<span class="hljs-string">&#x27;red&#x27;</span>)<br>plt.legend(loc =<span class="hljs-string">&#x27;upper left&#x27;</span>)<br>plt.ylim(-<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>plt.show()<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">100%|██████████| 295/295 [00:01&lt;00:00, 183.91it/s]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184333044.png?img"
alt="image-20210901184333044" /></p>
<h2 id="recurrent-neural-networks">Recurrent Neural Networks</h2>
<p><a
target="_blank" rel="noopener" href="https://github.com/hivandu/practise/blob/master/AI_core_competence/Basic%20ability/ex08_Recurrent_Neural_Networks.ipynb">source</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-comment"># load data</span><br>timeserise_revenue = pd.read_csv(<span class="hljs-string">&#x27;~/data/course_data/time_serise_revenue.csv&#x27;</span>)<br>sales_data = pd.read_csv(<span class="hljs-string">&#x27;~/data/course_data/time_serise_sale.csv&#x27;</span>)<br>timeserise_revenue.head()<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">	Unnamed: 0	day_1	day_2	day_3	day_4	day_5	day_6	day_7	day_8	day_9	...	day_51	day_52	day_53	day_54	day_55	day_56	day_57	day_58	day_59	day_60</span><br><span class="hljs-string">0	0	2.622866	2.657832	2.771121	2.815845	2.876267	2.859229	2.844758	2.793797	2.736443	...	1.228701	1.290414	1.474886	1.563295	1.736197	1.797285	1.978940	2.198979	2.277908	2.403300</span><br><span class="hljs-string">...</span><br><span class="hljs-string">4	4	1.702631	1.825995	2.038047	2.194083	2.313903	2.417883	2.567613	2.650782	2.729691	...	1.258760	1.137150	1.109007	1.104999	1.150137	1.204513	1.221350	1.327023	1.387304	1.557363</span><br><span class="hljs-string">5 rows × 61 columns</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sample_from_table</span>(<span class="hljs-params">sample_size, dataframe</span>):<br>    sample_row = dataframe.sample().values[<span class="hljs-number">0</span>]<br><br>    begin_column = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(sample_row) - sample_size - <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">return</span> (sample_row[begin_column: begin_column + sample_size],<br>            sample_row[begin_column + <span class="hljs-number">1</span>: begin_column + sample_size + <span class="hljs-number">1</span>])<br>  <br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> math, random<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-comment"># Generating a noisy multi-sin wave</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FullyConnected</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x_size, hidden_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(FullyConnected, self).__init__()<br>        self.hidden_size = hidden_size<br><br>        self.linear_with_tanh = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">10</span>, self.hidden_size),<br>            nn.Tanh(),<br>            nn.Linear(self.hidden_size, self.hidden_size),<br>            nn.Tanh(),<br>            nn.Linear(self.hidden_size, output_size)<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        yhat = self.linear_with_tanh(x)<br>        <span class="hljs-keyword">return</span> yhat<br>      <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SimpleRNN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, x_size, hidden_size, n_layers, batch_size, output_size</span>):<br>        <span class="hljs-built_in">super</span>(SimpleRNN, self).__init__()<br>        self.hidden_size = hidden_size<br>        self.n_layers = n_layers<br>        self.batch_size = batch_size<br>        <span class="hljs-comment"># self.inp = nn.Linear(1, hidden_size)</span><br>        self.rnn = nn.RNN(x_size, hidden_size, n_layers, batch_first=<span class="hljs-literal">True</span>)<br>        self.out = nn.Linear(hidden_size, output_size) <span class="hljs-comment"># 10 in and 10 out</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs, hidden=<span class="hljs-literal">None</span></span>):<br>        hidden = self.__init__hidden()<br>        <span class="hljs-comment"># print(&#x27;Forward hidden &#123;&#125;&#x27;.format(hidden.shape))</span><br>        <span class="hljs-comment"># print(&#x27;Forward inps &#123;&#125;&#x27;.format(inputs.shape))</span><br>        output, hidden = self.rnn(inputs.<span class="hljs-built_in">float</span>(), hidden.<span class="hljs-built_in">float</span>())<br>        <span class="hljs-comment"># print(&#x27;Out1 &#123;&#125;&#x27;.format(output.shape))</span><br>        output = self.out(output.<span class="hljs-built_in">float</span>())<br>        <span class="hljs-comment"># print(&#x27;Forward outputs &#123;&#125;&#x27;.format(output.shape))</span><br><br>        <span class="hljs-keyword">return</span> output, hidden<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__hidden</span>(<span class="hljs-params">self</span>):<br>        hidden = torch.zeros(self.n_layers, self.batch_size, self.hidden_size, dtype = torch.float64)<br>        <span class="hljs-keyword">return</span> hidden<br>      <br><span class="hljs-comment"># Set dataset</span><br>source_data = sales_data<br><br><span class="hljs-comment"># Fully Connected Model</span><br>n_epochs = <span class="hljs-number">100</span><br>n_iters= <span class="hljs-number">50</span><br>hidden_size = <span class="hljs-number">2</span> <span class="hljs-comment"># try to change this parameters</span><br>n_layers = <span class="hljs-number">2</span><br>batch_size = <span class="hljs-number">5</span><br>seq_length = <span class="hljs-number">10</span><br>n_sample_size = <span class="hljs-number">50</span><br><br>x_size = <span class="hljs-number">1</span><br><br>fc_model = FullyConnected(x_size, hidden_size, output_size = seq_length)<br>fc_model = fc_model.double()<br><br>criterion = nn.MSELoss()<br>optimizer = optim.SGD(fc_model.parameters(), lr = <span class="hljs-number">0.01</span>)<br><br>losses = np.zeros(n_epochs)<br><br>plt.imshow(fc_model.state_dict()[<span class="hljs-string">&#x27;linear_with_tanh.0.weight&#x27;</span>])<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184546617.png?img"
alt="image-20210901184546617" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):<br>    <span class="hljs-keyword">for</span> iter_ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iters):<br>        _inputs, _targets = sample_from_table(n_sample_size, source_data)<br><br>        inputs = Variable(torch.from_numpy(np.array([_inputs[<span class="hljs-number">0</span>:<span class="hljs-number">10</span>],<br>                                                    _inputs[<span class="hljs-number">10</span>:<span class="hljs-number">20</span>],<br>                                                    _inputs[<span class="hljs-number">20</span>:<span class="hljs-number">30</span>],<br>                                                    _inputs[<span class="hljs-number">30</span>:<span class="hljs-number">40</span>],<br>                                                    _inputs[<span class="hljs-number">40</span>:<span class="hljs-number">50</span>]],<br>                                                    dtype = np.double)))<br><br>        targets = Variable(torch.from_numpy(np.array([_targets[<span class="hljs-number">0</span>:<span class="hljs-number">10</span>],<br>                                                    _targets[<span class="hljs-number">10</span>:<span class="hljs-number">20</span>],<br>                                                    _targets[<span class="hljs-number">20</span>:<span class="hljs-number">30</span>],<br>                                                    _targets[<span class="hljs-number">30</span>:<span class="hljs-number">40</span>],<br>                                                    _targets[<span class="hljs-number">40</span>:<span class="hljs-number">50</span>]],<br>                                                    dtype = np.double)))<br>        <br>        outputs = fc_model(inputs.double())<br><br>        optimizer.zero_grad()<br>        loss = criterion(outputs, targets)<br>        loss.backward()<br>        optimizer.step()<br><br>        losses[epoch] += loss<br>        <span class="hljs-keyword">if</span> iter_ % <span class="hljs-number">10</span> == <span class="hljs-number">0</span>:<br>            plt.clf()<br>            plt.ion()<br>            plt.title(<span class="hljs-string">&#x27;Epoch &#123;&#125;, iter &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, iter_))<br>            plt.plot(torch.flatten(outputs.detach()), <span class="hljs-string">&#x27;r-&#x27;</span>, linewidth = <span class="hljs-number">1</span>, label = <span class="hljs-string">&#x27;Output&#x27;</span>)<br>            plt.plot(torch.flatten(targets), <span class="hljs-string">&#x27;c-&#x27;</span>, linewidth = <span class="hljs-number">1</span>, label = <span class="hljs-string">&#x27;Label&#x27;</span>)<br>            plt.plot(torch.flatten(inputs), <span class="hljs-string">&#x27;g-&#x27;</span>, linewidth = <span class="hljs-number">1</span>, label = <span class="hljs-string">&#x27;Input&#x27;</span>)<br>            plt.draw()<br>            plt.pause(<span class="hljs-number">0.05</span>)<br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184606015.png?img"
alt="image-20210901184606015" /></p>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184620638.png?img"
alt="image-20210901184620638" /></p>
<blockquote>
<p>A total of 5 * 99 pictures were rendered in the middle, so I won’t
show them one by one.</p>
</blockquote>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184826841.png?img"
alt="image-20210901184826841" /></p>
<h3 id="rnn-model">RNN Model</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs python">n_epochs = <span class="hljs-number">100</span><br>n_iters = <span class="hljs-number">50</span><br>hidden_size = <span class="hljs-number">2</span> <span class="hljs-comment"># try to change this parameters</span><br>n_layers = <span class="hljs-number">2</span><br>batch_size = <span class="hljs-number">5</span><br>seq_length = <span class="hljs-number">10</span><br>n_sample_size = <span class="hljs-number">50</span><br><br>x_size = <span class="hljs-number">1</span><br>output_size = <span class="hljs-number">1</span><br><br>rnn_model = SimpleRNN(x_size, hidden_size, n_layers, <span class="hljs-built_in">int</span>(n_sample_size / seq_length), output_size)<br><br>criterion = nn.MSELoss()<br>optimizer = optim.SGD(rnn_model.parameters(), lr = <span class="hljs-number">0.01</span>)<br><br>losses = np.zeros(n_epochs)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_epochs):<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">iter</span> <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_iters):<br>        _inputs, _targets = sample_from_table(n_sample_size, source_data)<br><br>        inputs = Variable(torch.from_numpy(np.array([_inputs[<span class="hljs-number">0</span>:<span class="hljs-number">10</span>],<br>                                                    _inputs[<span class="hljs-number">10</span>:<span class="hljs-number">20</span>],<br>                                                    _inputs[<span class="hljs-number">20</span>:<span class="hljs-number">30</span>],<br>                                                    _inputs[<span class="hljs-number">30</span>:<span class="hljs-number">40</span>],<br>                                                    _inputs[<span class="hljs-number">40</span>:<span class="hljs-number">50</span>]],<br>                                                    dtype = np.double)).unsqueeze(<span class="hljs-number">2</span>))<br><br>        targets = Variable(torch.from_numpy(np.array([_targets[<span class="hljs-number">0</span>:<span class="hljs-number">10</span>],<br>                                                    _targets[<span class="hljs-number">10</span>:<span class="hljs-number">20</span>],<br>                                                    _targets[<span class="hljs-number">20</span>:<span class="hljs-number">30</span>],<br>                                                    _targets[<span class="hljs-number">30</span>:<span class="hljs-number">40</span>],<br>                                                    _targets[<span class="hljs-number">40</span>:<span class="hljs-number">50</span>]],<br>                                                    dtype = np.double)).unsqueeze(<span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>())  <span class="hljs-comment"># [49] </span><br><br>        <span class="hljs-comment"># print(&#x27;Inputs &#123;&#125;, targets &#123;&#125;&#x27;.format(inputs.shape, targets.shape))</span><br><br>        <span class="hljs-comment"># Use teacher forcing 50% of the time</span><br>        <span class="hljs-comment"># force = random.random() &lt; 0.5</span><br>        outputs, hidden = rnn_model(inputs.double(), <span class="hljs-literal">None</span>)<br><br>        optimizer.zero_grad()<br>        loss = criterion(outputs, targets)<br>        loss.backward()<br>        optimizer.step()<br><br>        losses[epoch] += loss<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">iter</span> % <span class="hljs-number">10</span> ==<span class="hljs-number">0</span>:<br>            plt.clf()<br>            plt.ion()<br>            plt.title(<span class="hljs-string">&#x27;Epoch &#123;&#125;, iter &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, <span class="hljs-built_in">iter</span>))<br>            plt.plot(torch.flatten(outputs.detach()), <span class="hljs-string">&#x27;r-&#x27;</span>, linewidth = <span class="hljs-number">1</span>, label = <span class="hljs-string">&#x27;Output&#x27;</span>)<br>            plt.plot(torch.flatten(targets), <span class="hljs-string">&#x27;c-&#x27;</span>, linewidth = <span class="hljs-number">1</span>, label = <span class="hljs-string">&#x27;Label&#x27;</span>)<br>            plt.plot(torch.flatten(inputs), <span class="hljs-string">&#x27;g-&#x27;</span>, linewidth = <span class="hljs-number">1</span>, label = <span class="hljs-string">&#x27;Input&#x27;</span>)<br>            plt.draw()<br>            plt.pause(<span class="hljs-number">0.05</span>)<br><br><span class="hljs-comment"># if epoch &gt; 0:</span><br><span class="hljs-comment">#     print(epoch, loss)</span><br><br><br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184915753.png?img"
alt="image-20210901184915753" /></p>
<blockquote>
<p>A total of 5 * 99 pictures were rendered in the middle, so I won’t
show them one by one.</p>
</blockquote>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901184958237.png?img"
alt="image-20210901184958237" /></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.plot(losses[<span class="hljs-number">20</span>:])<br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img src="https://qiniu.hivan.me/MAMTimage-20210901185025707.png?img"
alt="image-20210901185025707" /></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>RNN</p><p><a href="https://hivan.me/example_08/">https://hivan.me/example_08/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-09-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-02</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/example_06/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Machine Learning Part-04</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/example_07/"><span class="level-item">Advanced Deep Learning</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/example_08/';
            this.page.identifier = 'example_08/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">171</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">22</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/"><span class="level-start"><span class="level-item">AI秘籍</span></span><span class="level-end"><span class="level-item tag">30</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">核心能力基础</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-10-26T10:10:41.000Z">2023-10-26</time></p><p class="title"><a href="/mount-apfs-on-mac/">Mac上挂载APFS移动硬盘</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-10-17T09:44:13.000Z">2023-10-17</time></p><p class="title"><a href="/Python-change-file-names-in-batches/">Python 批量修改文件名</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-27T05:04:36.000Z">2023-09-27</time></p><p class="title"><a href="/ai-core-competence-outline/">AI核心能力基础 - 规划和概要</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-09-04T09:20:55.000Z">2023-09-04</time></p><p class="title"><a href="/calculus-8/">13. 微积分 - 牛顿-莱布尼兹公式、泰勒展开</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Math/">Math</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-24T07:43:45.000Z">2023-08-24</time></p><p class="title"><a href="/Math-Introduction/">茶桁的AI秘籍 - 人工智能数学基础篇 导言</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Math/">Math</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>