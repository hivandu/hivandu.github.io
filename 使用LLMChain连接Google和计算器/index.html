<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>15. 使用LLMChain连接Google和计算器 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="大家好，我是茶桁. 在上一节课中，我们学习了如何使用LangChain这个Python包链式调用OpenAI的API。通过链式调用，我们可以将需要多轮询问AI才能解决的问题封装起来，将需要多轮自然语言调用才能解决的问题变成一个函数调用。"><meta property="og:type" content="blog"><meta property="og:title" content="15. 使用LLMChain连接Google和计算器"><meta property="og:url" content="https://hivan.me/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="大家好，我是茶桁. 在上一节课中，我们学习了如何使用LangChain这个Python包链式调用OpenAI的API。通过链式调用，我们可以将需要多轮询问AI才能解决的问题封装起来，将需要多轮自然语言调用才能解决的问题变成一个函数调用。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230605104013.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230605110352.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230605103945.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20230605123623.gif?imgNote"><meta property="article:published_time" content="2023-06-05T04:23:27.000Z"><meta property="article:modified_time" content="2023-06-10T14:17:09.519Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://qiniu.hivan.me/picGo/20230605104013.png?imgNote"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/"},"headline":"15. 使用LLMChain连接Google和计算器","image":[],"datePublished":"2023-06-05T04:23:27.000Z","dateModified":"2023-06-10T14:17:09.519Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"大家好，我是茶桁. 在上一节课中，我们学习了如何使用LangChain这个Python包链式调用OpenAI的API。通过链式调用，我们可以将需要多轮询问AI才能解决的问题封装起来，将需要多轮自然语言调用才能解决的问题变成一个函数调用。"}</script><link rel="canonical" href="https://hivan.me/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-06-05T04:23:27.000Z" title="6/5/2023, 12:23:27 PM">2023-06-05</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></span></div></div><h1 class="title is-3 is-size-4-mobile">15. 使用LLMChain连接Google和计算器</h1><div class="content"><p>大家好，我是茶桁.</p>
<p>在<a href="../使用链式调用简化多步提示语">上一节课</a>中，我们学习了如何使用LangChain这个Python包链式调用OpenAI的API。通过链式调用，我们可以将需要多轮询问AI才能解决的问题封装起来，将需要多轮自然语言调用才能解决的问题变成一个函数调用。</p>
<span id="more"></span>
<p>然而，LangChain对我们的帮助远不止于此。最近，ChatGPT发布了Plugins插件机制。通过Plugins，ChatGPT可以浏览整个互联网，还可以接入诸如Wolfram这样的科学计算工具，能够解决许多大语言模型难以解决的问题。不过，这是需要Plus用户才可享用的，并且每一个小时内的对话Token都是有限制的。</p>
<p>但是，这并不重要，我们通过LangChain也能实现类似的功能。在今天的课程中，我们将继续深入挖掘Langchain，看看它如何解决这些问题。</p>
<h2 id="解决-ai-数理能力的难题"><strong>解决 AI 数理能力的难题</strong></h2>
<p>虽然许多人发现 ChatGPT 在回答各种问题时表现得很好，但是当涉及到计算三位数乘法时，它就显得有些力不从心了。它似乎只是快速估算一个数字，而不是真正准确计算。为了解决这个问题，我们需要进一步研究 AI 数学能力的提升。</p>
<p>让我们看看下面这段代码，我们让 OpenAI 帮我们计算一下427乘以971等于多少。尽管它的计算结果相差无几，但它仍然算错了。这样的错误对于一个小学数学助教来说是难以忍受的。</p>
<p>因此，我们需要开发一种更强大的 AI 算法，它可以精确计算数字和解决复杂的数学问题。这将有助于开发更全面的 AI 功能，从而提高 AI 在各个领域的应用价值。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai, os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;OPENAI_API_KEY&#x27;</span>] = <span class="string">&#x27;OPENAI_API_KEY&#x27;</span></span><br><span class="line">openai.api_key = <span class="string">&quot;OPENAI_API_KEY</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">from langchain.prompts import PromptTemplate</span></span><br><span class="line"><span class="string">from langchain.llms import OpenAI</span></span><br><span class="line"><span class="string">from langchain.chains import LLMChain</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">llm = OpenAI(model_name = &#x27;text-davinci-003&#x27;, max_tokens = 2048, temperature = 0.5)</span></span><br><span class="line"><span class="string">multiply_prompt = PromptTemplate(template = &#x27;请计算一下&#123;question&#125;是多少?&#x27;, input_variables = [&#x27;question&#x27;])</span></span><br><span class="line"><span class="string">math_chain = LLMChain(llm = llm, prompt = multiply_prompt, output_key = &#x27;answer&#x27;)</span></span><br><span class="line"><span class="string">answer = math_chain.run(&#123;&#x27;question&#x27;: &quot;</span><span class="number">427</span>乘以<span class="number">971</span><span class="string">&quot;&#125;)</span></span><br><span class="line"><span class="string">print(&#x27;OpenAI API 说答案是:&#x27;, answer)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">python_answer = 427 * 971</span></span><br><span class="line"><span class="string">print(&#x27;Python 得到的答案是:&#x27;, python_answer)</span></span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">OpenAI API 说答案是: </span><br><span class="line"><span class="number">427</span> x <span class="number">971</span> = <span class="number">417</span>,<span class="number">797</span></span><br><span class="line"></span><br><span class="line">Python 得到的答案是: <span class="number">414617</span></span><br></pre></td></tr></table></figure>
<p>注：可以看到，OpenAI 给出的结果，答案是错误的。不过，这不是意味着 ChatGPT 就没有用处。实际上，有人很聪明，指出虽然 ChatGPT 直接算这些数学题不行，但是它不是会写代码吗？我们可以让它帮我们写一段利用 Python 计算这个数学式子的代码，从而得出正确的答案。这样，我们可以更好地了解到 ChatGPT 的潜力和用处。</p>
<p>首先，让我们来分析一下这个数学式子。它包括加减乘除和括号，所以我们可以使用 Python 中的基本数学运算符和括号来计算它。在代码中，我们可以定义变量来代表数学式子中的每个数字和符号，然后使用运算符和括号来计算它们之间的关系。</p>
<p>例如，我们可以定义变量 a、b、c 和 d 来代表数学式子中的数字，然后使用加减乘除和括号来计算它们之间的关系。具体代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">a = 2</span><br><span class="line">b = 3</span><br><span class="line">c = 4</span><br><span class="line">d = 5</span><br><span class="line"></span><br><span class="line">result = (a + b) * (c - d)</span><br><span class="line"></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p>运行以上代码，我们可以得到正确的答案：-10。这样，我们就可以利用 ChatGPT 帮助我们写出计算这个数学式子的 Python 代码，从而得出正确的答案，更好地了解 ChatGPT 的潜力和用处。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">multiply_prompt = PromptTemplate(template = <span class="string">&#x27;请写一段Python程序计算&#123;question&#125;。&#x27;</span>, input_variables = [<span class="string">&#x27;question&#x27;</span>])</span><br><span class="line">math_chain = LLMChain(llm = llm, prompt = multiply_prompt, output_key = <span class="string">&#x27;answer&#x27;</span>)</span><br><span class="line">answer = math_chain.run(&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&quot;427乘以971&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(answer)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 计算427乘以971</span></span><br><span class="line">result = <span class="number">427</span> * <span class="number">971</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印结果</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>我们不想再手动复制粘贴这段代码到Python解释器或者Notebook里去执行。因此，我们可以在后面调用一个Python解释器来自动完成整个过程，相关代码如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">multiply_prompt = PromptTemplate(template = <span class="string">&#x27;请写一段Python程序计算&#123;question&#125;。&#x27;</span>, input_variables = [<span class="string">&#x27;question&#x27;</span>])</span><br><span class="line">math_chain = LLMChain(llm = llm, prompt = multiply_prompt, output_key = <span class="string">&#x27;answer&#x27;</span>)</span><br><span class="line">answer_code = math_chain.run(&#123;<span class="string">&#x27;question&#x27;</span>: <span class="string">&quot;427乘以971&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.utilities <span class="keyword">import</span> PythonREPL</span><br><span class="line">python_repl = PythonREPL()</span><br><span class="line">result = python_repl.run(answer_code)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">427</span>乘以<span class="number">971</span>的结果是： <span class="number">414617</span></span><br></pre></td></tr></table></figure>
<p>注意：生成的 Python 脚本正确，可通过调用 Python 解释器获得计算结果。</p>
<p>可以看出，LangChain 内置了一个实用程序包，其中包含了 PythonREPL 类，可以调用 Python 解释器。如果你仔细观察对应代码的源代码，你会发现它实际上只是简单地调用了系统自带的 exec 方法来执行 Python 代码。除了 PythonREPL，utilities 包还有许多其他类，可以实现许多功能，比如直接运行 Bash 脚本、调用 Google 搜索 API 等等。你可以查看 LangChain 的文档，了解它内置的这些工具类。</p>
<p>如果你仔细思考一下，你会发现这实际上也是一种链式调用。只不过，调用链中的第二步不仅仅是访问 OpenAI 的 API。因此，对于这些工具能力，LangChain 也将它们封装成 LLMChain 的形式。例如，刚才的数学计算问题是一个先生成 Python 脚本，然后调用 Python 解释器的过程。LangChain 将这个过程封装成了一个名为 LLMMathChain 的 LLMChain。您不需要自己生成代码，再调用 PythonREPL，只需要直接调用 LLMMathChain，它就会在背景中完成所有操作。下面是相应的代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> LLMMathChain</span><br><span class="line">llm_math = LLMMathChain(llm = llm, verbose = <span class="literal">True</span>)</span><br><span class="line">result = llm_math.run(<span class="string">&quot;请计算一下427乘以971是多少？&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new LLMMathChain chain...</span><br><span class="line">请计算一下<span class="number">427</span>乘以<span class="number">971</span>是多少？</span><br><span class="line">```text</span><br><span class="line"><span class="number">427</span> * <span class="number">971</span></span><br><span class="line">```</span><br><span class="line">...numexpr.evaluate(<span class="string">&quot;427 * 971&quot;</span>)...</span><br><span class="line"></span><br><span class="line">Answer: <span class="number">414617</span></span><br><span class="line">&gt; Finished chain.</span><br><span class="line">Answer: <span class="number">414617</span></span><br></pre></td></tr></table></figure>
<p>LangChain 也将 utilities 包中的许多功能封装成了 Utility Chains。例如，SQLDatabaseChain 可以直接根据你的数据库生成 SQL，然后获取数据；LLMRequestsChain 可以通过 API 调用外部系统，获取所需的答案。您可以在 LangChain 的 Utility Chains 文档中找到可用的工具列表。</p>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230605104013.png?imgNote" alt="image-20230605104008009" /><figcaption aria-hidden="true">image-20230605104008009</figcaption>
</figure>
<p>LLMathChain使用OpenAI生成Python代码，然后通过REPL执行Python代码完成数学计算。</p>
<h2 id="通过-requestschain-获取实时外部信息"><strong>通过 RequestsChain 获取实时外部信息</strong></h2>
<p>在这里，我们将重点讲解如何通过 API 调用外部系统，以获得所需的答案。之前在介绍 llama-index 时，我们已经介绍过一种为 AI 引入外部知识的方法：计算这些外部知识的嵌入，并将其作为索引保存。但是，这种方法仅适用于处理预先准备好的知识，例如书籍或论文，这些内容虽然多，但是固定的，也不存在时效性问题，我们可以提前索引好，而且用户的问题往往也非常相似。</p>
<p>然而，对于具有时效性的问题，这种方法就不太适用了，因为我们可能没有必要不断地更新索引。例如，如果您想了解实时的天气情况，我们不太可能每隔几分钟就索引全球所有城市的最新天气信息。</p>
<p>这时，我们可以使用 LLMRequestsChain，通过 HTTP 请求来获取问题的答案。最简单粗暴的方法就是直接通过一个 HTTP 请求向 Google 提问。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMRequestsChain</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">在 &gt;&gt;&gt; 和 &lt;&lt;&lt; 之间是来自Google的原始搜索结果。</span></span><br><span class="line"><span class="string">请把对于问题&quot;&#123;query&#125;&quot;的答案从里面提取出来，如果里面没有相关信息的话就说“找不到“</span></span><br><span class="line"><span class="string">请使用如下格式：</span></span><br><span class="line"><span class="string">Extracted: &lt;answer or &quot;找不到&quot;&gt;</span></span><br><span class="line"><span class="string"><span class="meta">&gt;&gt;&gt; </span>&#123;requests_result&#125; &lt;&lt;&lt;</span></span><br><span class="line"><span class="string">Extracted:</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">PROMPT = PromptTemplate(</span><br><span class="line">    input_variables = [<span class="string">&#x27;query&#x27;</span>, <span class="string">&#x27;requests_result&#x27;</span>],</span><br><span class="line">    template = template,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">requests_chain = LLMRequestsChain(llm_chain = LLMChain(llm = OpenAI(temperature = <span class="number">0</span>), prompt = PROMPT))</span><br><span class="line">question = <span class="string">&quot;今天上海的天气怎么样？&quot;</span></span><br><span class="line"></span><br><span class="line">inputs = &#123;</span><br><span class="line">    <span class="string">&quot;query&quot;</span>: question,</span><br><span class="line">    <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://www.google.com/search?q=&quot;</span> + question.replace(<span class="string">&#x27; &#x27;</span>, <span class="string">&#x27;+&#x27;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">result = requests_chain(inputs)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"><span class="built_in">print</span>(result[<span class="string">&#x27;output&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>输出的结果：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;query&#x27;<span class="punctuation">:</span> &#x27;今天上海的天气怎么样？&#x27;<span class="punctuation">,</span> &#x27;url&#x27;<span class="punctuation">:</span> &#x27;https<span class="punctuation">:</span><span class="comment">//www.google.com/search?q=今天上海的天气怎么样？&#x27;, &#x27;output&#x27;: &#x27;多雲時陰，最高溫：27°C 最低溫：19°C&#x27;&#125;</span></span><br><span class="line">多雲時陰，最高溫：<span class="number">27</span>°C 最低溫：<span class="number">19</span>°C</span><br></pre></td></tr></table></figure>
<p>让我们来看看这段代码。基于 LLMRequestsChain，我们用到了之前使用过的好几个技巧。</p>
<ol type="1">
<li>首先，因为我们是简单粗暴地搜索 Google，但是我们想要的是一个有价值的天气信息，而不是整个网页。所以，我们还需要通过 ChatGPT 把网页搜索结果里面的答案给找出来。因此，我们定义了一个 PromptTemplate，通过一段提示语，让 OpenAI 在搜索结果中为我们找出问题的答案，而不是获取原始的 HTML 页面。</li>
<li>然后，我们使用了 LLMRequestsChain，并将刚才构造的 PromptTemplate 作为构造函数的一个参数传递给 LLMRequestsChain，以帮助我们在搜索之后处理搜索结果。</li>
<li>查询对应的搜索词会传递到 query 参数中，对应的原始搜索结果会默认放到 requests_results 中。而通过我们自己定义的 PromptTemplate 抽取出来的最终答案，则会放到 output 输出参数中。</li>
</ol>
<p>运行代码后，我们可以看到通过简单搜索 Google 并使用 OpenAI 提取搜索结果中的答案，我们得到了最新的天气信息。</p>
<h2 id="通过-transformationchain-转换数据格式"><strong>通过 TransformationChain 转换数据格式</strong></h2>
<p>有了实时的外部数据，我们就有了很多应用的创意了。比如说，我们可以根据气温来推荐大家穿什么衣服。如果最低温度低于 0 度，我们可以建议用户穿羽绒服。或者，根据是否下雨来决定是否提醒用户出门带伞。</p>
<p>但是，现在返回结果中的天气信息（天气、温度、风力）仅是一段文本，而非可以直接获取的 JSON 格式。当然，我们可以在 LLMChain 内再次链式调用 OpenAI 的接口，将这段文本转换成 JSON 格式。但这么做的话，一方面会消耗更多的 Token 和花费更多的资金，另一方面也会进一步增加程序运行所需的时间，毕竟一次往返的网络请求也很慢。这里的文本格式实际上非常简单，我们完全可以通过简单的字符串处理来解析它。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_temperature</span>(<span class="params">weather_info</span>):</span><br><span class="line">    split_info = weather_info.split(<span class="string">&#x27;，&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(split_info) &lt; <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&#x27;无法正确解析天气信息&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    weather_summary = split_info[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 提取最高温度</span></span><br><span class="line">    max_temp_start = weather_info.find(<span class="string">&quot;最高溫：&quot;</span>) + <span class="built_in">len</span>(<span class="string">&quot;最高溫：&quot;</span>)</span><br><span class="line">    max_temp_end = weather_info.find(<span class="string">&quot;°C&quot;</span>, max_temp_start)</span><br><span class="line">    max_temperature = weather_info[max_temp_start:max_temp_end]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 提取最低温度</span></span><br><span class="line">    min_temp_start = weather_info.find(<span class="string">&quot;最低溫：&quot;</span>) + <span class="built_in">len</span>(<span class="string">&quot;最低溫：&quot;</span>)</span><br><span class="line">    min_temp_end = weather_info.find(<span class="string">&quot;°C&quot;</span>, min_temp_start)</span><br><span class="line">    min_temperature = weather_info[min_temp_start:min_temp_end]</span><br><span class="line"></span><br><span class="line">    temperature_data = &#123;</span><br><span class="line">        <span class="string">&quot;weather_summary&quot;</span>: weather_summary,</span><br><span class="line">        <span class="string">&quot;max_temperature&quot;</span>: max_temperature,</span><br><span class="line">        <span class="string">&quot;min_temperature&quot;</span>: min_temperature</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> temperature_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试示例</span></span><br><span class="line">weather_info = <span class="string">&quot;多雲時陰，最高溫：27°C 最低溫：19°C&quot;</span></span><br><span class="line">result = extract_temperature(weather_info)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印拆分后的结果</span></span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将结果保存为JSON文件</span></span><br><span class="line"><span class="comment"># with open(&quot;weather_data.json&quot;, &quot;w&quot;) as file:</span></span><br><span class="line"><span class="comment">#     json.dump(result, file, ensure_ascii=False, indent=4)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出的结果：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;weather_summary&#x27;<span class="punctuation">:</span> &#x27;多雲時陰&#x27;<span class="punctuation">,</span> &#x27;max_temperature&#x27;<span class="punctuation">:</span> &#x27;<span class="number">27</span>&#x27;<span class="punctuation">,</span> &#x27;min_temperature&#x27;<span class="punctuation">:</span> &#x27;<span class="number">19</span>&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>以上代码其实是我用chatGPT在几次修改后产生的代码。因为我们并不需要保存JSON文件，所以我注释了后面两行代码，但是依然还是贴出来。</p>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230605110352.png?imgNote" alt="image-20230605110352650" /><figcaption aria-hidden="true">image-20230605110352650</figcaption>
</figure>
</blockquote>
<p>我们在这里实现了一个 <code>extract_temperature</code> 函数，可以将 LLMRequestsChain 的输出结果解析为一个 dict。不过，我们能否将该解析逻辑进一步传递到 LLMChain 链式调用的最后呢？答案当然是可以的。Langchain 中有一个专门的解决方案，称为 TransformChain，用于格式转换。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> TransformChain, SequentialChain</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform_func</span>(<span class="params">inputs: <span class="built_in">dict</span></span>) -&gt; <span class="built_in">dict</span>:</span><br><span class="line">    text = inputs[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;weather_info&quot;</span> : extract_temperature(text)&#125;</span><br><span class="line"></span><br><span class="line">transformation_chain = TransformChain(input_variables=[<span class="string">&quot;output&quot;</span>], </span><br><span class="line">                                      output_variables=[<span class="string">&quot;weather_info&quot;</span>], transform=transform_func)</span><br><span class="line"></span><br><span class="line">final_chain = SequentialChain(chains=[requests_chain, transformation_chain], </span><br><span class="line">                              input_variables=[<span class="string">&quot;query&quot;</span>, <span class="string">&quot;url&quot;</span>], output_variables=[<span class="string">&quot;weather_info&quot;</span>])</span><br><span class="line"></span><br><span class="line">final_chain</span><br><span class="line">final_result = final_chain.run(inputs)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(final_result)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出结果为：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;weather_summary&#x27;<span class="punctuation">:</span> &#x27;今天多雲時陰&#x27;<span class="punctuation">,</span> &#x27;max_temperature&#x27;<span class="punctuation">:</span> &#x27;雲時陰，最高溫<span class="number">27</span>&#x27;<span class="punctuation">,</span> &#x27;min_temperature&#x27;<span class="punctuation">:</span> &#x27;雲時陰，最高溫<span class="number">27</span>&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>在 requests_chain 后面跟上一个 transformation_chain，就能把结果解析成 dict，供后面的其他业务使用结构化的数据。</p>
</blockquote>
<p>在这里，我们先定义了一个 <code>transform_func</code> 函数，对前面的 <code>extract_temperature</code> 函数进行简单的封装。<code>transform_func</code> 函数的输入是整个 LLMChain 在执行到 TransformChain 之前的输出结果的 dict。我们前面看到整个 LLMRequestsChain 中的天气信息文本内容是通过 <code>output</code> 这个 key 得到的，因此在这里我们也是先通过它来获取天气信息的文本内容，再调用 <code>extract_temperature</code> 解析，并将结果输出到 <code>weather_info</code> 这个字段中。</p>
<p>然后，我们定义了一个 TransformChain，其输入参数是 output，输出参数是 <code>weather_info</code>。</p>
<p>最后，我们通过上一讲中介绍过的 SequentialChain，将前面的 LLMRequestsChain 和这里的 TransformChain 串联在一起，形成一个名为 <code>final_chain</code> 的新的 LLMChain。</p>
<p>在这三个步骤完成之后，我们只需要调用 <code>final_chain</code> 的 run 方法，输入有关天气的搜索文本即可获得天气信息的 dict 形式的输出。</p>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230605103945.png?imgNote" alt="image-20230605103928538" /><figcaption aria-hidden="true">image-20230605103928538</figcaption>
</figure>
<p>最后，让我们梳理一下 final_chain 完成的任务。</p>
<p>首先，通过一个 HTTP 请求，根据搜索词获取 Google 的搜索结果页。</p>
<p>接着，我们将自定义的提示（Prompt）提交给 OpenAI，并将搜索的问题和结果页发送给 OpenAI，以便它从中提取结果页中的天气信息。</p>
<p>最后，我们使用 transform_func 解析提取到的天气信息文本，并将其转换为一个字典。这样，后续的程序就可以轻松处理了。</p>
<h2 id="通过-vectordbqa-实现先搜索再回复的能力"><strong>通过 VectorDBQA 实现先搜索再回复的能力</strong></h2>
<p>另外，还有一个常用的 LLMChain，就是我们之前介绍的 llama-index 的使用场景，也就是针对自己的资料库进行问答。我们预先把资料库索引好，然后每次用户来问问题的时候，都是先到这个资料库里搜索，再把问题和答案一并交给 AI，让它去组织语言回答。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.embeddings.openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain.text_splitter <span class="keyword">import</span> SpacyTextSplitter</span><br><span class="line"><span class="keyword">from</span> langchain <span class="keyword">import</span> OpenAI, VectorDBQA</span><br><span class="line"><span class="keyword">from</span> langchain.document_loaders <span class="keyword">import</span> TextLoader</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">loader = TextLoader(<span class="string">&#x27;./data/ecommerce_faq.txt&#x27;</span>)</span><br><span class="line">documents = loader.load()</span><br><span class="line">text_splitter = SpacyTextSplitter(chunk_size=<span class="number">256</span>, pipeline=<span class="string">&quot;zh_core_web_sm&quot;</span>)</span><br><span class="line">texts = text_splitter.split_documents(documents)</span><br><span class="line"></span><br><span class="line">embeddings = OpenAIEmbeddings()</span><br><span class="line">docsearch = FAISS.from_documents(texts, embeddings)</span><br><span class="line"></span><br><span class="line">faq_chain = VectorDBQA.from_chain_type(llm=llm, vectorstore=docsearch, verbose=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p>注：上述代码创建了一个基于 FAISS 进行向量存储的 docsearch 索引，并基于该索引创建了 VectorDBQA 的 LLMChain。</p>
<p>首先，我们通过 TextLoader 将文件加载到内存中，并通过 SpacyTextSplitter 对文本进行分段，以确保每个 Document 都是一个完整的句子。因为这里的文档是关于电子商务常见问题的内容，所以我们设置 chunk_size 为 256。接着，我们使用 OpenAIEmbeddings 为文档创建 Embedding，并通过 FAISS 将其存储为一个 VectorStore。最后，我们使用 VectorDBQA 的 <code>from_chain_type</code> 方法定义了一个 LLM。相关的常见问题内容，请参见 <a href="../ecommerce_faq.txt">ecommerce_faq.txt</a> 文件，其中的内容是 ChatGPT编写的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">question = <span class="string">&quot;请问你们的货，能送到三亚吗？大概需要几天？&quot;</span></span><br><span class="line">result = faq_chain.run(question)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new VectorDBQA chain...</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 我们支持全国大部分省份的配送，包括三亚。一般情况下，大部分城市的订单在2-3个工作日内送达，偏远地区可能需要5-7个工作日。</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">question = <span class="string">&quot;请问你们的退货政策是怎么样的？&quot;</span> </span><br><span class="line">result = faq_chain.run(question)</span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new VectorDBQA chain...</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br><span class="line"> 自收到商品之日起7天内，如产品未使用、包装完好，您可以申请退货。某些特殊商品可能不支持退货，请在购买前查看商品详情页面的退货政策。</span><br></pre></td></tr></table></figure>
<p>我向它提了两个不同类型的问题，faq_chain 都能够正确地回答出来。你可以去看看 data 目录下面的 <a href="../ecommerce_faq.txt">ecommerce_faq.txt</a> 文件，看看它的回答是不是和文档中写的内容一致。</p>
<p>在 VectorDBQA 这个 LLMChain 背后，实际上是通过一系列的链式调用来完成搜索 VectorStore 和向 AI 发起 Completion 请求这两个步骤。</p>
<p>可以看到，LLMChain 是一个非常强大的工具，它可以将解决一个问题所需的多个步骤串联在一起。这些步骤可以是调用我们的语言模型，也可以是调用外部 API，或者在内部定义一个 Python 函数。这大大增强了我们利用大型语言模型的能力，特别是能够弥补它的许多不足之处，比如缺少有时效性的信息和通过 HTTP 调用比较慢等等。</p>
<h2 id="小结"><strong>小结</strong></h2>
<p>本文介绍了 Langchain 的链式调用，它不仅限于使用大型语言模型的接口。我们介绍了四种常见的将大型语言模型的接口和其他能力结合在一起的链式调用。</p>
<ol type="1">
<li><p>LLMMathChain 可以通过 Python 解释器变成一个计算器，让 AI 能够准确地进行数学运算。</p></li>
<li><p>通过 RequestsChain，我们可以直接调用外部 API，然后让 AI 从返回的结果中提取我们关心的内容。</p></li>
<li><p>TransformChain 可以让我们根据自己的要求对数据进行处理和转化，我们可以进一步将 AI 返回的自然语言结果转换成结构化数据，方便其他程序处理。</p></li>
<li><p>VectorDBQA 能够完成和 llama-index 相似的事情，只需要预先做好内部数据资料的 Embedding 和索引，通过对 LLMChain 进行一次调用，我们就可以直接获取回答的结果。</p></li>
</ol>
<p>这些能力大大增强了 AI 的实用性，解决了几个之前大型语言模型难以处理的问题，包括数学计算能力、实时数据能力、和现有程序结合的能力，以及搜索自己的资料库的能力。你完全可以定义自己需要的 LLMChain，通过程序来完成各种任务，然后合理地组合不同类型的 LLMChain 对象，来实现连 ChatGPT 都做不到的事情。而 ChatGPT Plugins 的实现机制，其实也是类似的。</p>
<h2 id="思考题"><strong>思考题</strong></h2>
<p>最后，留下一个思考题。我们前面提到，Langchain 中有 SQLDatabaseChain 可以直接让我们编写需求访问数据库。在官方文档中也给出了<a target="_blank" rel="noopener" href="https://python.langchain.com/en/latest/modules/chains/examples/sqlite.html">相应的示例</a>。你可以试着体验一下，思考一下它是通过什么样的提示语信息来让 AI 写出可以直接执行的 SQL？</p>
<p>欢迎你在评论区分享你的体验和思考结果。也欢迎你将本文分享给感兴趣的朋友。我们下一篇文章再见！</p>
<h2 id="推荐试用"><strong>推荐试用</strong></h2>
<p>我们目前对于 Langchain 的讲解都是通过 Python 编程的方式来实现真实业务场景的需求。有人直接为 Langchain 开发了一个可以拖拽的图形界面，叫做 <a target="_blank" rel="noopener" href="https://github.com/logspace-ai/langflow">LangFlow</a>。你可以尝试下载并体验一下，看看图形界面是否可以进一步提高你的效率。</p>
<figure>
<img src="https://qiniu.hivan.me/picGo/20230605123623.gif?imgNote" alt="img" /><figcaption aria-hidden="true">img</figcaption>
</figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>15. 使用LLMChain连接Google和计算器</p><p><a href="https://hivan.me/使用LLMChain连接Google和计算器/">https://hivan.me/使用LLMChain连接Google和计算器/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-06-05</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-10</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Langchain%E8%AE%A9AI%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9B/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">16. Langchain让AI拥有记忆力</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/"><span class="level-item">14. 使用链式调用简化多步提示语</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/';
            this.page.identifier = '使用LLMChain连接Google和计算器/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">143</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">13</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#解决-ai-数理能力的难题"><span class="level-left"><span class="level-item">1</span><span class="level-item">解决 AI 数理能力的难题</span></span></a></li><li><a class="level is-mobile" href="#通过-requestschain-获取实时外部信息"><span class="level-left"><span class="level-item">2</span><span class="level-item">通过 RequestsChain 获取实时外部信息</span></span></a></li><li><a class="level is-mobile" href="#通过-transformationchain-转换数据格式"><span class="level-left"><span class="level-item">3</span><span class="level-item">通过 TransformationChain 转换数据格式</span></span></a></li><li><a class="level is-mobile" href="#通过-vectordbqa-实现先搜索再回复的能力"><span class="level-left"><span class="level-item">4</span><span class="level-item">通过 VectorDBQA 实现先搜索再回复的能力</span></span></a></li><li><a class="level is-mobile" href="#小结"><span class="level-left"><span class="level-item">5</span><span class="level-item">小结</span></span></a></li><li><a class="level is-mobile" href="#思考题"><span class="level-left"><span class="level-item">6</span><span class="level-item">思考题</span></span></a></li><li><a class="level is-mobile" href="#推荐试用"><span class="level-left"><span class="level-item">7</span><span class="level-item">推荐试用</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-30T11:48:02.000Z">2023-06-30</time></p><p class="title"><a href="/%E6%88%91%E4%BB%AC%E6%97%A0%E6%B3%95%E9%80%9A%E8%BF%87%E6%94%B9%E9%80%A0%E8%87%AA%E5%B7%B1%E6%91%86%E8%84%B1%E6%B0%94%E5%80%99%E5%8D%B1%E6%9C%BA/">观点：我们无法通过改造自己摆脱气候危机</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-14T14:36:13.000Z">2023-06-14</time></p><p class="title"><a href="/%E5%88%A9%E7%94%A8LangChain%E8%AE%A9AI%E5%81%9A%E5%86%B3%E7%AD%96/">17. 利用LangChain让AI做决策</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-10T14:16:00.000Z">2023-06-10</time></p><p class="title"><a href="/Langchain%E8%AE%A9AI%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86%E5%8A%9B/">16. Langchain让AI拥有记忆力</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-05T04:23:27.000Z">2023-06-05</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/">15. 使用LLMChain连接Google和计算器</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-02T09:14:18.000Z">2023-06-02</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/">14. 使用链式调用简化多步提示语</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>