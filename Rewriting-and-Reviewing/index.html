<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>08 改写和审核 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Hi, 我是茶桁。 我们已经介绍了 OpenAI 的主要接口。这是基础知识系列的最后一讲，我们将讨论 OpenAI GPT 系列模型的其他接口。你可能不会经常使用其中一些接口，但了解它们不会有任何坏处，说不定你会在某些需求中用到它们。"><meta property="og:type" content="blog"><meta property="og:title" content="08 改写和审核"><meta property="og:url" content="https://hivan.me/Rewriting-and-Reviewing/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Hi, 我是茶桁。 我们已经介绍了 OpenAI 的主要接口。这是基础知识系列的最后一讲，我们将讨论 OpenAI GPT 系列模型的其他接口。你可能不会经常使用其中一些接口，但了解它们不会有任何坏处，说不定你会在某些需求中用到它们。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hivan.me/Rewriting-and-Reviewing/20230601170036.png"><meta property="article:published_time" content="2023-05-15T09:00:02.000Z"><meta property="article:modified_time" content="2023-06-01T13:23:12.734Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://hivan.me/Rewriting-and-Reviewing/20230601170036.png"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/Rewriting-and-Reviewing/"},"headline":"08 改写和审核","image":["https://hivan.me/Rewriting-and-Reviewing/20230601170036.png"],"datePublished":"2023-05-15T09:00:02.000Z","dateModified":"2023-06-01T13:23:12.734Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Hi, 我是茶桁。 我们已经介绍了 OpenAI 的主要接口。这是基础知识系列的最后一讲，我们将讨论 OpenAI GPT 系列模型的其他接口。你可能不会经常使用其中一些接口，但了解它们不会有任何坏处，说不定你会在某些需求中用到它们。"}</script><link rel="canonical" href="https://hivan.me/Rewriting-and-Reviewing/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-05-15T09:00:02.000Z" title="5/15/2023, 5:00:02 PM">2023-05-15</time>发表</span><span class="level-item"><time dateTime="2023-06-01T13:23:12.734Z" title="6/1/2023, 9:23:12 PM">2023-06-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></span><span class="level-item">34 分钟读完 (大约5157个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">08 改写和审核</h1><div class="content"><p>Hi, 我是茶桁。</p>
<p>我们已经介绍了 OpenAI 的主要接口。这是基础知识系列的最后一讲，我们将讨论 OpenAI GPT 系列模型的其他接口。你可能不会经常使用其中一些接口，但了解它们不会有任何坏处，说不定你会在某些需求中用到它们。</p>
<span id="more"></span>
<p>在这篇文章中，我们将一起探讨 OpenAI 为文本改写和内容审核提供的功能，以及 GPT 系列模型的种类、区别和应用场景。</p>
<h3 id="文本改写教程">文本改写教程</h3>
<p>我猜你可能已经用过许多基于 AI 大型语言模型的产品了。其中很常见的一类应用是写作助手，比如 Notion AI。它可以帮助你在文章中选择一段内容，并让 AI 帮你修改它，例如缩短文本或改变语气等。</p>
<img src="/Rewriting-and-Reviewing/20230601170036.png" class="" title="img">
<p>OpenAI的GPT系列模型是一个生成式模型，给它一段文字，它可以补全后面的文字。要修改一段内容，可以通过提示语来解决问题。下面这段代码是通过ChatGPT模型实现了这个功能。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">openai.api_key = <span class="string">&#x27;OPENAI_API_KEY&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_text_short</span>(<span class="params">text</span>):</span><br><span class="line">    messages = []</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果&quot;</span>&#125;)</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: text&#125;)</span><br><span class="line">    response = openai.ChatCompletion.create(</span><br><span class="line">        model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">        messages=messages,</span><br><span class="line">        temperature=<span class="number">0.5</span>,</span><br><span class="line">        max_tokens=<span class="number">2048</span>,</span><br><span class="line">        presence_penalty=<span class="number">0</span>,</span><br><span class="line">        frequency_penalty=<span class="number">2</span>,</span><br><span class="line">        n=<span class="number">3</span>,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">long_text = <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">我们可以回顾下它走的一些关键路程：GPT 1.0走的是生成模式的自回归语言模型路线，比Bert出来的还早些。Bert证明了：双向语言模型对于很多NLP理解类任务，效果比自回归这种单向语言模型效果更好。尽管如此，GPT 2.0并没有因此切换到双向语言模型这条路上，仍然走文本生成的路，而且开始尝试零示例（zero shot）prompt和少量示例（few shot）prompt。其实这时候， OpenAI心目中的AGI已经开始浮出水面，逐渐显示出轮廓了。只是因为zero shot/few shot效果比Bert+fine-tuning差的比较远，所以大家都没太当回事，甚至不理解它为什么要始终坚持走单向语言模型的路线。这个时候，我估计即使是OpenAI自己，也不一定能确保这条路肯定能走通。</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">short_version = make_text_short(long_text)</span><br><span class="line"></span><br><span class="line">index = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> choice <span class="keyword">in</span> short_version[<span class="string">&quot;choices&quot;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;version <span class="subst">&#123;index&#125;</span>: &quot;</span> + choice[<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>])</span><br><span class="line">    index += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">version <span class="number">1</span>: GPT <span class="number">1.0</span>和Bert是NLP领域的里程碑，前者采用了自回归语言模型，后者证明双向语言模型更优。不过GPT <span class="number">2.0</span>仍然坚持文本生成路线，并尝试了零/少量示例prompt。OpenAI心目中的AGI开始显现轮廓，但由于效果不如Bert+fine-tuning而被忽视。这条路是否可行并不能确定。</span><br><span class="line">version <span class="number">2</span>: GPT <span class="number">1.0</span>采用了生成模式的自回归语言模型路线，比Bert更早。Bert证明了双向语言模型在NLP理解类任务上效果更好，但GPT <span class="number">2.0</span>仍然坚持文本生成路线，并尝试了零/少量示例prompt。OpenAI心目中的AGI逐渐浮出水面，但zero shot/few shot效果不如Bert+fine-tuning, 这条路是否可行还需观察。</span><br><span class="line">version <span class="number">3</span>: GPT <span class="number">1.0</span>采用自回归语言模型，比Bert早。Bert证明双向语言模型效果更好，但GPT <span class="number">2.0</span>仍然走文本生成路线，并尝试了零/少量示例prompt。OpenAI的AGI已经开始浮出水面，只是因为zero/few shot效果差而被忽视。即使OpenAI也不能保证这条路一定能成功。</span><br></pre></td></tr></table></figure>
<p>我们使用 ChatGPT 的模型接口，因为它比较便宜。我们使用了以下参数：</p>
<ol type="1">
<li><p><code>n=3</code>，让 AI 给我们返回 3 个答案供我们选择。在文本改写类的应用里面，我们通常不只是直接给出答案，而是会给用户几个选项来选择。</p></li>
<li><p><code>presence_penalty=0</code>、 <code>frequency_penalty=2</code>。这两个参数和 <code>temperature</code> 参数类似，都是来控制你输出的内容的。 <code>presence_penalty</code> 指的是如果一个 Token 在前面的内容已经出现过了，那么在后面生成的时候给它的概率一定的惩罚； <code>frequency_penalty</code> 指的是对于重复出现的 Token 进行概率惩罚。这样，AI 就会尽量使用不同的表述。</p></li>
</ol>
<h3 id="通过-logit_bias-参数精准控制内容"><strong>通过 logit_bias 参数精准控制内容</strong></h3>
<p>虽然 <code>temperature</code> 、 <code>presence_penalty</code> 和 <code>frequency_penalty</code> 等参数都可以控制生成文本的风格，但是它们都只是单一的参数，无法精确控制不想出现的词汇。不过，OpenAI 提供了方法来解决这个问题。例如，如果我们不想让“灾害”这两个字出现在生成的内容中，可以采取如下措施。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tiktoken</span><br><span class="line">encoding = tiktoken.get_encoding(<span class="string">&#x27;p50k_base&#x27;</span>)</span><br><span class="line">token_ids = encoding.encode(<span class="string">&quot;灾害&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(token_ids)</span><br><span class="line"></span><br><span class="line">bias_map = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> token_id <span class="keyword">in</span> token_ids:</span><br><span class="line">    bias_map[token_id] = -<span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_text_short</span>(<span class="params">text</span>):</span><br><span class="line">    messages = []</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个用来将文本改写得短的AI助手，用户输入一段文本，你给出一段意思相同，但是短小精悍的结果&quot;</span>&#125;)</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: text&#125;)</span><br><span class="line">    response = openai.ChatCompletion.create(</span><br><span class="line">        model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, messages=messages, temperature=<span class="number">0.5</span>, max_tokens=<span class="number">2048</span>,</span><br><span class="line">        n=<span class="number">3</span>, presence_penalty=<span class="number">0</span>, frequency_penalty=<span class="number">2</span>, </span><br><span class="line">        logit_bias = bias_map,</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">short_version = make_text_short(long_text)</span><br><span class="line"></span><br><span class="line">index = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> choice <span class="keyword">in</span> short_version[<span class="string">&quot;choices&quot;</span>]:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;version <span class="subst">&#123;index&#125;</span>: &quot;</span> + choice[<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>])</span><br><span class="line">    index += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>输出结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[<span class="number">163</span>, <span class="number">223</span>, <span class="number">122</span>, <span class="number">22522</span>, <span class="number">111</span>]</span><br><span class="line">version <span class="number">1</span>: GPT <span class="number">1.0</span>是生成模式的自回归语言模型，比Bert还早。Bert证明了双向语言模型效果更好，但GPT <span class="number">2.0</span>仍然坚持文本生成路线，并尝试零/少量示例prompt。这时OpenAI的AGI开始浮出水面，只是因为效果不如Bert+fine-tuning而被忽视。</span><br><span class="line">version <span class="number">2</span>: GPT <span class="number">1.0</span>是自回归语言模型，比Bert早。Bert证明了双向语言模型效果更好，但GPT <span class="number">2.0</span>仍然选择文本生成，并尝试了零/少量示例prompt。OpenAI的AGI开始浮出水面，但因为zero/few shot效果差被忽视。这条路是否可行不确定。</span><br><span class="line">version <span class="number">3</span>: GPT <span class="number">1.0</span>采用生成模式自回归语言模型，比Bert更早。Bert证明了双向语言模型的效果比自回归好，但GPT <span class="number">2.0</span>仍然坚持文本生成路线，并尝试零/少量示例prompt。OpenAI心目中的AGI已经开始浮出水面，只是因为zero shot/few shot效果不如Bert+fine-tuning而被忽视。</span><br></pre></td></tr></table></figure>
<p>我们使用 Tiktoken 库，找到了“灾害”对应的 Token，并赋予它们 -100 的 bias，以避免这个词出现在生成的回复中。我们将整个 <code>bias_map</code> 作为参数传递给 <code>Completion</code> 的 <code>logit_bias</code> 参数。现在，生成的三个回复都不包含“灾害”这个词了，即使之前的第一个回复中也包含了。现在，“灾”这个字被强制改成了繁体字，而另一个则出现了错别字“宣”。</p>
<p><code>logit_bias</code> 参数的取值范围为 -100 到 100 之间，但通常设置在 1 到 -1 之间就足够了。如果将其设置为 100，则必须出现某些字，整个生成过程会变得非常缓慢，难以忍受。</p>
<h3 id="用英文减少-token-使用">用英文减少 Token 使用</h3>
<p>虽然“灾害”只有两个中文字，但在使用 Tiktoken 处理时，我们打印了对应的 Token ID，实际上需要使用5个 Token。同样的，中文中含义相同的词语，所需的 Token 数量比英文多。例如，将上面的句子翻译成英文，与中文相同的内容所需的 Token 数量进行比较。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">translate</span>(<span class="params">text</span>):</span><br><span class="line">    messages = []</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;你是一个翻译，把用户的话翻译成英文&quot;</span>&#125;)</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: text&#125;)</span><br><span class="line">    response = openai.ChatCompletion.create(</span><br><span class="line">        model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>, messages=messages, temperature=<span class="number">0.5</span>, max_tokens=<span class="number">2048</span>,        n=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> response[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line"></span><br><span class="line">chinese = long_text</span><br><span class="line">english = translate(chinese)</span><br><span class="line"></span><br><span class="line">num_of_tokens_in_chinese = <span class="built_in">len</span>(encoding.encode(chinese))</span><br><span class="line">num_of_tokens_in_english = <span class="built_in">len</span>(encoding.encode(english))</span><br><span class="line"><span class="built_in">print</span>(english)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;chinese: <span class="subst">&#123;num_of_tokens_in_chinese&#125;</span> tokens&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;english: <span class="subst">&#123;num_of_tokens_in_english&#125;</span> tokens&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">We can review some of its key milestones: GPT <span class="number">1.0</span> followed the path of a generative pattern of autoregressive language model, which came out earlier than Bert. Bert proved that <span class="keyword">for</span> many NLP understanding tasks, the effect of bidirectional language models <span class="keyword">is</span> better than that of unidirectional language models like autoregressive. Nevertheless, GPT <span class="number">2.0</span> did <span class="keyword">not</span> switch to the bidirectional language model, but continued to follow the path of text generation, <span class="keyword">and</span> began to <span class="keyword">try</span> zero-shot <span class="keyword">and</span> few-shot prompts. Actually, at this point, OpenAI<span class="string">&#x27;s AGI had already begun to emerge and gradually showed its outline. It&#x27;</span>s just that because the effect of zero-shot/few-shot <span class="keyword">is</span> far worse than Bert+fine-tuning, everyone didn<span class="string">&#x27;t pay much attention to it, and even didn&#x27;</span>t understand why it always insisted on the path of unidirectional language models. At this point, I estimate that even OpenAI itself cannot guarantee that this path will definitely work.</span><br><span class="line">chinese: <span class="number">589</span> tokens</span><br><span class="line">english: <span class="number">208</span> tokens</span><br></pre></td></tr></table></figure>
<p>同样的内容，在中文中要消耗超过 589个 Token，而英文只有 208。在使用 OpenAI 的接口时，最好使用英语提示语，以节约成本。当然，在输出结果时可以使用 " <code>generate Chinese</code>" 等提示。但是，我们将在后面的课程演示中尽量使用中文，以方便您的理解。</p>
<h3 id="openai-的模型">OpenAI 的模型</h3>
<p>OpenAI 曾经提供过一个<a target="_blank" rel="noopener" href="https://platform.openai.com/docs/api-reference/edits">Edit 接口</a>，并单独提供了文本编辑模型。目前，这个接口和模型不能使用，可能因为是 Alpha 版本或已被下线。</p>
<p>由于 OpenAI 的产品更新非常快，所以最好的办法是通过它提供的接口查看可用模型，以便选择效果最好或最新的模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># list all open ai models</span></span><br><span class="line">engines = openai.Engine.<span class="built_in">list</span>()</span><br><span class="line">pd = pd.DataFrame(openai.Engine.<span class="built_in">list</span>()[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">display(pd[[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;owner&#x27;</span>]])</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了文本长度，仅展示了部分，中间大部分省略掉了。可以去查看我源代码，里面有展示。</span></span><br><span class="line"><span class="built_in">id</span>	owner</span><br><span class="line"><span class="number">0</span>	whisper-<span class="number">1</span>	openai-internal</span><br><span class="line"><span class="number">1</span>	babbage	openai</span><br><span class="line"><span class="number">2</span>	davinci	openai</span><br><span class="line"><span class="number">3</span>	text-davinci-edit-001	openai</span><br><span class="line"><span class="number">4</span>	babbage-code-search-code	openai-dev</span><br><span class="line"><span class="number">5</span>	text-similarity-babbage-001	openai-dev</span><br><span class="line"><span class="number">6</span>	code-davinci-edit-001	openai</span><br><span class="line"><span class="number">7</span>	text-davinci-001	openai</span><br><span class="line">...</span><br><span class="line"><span class="number">49</span>	davinci-similarity	openai-dev</span><br></pre></td></tr></table></figure>
<p>截止到目前为止，输出结果中有 49 个模型。这些模型的名称已经很直观了，比如 <code>text-similarity-babbage-001</code> 用于相似度匹配，适合用于零样本分类，而 <code>text-search-davinci-doc-001</code> 更适合用于文档搜索。虽然一些模型标记为 openai-dev 或 <code>openai-internal</code> , 但它们仍然可用。例如，在第 02 讲中使用 <code>get_embedding</code> 方法获取向量时，后台使用的是 <code>text-similarity-davinci-001</code> 模型，这也是 openai-dev 的模型之一。虽然其中许多模型已经过时，但实际上只需要关注几类主要模型即可。GPT-4 家族的模型，包括 gpt-4 和 gpt-4-0314。使用方式和 ChatGPT 的模型一样，带日期的模型是模型快照，不会随时间迁移不断更新。GPT-4 的模型现在还很昂贵，输入 1000 个 Token 需要 0.03 美分，生成 1000 个 Token 则需要 0.06 美分。通常我使用它来写代码，准确率较高。</p>
<ol type="1">
<li><p>GPT-3.5 家族的模型，包括 ChatGPT 所使用的 gpt-3.5-turbo 或者 gpt-3.5-turbo-0301，以及 text-davinci-003 和 text-davinci-002 这两个模型。前者专门针对对话的形式进行了微调，并且价格便宜，无论输入输出，1000 个 Token 都只需要 0.002 美分。后两个里，003 的模型有一个特殊功能，支持"插入文本"。003 是基于强化学习微调的，而 002 则是监督学习下微调的。text-davinci-003 和 002 模型比 3.5-turbo 贵 10 倍，但输出更稳定。你可以根据自己需要来决定。</p></li>
<li><p>Ada、Babbage、Curie 以及 Davinci 这四个基础模型只适合下达单轮指令，不适合考虑复杂上下文和进行逻辑推理。这四个模型按首字母排序，价格越来越贵，效果越来越好。如果要微调一个属于自己的模型，需要基于这四个基础模型。</p></li>
<li><p>text-embedding-ada-002、text-similarity-ada-001 这些专门用途模型通常用于获取 Embedding，用于其他机器学习模型的训练或语义相似度比较。</p></li>
</ol>
<p>所有模型的名字都来自科学史上的名人。Ada 来自人类史上第一位程序员 Ada，她也是著名诗人拜伦的女儿。Babadge 则是设计了分析机的巴贝奇，巴贝奇分析机也被认为是现代计算机的前身。Curie 指居里夫人，Davinci 是指达芬奇。</p>
<p>可以挑几个模型试一下它们 Embedding 的维度数量，就知道模型的尺寸不同。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> openai.embeddings_utils <span class="keyword">import</span> get_embedding</span><br><span class="line"></span><br><span class="line">text = <span class="string">&quot;让我们来算算Embedding&quot;</span></span><br><span class="line"></span><br><span class="line">embedding_ada = get_embedding(text, engine=<span class="string">&quot;text-embedding-ada-002&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;embedding-ada: &quot;</span>, <span class="built_in">len</span>(embedding_ada))</span><br><span class="line"></span><br><span class="line">similarity_ada = get_embedding(text, engine=<span class="string">&quot;text-similarity-ada-001&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;similarity-ada: &quot;</span>, <span class="built_in">len</span>(similarity_ada))</span><br><span class="line"></span><br><span class="line">babbage_similarity = get_embedding(text, engine=<span class="string">&quot;babbage-similarity&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;babbage-similarity: &quot;</span>, <span class="built_in">len</span>(babbage_similarity))</span><br><span class="line"></span><br><span class="line">babbage_search_query = get_embedding(text, engine=<span class="string">&quot;text-search-babbage-query-001&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;search-babbage-query: &quot;</span>, <span class="built_in">len</span>(babbage_search_query))</span><br><span class="line"></span><br><span class="line">curie = get_embedding(text, engine=<span class="string">&quot;curie-similarity&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;curie-similarity: &quot;</span>, <span class="built_in">len</span>(curie))</span><br><span class="line"></span><br><span class="line">davinci = get_embedding(text, engine=<span class="string">&quot;text-similarity-davinci-001&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;davinci-similarity: &quot;</span>, <span class="built_in">len</span>(davinci))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">embedding-ada:  <span class="number">1536</span></span><br><span class="line">similarity-ada:  <span class="number">1024</span></span><br><span class="line">babbage-similarity:  <span class="number">2048</span></span><br><span class="line">search-babbage-query:  <span class="number">2048</span></span><br><span class="line">curie-similarity:  <span class="number">4096</span></span><br><span class="line">davinci-similarity:  <span class="number">12288</span></span><br></pre></td></tr></table></figure>
<p><code>ada-similarity</code> 的最小维度为 1024， <code>davinci-similarity</code> 的最大维度为 12288。因此，它们的价格和效果有所不同。</p>
<h3 id="gpt-也能插入内容">GPT 也能插入内容</h3>
<p><code>text-davinci-003</code> 模型有一个特殊功能：插入文本。你可以使用这个功能来改写文本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">prefix = <span class="string">&quot;&quot;&quot;在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。</span></span><br><span class="line"><span class="string">在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\n&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。</span></span><br><span class="line">suffix = <span class="string">&quot;&quot;&quot;\n面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。</span></span><br><span class="line"><span class="string">这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。</span></span><br><span class="line"><span class="string">只有这样，我们才能真正地实现自己的潜力并取得成功。&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">insert_text</span>(<span class="params">prefix, suffix</span>):</span><br><span class="line">    response = openai.Completion.create(</span><br><span class="line">        model=<span class="string">&quot;text-davinci-003&quot;</span>,</span><br><span class="line">        prompt=prefix,</span><br><span class="line">        suffix=suffix,</span><br><span class="line">        max_tokens=<span class="number">1024</span>,</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line">response = insert_text(prefix, suffix)</span><br><span class="line"><span class="built_in">print</span>(response[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">此外，还有一些挑战和困难是由自我内在的原因导致的，比如事业上的恐惧和沮丧，以及担心无法达到完美标准等。</span><br></pre></td></tr></table></figure>
<p>使用这个接口和普通的 Completion 接口基本相同，唯一的区别在于除了前缀的 prompt 参数之外，还需要一个后缀的 suffix 参数。</p>
<p>需要注意的是插入内容的提示语。如果我们稍微修改上面的内容，例如去掉 Suffix 一开始的换行符，插入的文本内容可能会不如预期。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">prefix = <span class="string">&quot;&quot;&quot;在这个快节奏的现代社会中，我们每个人都面临着各种各样的挑战和困难。</span></span><br><span class="line"><span class="string">在这些挑战和困难中，有些是由外部因素引起的，例如经济萧条、全球变暖和自然灾害等。\n&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 还有一些是由内部因素引起的，例如情感问题、健康问题和自我怀疑等。</span></span><br><span class="line">suffix = <span class="string">&quot;&quot;&quot;面对这些挑战和困难，我们需要采取积极的态度和行动来克服它们。</span></span><br><span class="line"><span class="string">这意味着我们必须具备坚韧不拔的意志和创造性思维，以及寻求外部支持的能力。</span></span><br><span class="line"><span class="string">只有这样，我们才能真正地实现自己的潜力并取得成功。&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">response = insert_text(prefix, suffix)</span><br><span class="line"><span class="built_in">print</span>(response[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;text&quot;</span>])</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">而另一些则是由内在因素引起的，比如性格、思想、管理方式或者技能缺乏等。</span><br><span class="line">无论是外部因素还是内在因素，</span><br></pre></td></tr></table></figure>
<p>在使用这个 INSERT 接口的时候，考虑好文本之间需要使用什么样的分隔符，是非常重要的。</p>
<h3 id="ai-的正直">AI 的正直</h3>
<p>介绍 OpenAI 的最后一个自然语言处理接口——Moderate。这是唯一一个免费的接口，可以检查用户输入和返回的内容。如果出现不当内容，你就可以屏蔽用户访问或人工审核。</p>
<p>下面看一个例子，如何使用这个接口。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">chatgpt</span>(<span class="params">text</span>):</span><br><span class="line">    messages = []</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a useful AI assistant&quot;</span>&#125;)</span><br><span class="line">    messages.append( &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: text&#125;)</span><br><span class="line">    response = openai.ChatCompletion.create(</span><br><span class="line">        model=<span class="string">&quot;gpt-3.5-turbo&quot;</span>,</span><br><span class="line">        messages=messages,</span><br><span class="line">        temperature=<span class="number">0.5</span>,</span><br><span class="line">        max_tokens=<span class="number">2048</span>,</span><br><span class="line">        top_p=<span class="number">1</span>,</span><br><span class="line">    )</span><br><span class="line">    message = response[<span class="string">&quot;choices&quot;</span>][<span class="number">0</span>][<span class="string">&quot;message&quot;</span>][<span class="string">&quot;content&quot;</span>]</span><br><span class="line">    <span class="keyword">return</span> message</span><br><span class="line"></span><br><span class="line">threaten = <span class="string">&quot;你不听我的我就拿刀砍死你&quot;</span></span><br><span class="line"><span class="built_in">print</span>(chatgpt(threaten))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">对不起，我不理解您的意思。作为AI助手，我旨在为您提供最好的服务和支持，而且我不能被伤害。如果您有任何问题或需要帮助，请告诉我，我会尽力回答和解决。</span><br></pre></td></tr></table></figure>
<p>对于 AI 的暴力威胁，我们可以看到简单调用 ChatGPT 的 API 并不能返回一个日常的对话，而是告知用户不会回应暴力言论。接着，我们可以将这句话发送到 moderate 的接口进行进一步处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">threaten = <span class="string">&quot;你不听我的我就拿刀砍死你&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">moderation</span>(<span class="params">text</span>):</span><br><span class="line">    response = openai.Moderation.create(</span><br><span class="line">        <span class="built_in">input</span>=text</span><br><span class="line">    )</span><br><span class="line">    output = response[<span class="string">&quot;results&quot;</span>][<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"><span class="built_in">print</span>(moderation(threaten))</span><br></pre></td></tr></table></figure>
<p>返回结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;categories&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;hate&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;hate/threatening&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;self-harm&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;sexual&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;sexual/minors&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;violence&quot;</span>: true,</span><br><span class="line">    <span class="string">&quot;violence/graphic&quot;</span>: false</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;category_scores&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;hate&quot;</span>: <span class="number">0.030033664777874947</span>,</span><br><span class="line">    <span class="string">&quot;hate/threatening&quot;</span>: <span class="number">0.0002820899826474488</span>,</span><br><span class="line">    <span class="string">&quot;self-harm&quot;</span>: <span class="number">0.004850226454436779</span>,</span><br><span class="line">    <span class="string">&quot;sexual&quot;</span>: <span class="number">2.2907377569936216e-05</span>,</span><br><span class="line">    <span class="string">&quot;sexual/minors&quot;</span>: <span class="number">6.477687275463495e-09</span>,</span><br><span class="line">    <span class="string">&quot;violence&quot;</span>: <span class="number">0.9996402263641357</span>,</span><br><span class="line">    <span class="string">&quot;violence/graphic&quot;</span>: <span class="number">4.35576839663554e-05</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;flagged&quot;</span>: true</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>moderate 接口返回的是一个 JSON，包括是否应该对输入内容进行标记的 flag，问题类型的 categories，以及每个 categories 的分数 category_scores。举例，我们的文本被标记为暴力。该免费接口可用于所有输入输出，即使您不使用 ChatGPT 的 AI 功能，只是经营在线网站，也可以使用该接口过滤不合适的内容。</p>
<h3 id="小结">小结</h3>
<p>我们总结了 ChatGPT API 的基础功能，包括如何使用提示语进行文本改写。我们深入了解了 Completion 接口的一些新参数，其中的 logit_bias 参数可以帮助我们在生成的文本中精确避免不希望出现的 Token。我们还发现，中文消耗的 Token 数量要远高于英文，因此建议在生产环境下使用英文提示语。</p>
<p>此外，我们介绍了 OpenAI 提供的各种模型以及它们的应用场景。我们体验了两个特殊接口：文本插入功能和内容审核过滤。这样我们就学习了 OpenAI GPT 模型的所有基本接口，以及如何利用这些接口完成最简单的任务，包括文本处理、聊天机器人、分类和聚类、以及文本改写和内容审核。</p>
<p>在第二部分中，我们将学习如何结合自己的专有数据开发自己的应用程序，这是这门课程中更精彩的一部分。</p>
<p><strong>而到此为止，本课程的免费部分也就结束了，之后就要进入收费课程。放心，不会很贵的，如果您觉得课程对您有用，应该不是吝啬那1 ~ 2元。</strong></p>
<h3 id="课后练习">课后练习</h3>
<p>使用<a target="_blank" rel="noopener" href="https://www.hivan.me/Quickly%20build%20an%20AI%20application">06讲中</a>介绍的Gradio和本讲介绍的内容，尝试创建一个文本改写应用。另外，可以将问题拆解并输入ChatGPT，看看它是否能够编写相应的代码。期待在评论区看到您的分享，欢迎将此课程分享给感兴趣的朋友。下次见！</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>08 改写和审核</p><p><a href="https://hivan.me/Rewriting-and-Reviewing/">https://hivan.me/Rewriting-and-Reviewing/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-05-15</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/Implementing-semantic-retrieval-using-Embedding/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">09 使用Embedding实现语义检索</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/AI-can-help-you-summarize-your-content/"><span class="level-item">07 AI帮你做总结</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/Rewriting-and-Reviewing/';
            this.page.identifier = 'Rewriting-and-Reviewing/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">140</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">14</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-05T04:23:27.000Z">2023-06-05</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8LLMChain%E8%BF%9E%E6%8E%A5Google%E5%92%8C%E8%AE%A1%E7%AE%97%E5%99%A8/">15. 使用LLMChain连接Google和计算器</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-06-02T09:14:18.000Z">2023-06-02</time></p><p class="title"><a href="/%E4%BD%BF%E7%94%A8%E9%93%BE%E5%BC%8F%E8%B0%83%E7%94%A8%E7%AE%80%E5%8C%96%E5%A4%9A%E6%AD%A5%E6%8F%90%E7%A4%BA%E8%AF%AD/">14. 使用链式调用简化多步提示语</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-28T09:50:41.000Z">2023-05-28</time></p><p class="title"><a href="/Use-AI-to-write-a-snake-game/">利用AI写一个『贪吃蛇游戏』</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-28T09:17:32.000Z">2023-05-28</time></p><p class="title"><a href="/Use-multi-step-prompts-to-ask-AI-to-write-tests-for-you/">13 使用多步提示语让AI帮你写测试</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-05-26T09:15:54.000Z">2023-05-26</time></p><p class="title"><a href="/AI-create-a-excel-plugin/">12 AI帮你写个小插件，轻松处理Excel文件</a></p><p class="categories"><a href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>