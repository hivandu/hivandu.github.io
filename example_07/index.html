<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Advanced Deep Learning - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Different optimer"><meta property="og:type" content="blog"><meta property="og:title" content="Advanced Deep Learning"><meta property="og:url" content="https://hivan.me/example_07/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Different optimer"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hivan.me/img/og_image.png"><meta property="article:published_time" content="2021-09-02T12:59:46.686Z"><meta property="article:modified_time" content="2023-06-02T03:45:50.694Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI,人工智能,代码,大语言模型"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://hivan.me/img/og_image.png"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/example_07/"},"headline":"Advanced Deep Learning","image":["https://hivan.me/img/og_image.png"],"datePublished":"2021-09-02T12:59:46.686Z","dateModified":"2023-06-02T03:45:50.694Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Different optimer"}</script><link rel="canonical" href="https://hivan.me/example_07/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-09-02T12:59:46.686Z" title="9/2/2021, 8:59:46 PM">2021-09-02</time>发表</span></div></div><h1 class="title is-3 is-size-4-mobile">Advanced Deep Learning</h1><div class="content"><h2 id="different-optimer">Different optimer</h2>
<span id="more"></span>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><br>x = np.random.random(size=(<span class="hljs-number">100</span>, <span class="hljs-number">8</span>))<br>linear = torch.nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">1</span>)<br>sigmoid = torch.nn.Sigmoid()<br>linear2 = torch.nn.Linear(in_features=<span class="hljs-number">1</span>, out_features=<span class="hljs-number">1</span>)<br><br>model = torch.nn.Sequential(linear, sigmoid, linear2).double()<br>train_x = torch.from_numpy(x)<br><br><span class="hljs-built_in">print</span>(model(train_x).shape)<br><br>yture = torch.from_numpy(np.random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">5</span>, size=(<span class="hljs-number">100</span>, <span class="hljs-number">1</span>)))<br><br><span class="hljs-comment"># print(x)</span><br><span class="hljs-built_in">print</span>(yture.shape)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">torch.Size([100, 1])</span><br><span class="hljs-string">torch.Size([100, 1])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>loss_fn = torch.nn.MSELoss()<br>optimer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">1e-5</span>)<br><br><span class="hljs-keyword">for</span> e <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span> // <span class="hljs-number">1</span>): <span class="hljs-comment"># stochastic gradient descent</span><br>    <span class="hljs-comment"># for b in range(100 // 10): # mini-batch gradient descent</span><br>    <span class="hljs-comment"># for b in range(100 // 100): # batch gradient descent</span><br>        batch_index = np.random.choice(<span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(train_x)), size=<span class="hljs-number">20</span>)<br><br>        yhat = model(train_x[batch_index])<br>        loss = loss_fn(yhat, yture[batch_index])<br>        loss.backward()<br>        <span class="hljs-built_in">print</span>(loss)<br>        optimer.step()<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">tensor(5.0873, dtype=torch.float64, grad_fn=&lt;MseLossBackward&gt;)</span><br><span class="hljs-string">tensor(3.4337, dtype=torch.float64, grad_fn=&lt;MseLossBackward&gt;)</span><br><span class="hljs-string">show more (open the raw output data in a text editor) ...</span><br><span class="hljs-string"></span><br><span class="hljs-string">tensor(2.1481, dtype=torch.float64, grad_fn=&lt;MseLossBackward&gt;)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><br></code></pre></td></tr></table></figure>
<h2 id="matrix-dimension">Matrix dimension</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>x = torch.from_numpy(np.random.random(size=(<span class="hljs-number">4</span>, <span class="hljs-number">10</span>)))<br><span class="hljs-built_in">print</span>(x.shape)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">torch.Size([4, 10])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>model = nn.Sequential(<br>    nn.Linear(in_features=<span class="hljs-number">10</span>, out_features=<span class="hljs-number">5</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Sigmoid(),<br>    nn.Linear(in_features=<span class="hljs-number">8</span>, out_features=<span class="hljs-number">8</span>).double(),<br>    nn.Softmax()<br>)<br><br>ytrue = torch.randint(<span class="hljs-number">8</span>, (<span class="hljs-number">4</span>, ))<br><span class="hljs-built_in">print</span>(ytrue)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">tensor([4, 0, 7, 7])</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br>loss_fn = nn.CrossEntropyLoss()<br><br><span class="hljs-built_in">print</span>(model(x).shape)<br><span class="hljs-built_in">print</span>(ytrue.shape)<br>loss = loss_fn(model(x), ytrue)<br><br><span class="hljs-built_in">print</span>(torch.randint(<span class="hljs-number">5</span>, (<span class="hljs-number">3</span>, )))<br><br>loss.backward()<br><br><span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters():<br>    <span class="hljs-built_in">print</span>(p, p.grad)<br></code></pre></td></tr></table></figure>
<h2 id="advanced-deep-learning">Advanced deep learning</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Basic computing library</span><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-comment"># Deep learning library</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-comment"># Auxiliary drawing gallery</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-comment"># Time operation library</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-comment"># Progress bar control library</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br></code></pre></td></tr></table></figure>
<h3 id="project-1-forward-propagation-of-simple-neural-network">Project
1: Forward propagation of simple neural network</h3>
<h4
id="question-1-define-the-initial-parameters-and-activation-function">Question
1: Define the initial parameters and activation function</h4>
<p>You need to use numpy to implement the forward propagation process of
the neural network and calculate the final output result of the output
layer. In order to complete the above tasks, we need to make the
following assumptions: 1. The value entered is [3,5] 1. The two weights
of the hidden layer h1 are [2,4], [4,-5] 1. The two weights of the
hidden layer h2 are [-1,1], [2,2] 1. The weight of the output layer is
[-3,7] 1. All layers do not use bias 1. All hidden layers need to add
tanh activation function</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Define a numpy array with the input data of the neural network:</span><br>input_data = np.array([<span class="hljs-number">3</span>, <span class="hljs-number">5</span>])<br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Define a numpy array with the content of the hidden layer and output layer weights of the neural network:</span><br><span class="hljs-comment"># Tips: The weight dictionary has been built, you only need to fill in the corresponding value according to the hidden layer name</span><br>weights = &#123;<span class="hljs-string">&#x27;h11&#x27;</span>: np.array([<span class="hljs-number">2</span>, <span class="hljs-number">4</span>]),<br>           <span class="hljs-string">&#x27;h12&#x27;</span>: np.array([<span class="hljs-number">4</span>, -<span class="hljs-number">5</span>]),<br>           <span class="hljs-string">&#x27;h21&#x27;</span>: np.array([-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>]),<br>           <span class="hljs-string">&#x27;h22&#x27;</span>: np.array([<span class="hljs-number">2</span>, <span class="hljs-number">2</span>]),<br>           <span class="hljs-string">&#x27;out&#x27;</span>: np.array([-<span class="hljs-number">3</span>, <span class="hljs-number">7</span>])&#125;<br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Improve the following tanh activation function:</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tanh</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-keyword">return</span> (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))<br>  <br><br></code></pre></td></tr></table></figure>
<h4
id="question-2-calculate-the-neural-network-output-layer-by-layer">Question
2: Calculate the neural network output layer by layer</h4>
<p>In the calculation of the neural network, it is necessary to first
multiply the weight of the layer to be calculated with its input data,
and then sum, and then through the operation of the activation function,
it can be output to the next layer.</p>
<p>Below we will use the layer as the unit to perform calculations:</p>
<ol type="1">
<li>The first is the first hidden layer. You need to multiply, sum, and
input the data of the input layer and the weight of the hidden layer
into the activation function.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(input_data * weights[<span class="hljs-string">&#x27;h11&#x27;</span>])<br>a = tanh(input_data * weights[<span class="hljs-string">&#x27;h11&#x27;</span>]).<span class="hljs-built_in">sum</span>()<br>b = tanh((input_data * weights[<span class="hljs-string">&#x27;h11&#x27;</span>]).<span class="hljs-built_in">sum</span>())<br><span class="hljs-built_in">print</span>(a,b)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[ 6 20]</span><br><span class="hljs-string">1.9999877116507956 1.0</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> multiply, sum, and input the data of the input layer and the weight of the first hidden layer into the activation function.</span><br>hidden_11_value = tanh(input_data * weights[<span class="hljs-string">&#x27;h11&#x27;</span>]).<span class="hljs-built_in">sum</span>()<br>hidden_12_value = tanh(input_data * weights[<span class="hljs-string">&#x27;h12&#x27;</span>]).<span class="hljs-built_in">sum</span>()<br>hidden_1_output = np.array([hidden_11_value, hidden_12_value])<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">1.9999877116507956</span><br><span class="hljs-string">-7.550282621338056e-11</span><br><span class="hljs-string">[ 1.99998771e+00 -7.55028262e-11]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>Next is the second hidden layer, the operation of this layer is
exactly the same as the previous layer.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> multiply, sum, and input the data output by the upper layer and the weight of the second hidden layer into the activation function.</span><br>hidden_21_value = tanh(hidden_1_output * weights[<span class="hljs-string">&#x27;h21&#x27;</span>]).<span class="hljs-built_in">sum</span>()<br>hidden_22_value = tanh(hidden_1_output * weights[<span class="hljs-string">&#x27;h22&#x27;</span>]).<span class="hljs-built_in">sum</span>()<br>hidden_2_output = np.array([hidden_21_value, hidden_22_value])<br><br></code></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>Finally, there is the output layer. At this time, there is only one
node that needs to be calculated, and there is no need to add an
activation function.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> multiply and sum the data output by the upper layer and the weight of the output layer</span><br>output = (hidden_2_output * weights[<span class="hljs-string">&#x27;out&#x27;</span>]).<span class="hljs-built_in">sum</span>()<br></code></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>At this point, you have completed all the calculations. Now let's
print out the output of these layers and have a look.</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(output)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">9.887385002294863</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h3 id="project-2-cifar-10-image-classification">Project 2: CIFAR-10
Image Classification</h3>
<h4 id="preparation">Preparation</h4>
<p>The data set used in this project can be directly exported from the
torchvision library. Here are some basic data operations (data download
may take a few minutes, please be patient).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">##Define various transformation operations on the image, including converting the array to tensor, and regularizing the image</span><br><span class="hljs-comment">#transforms.Compose is mainly used for some common graphics transformations, such as cropping and rotation</span><br><span class="hljs-comment">#Traverse the list array and perform each transforms operation on the img in turn</span><br>transform = transforms.Compose([transforms.ToTensor(),<br>                                transforms.Normalize((<span class="hljs-number">0.4914</span>, <span class="hljs-number">0.48216</span>, <span class="hljs-number">0.44653</span>),<br>                                                     (<span class="hljs-number">0.24703</span>, <span class="hljs-number">0.24349</span>, <span class="hljs-number">0.26159</span>))))<br><span class="hljs-comment">#Export the CIFAR10 data set in torchvision. The root is the directory where the data is stored after downloading. The train controls whether it is in the training phase, the download controls whether it needs to be downloaded, and the transform passes in a series of image transformations.</span><br>trainset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;~/data/course_data/&#x27;</span>,<br>                                        train=<span class="hljs-literal">True</span>,<br>                                        download=<span class="hljs-literal">True</span>,<br>                                        transform=transform)<br>testset = torchvision.datasets.CIFAR10(root=<span class="hljs-string">&#x27;~/data/course_data/&#x27;</span>,<br>                                       train=<span class="hljs-literal">False</span>,<br>                                       download=<span class="hljs-literal">True</span>,<br>                                       transform=transform)<br><span class="hljs-comment">#Used to divide the training data into multiple groups, this function throws a group of data each time.</span><br>trainloader = torch.utils.data.DataLoader(trainset,<br>                                          batch_size=<span class="hljs-number">16</span>,<br>                                          shuffle=<span class="hljs-literal">True</span>)<br><span class="hljs-comment">#Used to divide the test data into multiple groups, this function throws a group of data each time.</span><br>testloader = torch.utils.data.DataLoader(testset,<br>                                         batch_size=<span class="hljs-number">16</span>,<br>                                         shuffle=<span class="hljs-literal">False</span>)<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ~/data/course_data/cifar-10-python.tar.gz</span><br><span class="hljs-string">170499072it [02:24, 1181561.38it/s]                               </span><br><span class="hljs-string">Extracting ~/data/course_data/cifar-10-python.tar.gz to ~/data/course_data/</span><br><span class="hljs-string">Files already downloaded and verified</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p>After the data download is complete, we can simply check the data
label to see if it is correct with the data set in the exercise
description.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python">trainset.classes<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">[&#x27;airplane&#x27;,</span><br><span class="hljs-string"> &#x27;automobile&#x27;,</span><br><span class="hljs-string"> &#x27;bird&#x27;,</span><br><span class="hljs-string"> &#x27;cat&#x27;,</span><br><span class="hljs-string"> &#x27;deer&#x27;,</span><br><span class="hljs-string"> &#x27;dog&#x27;,</span><br><span class="hljs-string"> &#x27;frog&#x27;,</span><br><span class="hljs-string"> &#x27;horse&#x27;,</span><br><span class="hljs-string"> &#x27;ship&#x27;,</span><br><span class="hljs-string"> &#x27;truck&#x27;]</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<p>Let's check the data image again.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#Display the pictures visually</span><br><span class="hljs-comment">#Define drawing function</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">imshow</span>(<span class="hljs-params">inp, title = <span class="hljs-literal">None</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># Define the canvas for drawing</span><br>    fig = plt.figure(figsize = (<span class="hljs-number">30</span>, <span class="hljs-number">30</span>))<br><br>    <span class="hljs-comment"># Convert the dimensions of the picture</span><br>    inp = inp.numpy().transpose((<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>))<br>    mean = np.array([<span class="hljs-number">0.485</span>, <span class="hljs-number">0.456</span>, <span class="hljs-number">0.406</span>])<br>    std = np.array([<span class="hljs-number">0.229</span>, <span class="hljs-number">0.224</span>, <span class="hljs-number">0.225</span>])<br><br>    <span class="hljs-comment"># Standardize the picture</span><br>    inp = std * inp + mean<br><br>    <span class="hljs-comment"># The value of the entire image array is limited to the specified value a_min, and a_max</span><br>    inp = np.clip(inp, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># Visual display of pictures</span><br>    plt.imshow(inp,)<br><br><span class="hljs-comment"># Get a batch of data</span><br>inputs, classes = <span class="hljs-built_in">next</span>(<span class="hljs-built_in">iter</span>(trainloader))<br><br><span class="hljs-comment"># Display in grid format, the function is to combine several images into one image</span><br>out = torchvision.utils.make_grid(inputs)<br><br><span class="hljs-comment"># plt.imshow() can display the picture and also display its format</span><br>imshow(out, title = [trainset.classes[x] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> classes])<br></code></pre></td></tr></table></figure>
<h4 id="question-1-build-a-simple-neural-network">Question 1: Build a
simple neural network</h4>
<p>After the data is ready, you need to build a simple neural
network.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> define a layer 3 fully connected neural network, the input dimension is 32*32*3, the output dimension of the first layer is 1000, the output dimension of the second layer is 500, and the output dimension of the third layer is 10</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Net, self).__init__()<br>        self.fc1 = nn.Linear(<span class="hljs-number">32</span>*<span class="hljs-number">32</span>*<span class="hljs-number">3</span>, <span class="hljs-number">1000</span>) <br>        self.fc2 = nn.Linear(<span class="hljs-number">1000</span>, <span class="hljs-number">500</span>) <br>        self.fc3 = nn.Linear(<span class="hljs-number">500</span>, <span class="hljs-number">10</span>) <br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = F.relu(self.fc1(x))<br>        x = F.relu(self.fc2(x))<br><br>        <span class="hljs-keyword">return</span> self.fc3(x)<br><br><span class="hljs-comment"># Instantiate the neural network class</span><br>net = Net()<br></code></pre></td></tr></table></figure>
<p>After the model structure is defined, the loss function and optimizer
need to be determined.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Define loss function-cross entropy</span><br>criterion = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># Define the optimizer, pass the parameters of the neural network to the optimizer, and define the learning rate</span><br>optimizer = optim.Adam(net.parameters(), lr = <span class="hljs-number">3e-4</span>)<br></code></pre></td></tr></table></figure>
<h4 id="question-2-neural-network-training">Question 2: Neural Network
Training</h4>
<p>The main content of the model has been completed, and the training
can be carried out below. In the process of model training, the
following steps are generally followed:</p>
<ol type="1">
<li>Big for loop-epochs, used to manage a set of data loop training
several times</li>
<li>Small for loop-step, used to retrieve data from dataloader in
batchsize unit</li>
<li>Clear the gradient of the optimizer</li>
<li>Read in data and label, and perform shape transformation (can be
done or not)</li>
<li>Run the forward propagation process of the model</li>
<li>Generate the final result based on the model output</li>
<li>Calculate the loss</li>
<li>Calculate the gradient based on the loss</li>
<li>Update parameters based on gradient</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> training model</span><br>num_epochs = <span class="hljs-number">10</span><br>since = time.time()<br>net.train()<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Epoch <span class="hljs-subst">&#123;epoch + <span class="hljs-number">1</span>&#125;</span> / <span class="hljs-subst">&#123;num_epochs&#125;</span>&#x27;</span>)<br><br>    running_loss = <span class="hljs-number">0.0</span><br>    running_corrects = <span class="hljs-number">0</span><br><br>    <span class="hljs-comment"># Take out each batch of data in a loop from the trainloader</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> tqdm(trainloader):<br>        <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Completion code</span><br>        inputs, labels = data<br>        inputs = inputs.view(-<span class="hljs-number">1</span>, <span class="hljs-number">32</span> * <span class="hljs-number">32</span> * <span class="hljs-number">3</span>)<br>        optimizer.zero_grad()<br>        outputs = net(inputs)<br>        _, preds = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br>        loss = criterion(outputs, labels)<br>        loss.backward()<br>        optimizer.step()<br><br>        <span class="hljs-comment"># Calculation of the loss function of a batch of data</span><br>        running_loss += loss.item() * inputs.size(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># Calculation of the accuracy of a batch of data</span><br>        running_corrects += torch.<span class="hljs-built_in">sum</span>(preds == labels.data)<br>    <br>    epoch_loss = running_loss / trainloader.dataset.data.shape[<span class="hljs-number">0</span>]<br>    epoch_acc = running_corrects.double() / trainloader.dataset.data.shape[<span class="hljs-number">0</span>]<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;train loss: &#123;:.4f&#125; Acc: &#123;:.4f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch_loss, epoch_acc))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;-&#x27;</span> * <span class="hljs-number">20</span>)<br><br>time_elapsed = time.time()-since<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Trainning complete in &#123;:.0f&#125;m &#123;:.0f&#125;s&#x27;</span>.<span class="hljs-built_in">format</span>(time_elapsed // <span class="hljs-number">60</span>, time_elapsed% <span class="hljs-number">60</span>))<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">Epoch 1 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:04&lt;00:00, 48.74it/s]</span><br><span class="hljs-string">train loss: 1.6377 Acc: 0.4185</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 2 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:04&lt;00:00, 48.15it/s]</span><br><span class="hljs-string">train loss: 1.4254 Acc: 0.4962</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 3 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:06&lt;00:00, 47.29it/s]</span><br><span class="hljs-string">train loss: 1.3065 Acc: 0.5372</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 4 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:04&lt;00:00, 48.76it/s]</span><br><span class="hljs-string">train loss: 1.2026 Acc: 0.5729</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 5 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:02&lt;00:00, 49.98it/s]</span><br><span class="hljs-string">train loss: 1.1129 Acc: 0.6033</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 6 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:01&lt;00:00, 51.17it/s]</span><br><span class="hljs-string">train loss: 1.0252 Acc: 0.6343</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 7 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:02&lt;00:00, 49.67it/s]</span><br><span class="hljs-string">train loss: 0.9373 Acc: 0.6668</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 8 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:02&lt;00:00, 49.63it/s]</span><br><span class="hljs-string">train loss: 0.8545 Acc: 0.6936</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 9 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:02&lt;00:00, 50.02it/s]</span><br><span class="hljs-string">train loss: 0.7770 Acc: 0.7242</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Epoch 10 / 10</span><br><span class="hljs-string">100%|██████████| 3125/3125 [01:02&lt;00:00, 50.16it/s]train loss: 0.7020 Acc: 0.7492</span><br><span class="hljs-string">--------------------</span><br><span class="hljs-string">Trainning complete in 10m 33s</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
<h4 id="question-3-model-evaluation">Question 3: Model evaluation</h4>
<p>After completing the model training, the model needs to be evaluated
to verify the accuracy of the model on the test set.</p>
<p>Tips: In the model training log, the accuracy acc is also printed,
but this is the accuracy of the model on the training set, not the
accuracy on the test set. You can observe the accuracy of the training
set and the accuracy of the test set to see if there is any
difference.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># <span class="hljs-doctag">TODO:</span> Complete model evaluation</span><br>correct, total = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>net.<span class="hljs-built_in">eval</span>()<br><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> tqdm(testloader):<br>    inputs, labels = data<br>    inputs = inputs.view(-<span class="hljs-number">1</span>, <span class="hljs-number">32</span> * <span class="hljs-number">32</span> * <span class="hljs-number">3</span>)<br>    outputs = net(inputs)<br>    _, predicted = torch.<span class="hljs-built_in">max</span>(outputs, <span class="hljs-number">1</span>)<br>    total += labels.size(<span class="hljs-number">0</span>)<br>    correct += (predicted == labels).<span class="hljs-built_in">sum</span>().item()<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;The testing set accuracy of the network is: %d %%&#x27;</span>% (<span class="hljs-number">100</span> * correct / total))<br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">100%|██████████| 625/625 [00:03&lt;00:00, 157.71it/s]The testing set accuracy of the network is: 53 %</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br></code></pre></td></tr></table></figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>Advanced Deep Learning</p><p><a href="https://hivan.me/example_07/">https://hivan.me/example_07/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-09-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-02</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/example_08/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">RNN</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/example_02/"><span class="level-item">Initial exploration of machine learning</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/example_07/';
            this.page.identifier = 'example_07/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">168</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/"><span class="level-start"><span class="level-item">AI秘籍</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-07T11:40:50.000Z">2023-08-07</time></p><p class="title"><a href="/Detailed-of-dictonary/">11. 数据类型 - 字典</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-07T03:44:38.000Z">2023-08-07</time></p><p class="title"><a href="/Detailed-of-tuple/">10. 数据类型 - 元组详解</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-06T06:45:03.000Z">2023-08-06</time></p><p class="title"><a href="/Detailed-of-list/">9. 数据类型 - 列表详解</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-05T03:28:07.000Z">2023-08-05</time></p><p class="title"><a href="/Detailed-of-string/">8. 数据类型 - 字符串详解</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-08-04T08:13:00.000Z">2023-08-04</time></p><p class="title"><a href="/python-Built-in-functions/">7. Python的内置函数</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>