<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>32. 深度学习进阶 - Transfer Learning - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content=""><meta property="og:type" content="blog"><meta property="og:title" content="32. 深度学习进阶 - Transfer Learning"><meta property="og:url" content="https://hivan.me/32.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20Transfer%20Learning/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-12-23T23:30:00.000Z"><meta property="article:modified_time" content="2023-12-24T05:54:53.573Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI"><meta property="twitter:card" content="summary"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/32.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20Transfer%20Learning/"},"headline":"32. 深度学习进阶 - Transfer Learning","image":[],"datePublished":"2023-12-23T23:30:00.000Z","dateModified":"2023-12-24T05:54:53.573Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":""}</script><link rel="canonical" href="https://hivan.me/32.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20Transfer%20Learning/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?f91b64734fdc7bfb999e48f9248d44dd";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-ZFB6CVWZFJ" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-ZFB6CVWZFJ');</script><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2023-12-23T23:30:00.000Z" title="12/24/2023, 7:30:00 AM">2023-12-24</time>发表</span><span class="level-item"><a class="link-muted" href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a><span> / </span><a class="link-muted" href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></span></div></div><h1 class="title is-3 is-size-4-mobile">32. 深度学习进阶 - Transfer Learning</h1><div class="content"><p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925028.png"
alt="Alt text" /></p>
<span id="more"></span>
<p>Hi，你好。我是茶桁。</p>
<p>之前的课程中，咱们学习了CNN的原理，学习了pooling, fully
connected是做什么的。还了解了理论上简单的模型也是可以做事情的，只不过在特定的一些情况下要解决问题的时候简单方法效果不太好，所以用了像LSTM，或者RNN、CNN之类的结构。</p>
<p>这些本质上都是在做特征的提取。一个经典的观念是，神经网络其实一共都可以分成两个部分，第一个部分是特征提取，第二个部分是分类器。像fully
connected layer，其实就是之后再加上一个Softmax或者log
Softmax，在做分类器的实现。</p>
<p>前面在进入全连接层之前，也在进入Softmax或者log
Softmax之前，全部做的都是特征提取的事。</p>
<p>不管你是线性函数，就线性变化全连接的这种网络，还是RNN，LSTM或者CNN等等，在进入Softmax之前，这些都是在做特征提取。</p>
<p>Hinton当时的说法我觉得说的很有道理，就说「<strong>特征提取的作用是让相似的东西不相似，让不相似的相似</strong>」。</p>
<p>意思就是，我们对于任何一个神经网络来说，到最终的这个全连接，加上Softmax，之前的这些东西不管你是输入的是一个图片还是几个文字，还是说一串数据。所谓的让看起来相似的东西不相似是如果有两个图片，或者两组数据，他们在我们人看起来是比较类似的。但是假设他们的label不一样的话，我们整个特征提取的过程是把输入的这两个x，人看起来是一样的，在最后输出的这个地方要尽可能的不一样。所以送到分类器里边，它们结果差距才能大。</p>
<p>如果这两个东西看起来很不一样，就假如说有两只猫，一只猫特别瘦，黑黑的。一只是橘猫，特别的胖，大小也不一样。但这个在图片来说这差距是很大的。我们整个做feature
extraction的时候是要把这两张图在最后变成一样，就在最后的时候变得相似。输入的时候不相似，但是经过特征提取其实要把它变相似。这样送入到了Softmax它才会产生分类的作用。</p>
<p>接下来讲了卷积神经网络的计算过程以及整个模型的搭建是什么样的。然后还讲了RES-NET的原理，这个也需要去理解。</p>
<h2 id="transfer-learning">Transfer Learning</h2>
<p>那么现在，咱们今天就跟大家来介绍一个比较重要的概念，深度学习共同的基础部分，就是<code>transfer learning</code>。</p>
<p>咱们现在的这个深度学习模型变得越来越复杂了。上节课给大家举过这些例子，不同的人提出来了不同的模型，
重点给大家介绍了一个RES-NET和Inception model，也称为GoogleNET。</p>
<p>模型现在其实已经变得越来越复杂，这么复杂的结果是什么呢？结果是我们现在已经很难从头到尾搭建一个模型了。现在的模型结构已经这么复杂了，很少有人能有时间，或者在工作的时候有时间、有精力能从零开始一层一层的去做搭建，这是第一方面。</p>
<p>第二个方面，大家还发现一个特点。在结构中越接近前边虽然任务不一样，比如解决动物分类或者解决人物分类，但是越靠近前边，它们的特征相似度越高。</p>
<p>换句话说，有一个RES-NET专门对人物分类，还有一个是是专门做动物，它们分的类别完全不一样。但是就前边这些CNN的结果往往都很相似，而且是越往前越相似。</p>
<p>这是因为这些过程都是在做特征提取，如果都是一个比较相似的图片任务的话，在这个过程中特征提取其实从刚开始的时候在解析图片上的重要程度，其实要提取的东西都是类似的。</p>
<p>比方说识别我左手的水和我右手的手机，还有我前面站着一个美女，刚开始都是要识别它的轮廓。然后都要识别它的局部的形状，还要识别颜色...
这样的一个直接的结果，其实我们每一层用的filter都是类似的，只要达到一个比较好的结果，前面的这些filter都是类似的。</p>
<p>filter类似是因为filter控制的是我们要提取什么重要特征。那么我们就发现从前到后，其实越是前边越是比较简单的特征，线、块这些，到后边越来越综合。</p>
<p>有了这个之后大家就发现，既然现在模型这么复杂，从头到尾要搭建一个模型已经很难了，我们可以直接用这个模型的结构。</p>
<p>第二我们发现不仅模型的结构可以，模型的权重都也可以。可以用这个模型的权重来训练，直接把这个模型的权重拿过来。</p>
<p>其实也就是说，我们可以直接下载一个模型，把别人训练好的权重一起拿过来，这些东西就是一堆数字。然后它是在task
a上弄的，我把它用到了task
b上。训练的时候让它不要进行反向传播，在进入全连接层的时候再进行反向传播。</p>
<p>大家把这种学习方式就叫做<code>transfer Learning</code>，
迁移学习。我们平时日常在工作的时候经常会这么做。</p>
<p>客观上来讲，不同的任务，任务越类似肯定迁移的时候越好迁移。所以说其实它和任务的相似度以及和数据量的相对大小很有关系。</p>
<p>假设我们两个任务，A和B。这两个任务，A是分类狗，B是分类狼，A原本训练数据集是100W，B的训练集是1W。那么这两个任务比较而言，任务相似度非常大，原任务相对新任务数据量比较大，这个时候基本上迁移学习就非常好迁移，我们都可以不去更改进入全连接层之前的所有内容就可以进行迁移，只需要更改全连接层。也就是特征提取的部分完全平移。</p>
<p>那么如果A任务还是分类狗，B任务是分类汽车。A原本训练数据集是100W，B的训练集是5000W。那这两个任务比较而言，任务相似度非常小，原任务相对新任务数据量是小的，这个时候迁移学习就变得很困难，可能也只有图像线条，颜色这些个特征提取的部分可以迁移，基本是特征提取的最前边的部分。</p>
<p>所以，Transfer
Learning的容易程度，在一个二维平面直角坐标系内的两个相关项，也就是x和y轴就是任务相似度和原任务相对新任务数据量的大小。</p>
<p>如果重新训练，怎么样来transfer呢？说了这么多，还是直接来看一个实例,
来看看我们具体该如何做「冻结」。</p>
<p>用的这个数据集,
cifar10，这也是一个很经典的数据，它是十个典型的很常见的物品的分类。</p>
<p>咱们先引入必要的库，然后down数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> icecream <span class="hljs-keyword">import</span> ic<br><br><br>cifar_10 = torchvision.datasets.CIFAR10(<span class="hljs-string">&#x27;.&#x27;</span>, download=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>这个文件一共170多兆，大部分人物提取的特征差不多，所以权重可以不用更新，用其他相似任务的参数，相当于新模型初始化的时候，理解为更接近在最优点附近。</p>
<p>它里面的每一个数据的类型是一个PRL的image,
要在PyTorch里对这个图片进行使用，我们需要进行一个预处理。我们需要在前面定义一个方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">preprocess = transforms.Compose([<br>    transforms.Resize(<span class="hljs-number">224</span>),<br>    transforms.CenterCrop(<span class="hljs-number">224</span>),<br>    transforms.ToTensor()<br>])<br></code></pre></td></tr></table></figure>
<p>首先, 我们要先Resize，然后用一个CenterCrop，
让图片以中心扩散进行切割。如果有些图片不是正方形，那么第二个操作就是把中间的部分裁一个正方形出来。最后再把它变成一个Tensor。</p>
<p>然后我们需要修改一下数据获取数据时的<code>transform</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cifar_10 = torchvision.datasets.CIFAR10(<span class="hljs-string">&#x27;.&#x27;</span>, download=<span class="hljs-literal">True</span>, transform=preprocess)<br></code></pre></td></tr></table></figure>
<p>现在看一下, cifar_10的数据就变成tensor了，shape是[3,224,224]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">cifar_10[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].shape<br><br>---<br>torch.Size([<span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>])<br></code></pre></td></tr></table></figure>
<p>得到Tensor数据之后，要训练的时候得一次一次的取不同的数值出来，我们要做SGD，随机梯度下降。那么在做这个的时候有一种方法，写个复循环然后每次随机取一些index，再把这些index的值给它取出来，这是一种方法。</p>
<p>还有一种方法，我们可以直接用<code>DataLoader</code>，声明了之后每次要生成一个迭代器，每次会输出一些内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">train_loader = torch.utils.data.DataLoader(cifar_10, batch_size=<span class="hljs-number">512</span>, shuffle=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>如果要把所有的数据传输进去，它有5万个照片太大了，内存吃不消。所以要把它做成SGD，要每次随机取一个东西。</p>
<p>然后我们来定义一个RES-NET：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">resnet = torchvision.models.resnet18()<br></code></pre></td></tr></table></figure>
<p>有了这样的RES-NET之后，它输出的是1000维的，而我们这里其实是需要一个10维的，那我们就需要把它的最后一层给它重新做一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_num = resnet.fc.in_features<br>resnet.fc = nn.Linear(feature_num, <span class="hljs-number">10</span>)<br></code></pre></td></tr></table></figure>
<p>如果我们没有这一句，我们可以来看看它会输出什么。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">ic(resnet(cifar_10[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].unsqueeze(<span class="hljs-number">0</span>)))<br><br>---<br>ic| resnet(cifar_10[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].unsqueeze(<span class="hljs-number">0</span>)): tensor([[-<span class="hljs-number">6.9484e-01</span>, ..., <span class="hljs-number">1008e+00</span>]], grad_fn=&lt;AddmmBackward0&gt;)<br>tensor([[-<span class="hljs-number">6.9484e-01</span>, ..., <span class="hljs-number">1.1008e+00</span>]],<br>       grad_fn=&lt;AddmmBackward0&gt;)<br></code></pre></td></tr></table></figure>
<p>输出的是一个很长的东西，其实是有1,000维的，这里输出了1,000个。</p>
<p>现在如果把它的最后一层全连接层改了，变成10分类，因为这个cifar10是一个是分类问题。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">feature_num = resnet.fc.in_features<br>resnet.fc = nn.Linear(feature_num, <span class="hljs-number">10</span>)<br>ic(resnet(cifar_10[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].unsqueeze(<span class="hljs-number">0</span>)))<br></code></pre></td></tr></table></figure>
<p>改完之后输出的数据就是10维的了，大家可以自己去跑一下代码，我这里就不贴了。</p>
<p>接着我们再来生成一个loss函数和一个优化器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">criterion = nn.CrossEntropyLoss()<br>optimizer = torch.optim.SGD(resnet.parameters(), lr=<span class="hljs-number">1e-3</span>, momentum=<span class="hljs-number">0.9</span>)<br></code></pre></td></tr></table></figure>
<p>criterion是测量尺度、考核标准的意思。parameters是要把所有参数进行拟合，
进行重新训练。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs python">epochs = <span class="hljs-number">2</span><br>losses = []<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    epoch_loss = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i, (images, labels) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_loader):<br>        ic(epoch, i)<br>        predicts = resnet(images)<br>        loss = criterion(output, labels)<br>        optimizer.zero_grad()<br><br>        loss.backward()<br>        optimizer.step()<br><br>        epoch_loss += loss.item()<br><br>        <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Epoch: &#123;&#125; batch: &#123;&#125;, loss ==&gt; &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, i, epoch_loss / i))<br>    losses.append(epoch_loss / i)<br><br>plt.plot(losses)<br><br>---<br><br>0it [<span class="hljs-number">00</span>:<span class="hljs-number">00</span>, ?it/s]<br>ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">0</span><br>1it [<span class="hljs-number">00</span>:<span class="hljs-number">53</span>, <span class="hljs-number">53.71</span>s/it]ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">1</span><br>2it [01:<span class="hljs-number">42</span>, <span class="hljs-number">50.98</span>s/it]<br>Epoch: <span class="hljs-number">0</span> batch: <span class="hljs-number">1</span>, loss ==&gt; <span class="hljs-number">4.71190333366394</span><br>ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">2</span><br>...<br>98it [<span class="hljs-number">1</span>:<span class="hljs-number">12</span>:04, <span class="hljs-number">44.13</span>s/it]<br>Epoch: <span class="hljs-number">1</span> batch: <span class="hljs-number">97</span>, loss ==&gt; <span class="hljs-number">1.7719330222336287</span><br></code></pre></td></tr></table></figure>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925029.png"
alt="Alt text" /></p>
<p>现在是这么个结果, 我们先来保存一下，我创建了一个32.log,
用于暂时保存咱们的结果。那因为我训练的时候加了一个tqdm，所以也把时间打印了出来，不过为了避免代码上的误解，所以代码我还是给的没有加tqdm的样子。</p>
<p>现在要迁移怎么迁移呢？很简单，第一步我们需要改一下我们的RES-NET。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">resnet = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>我们加一个参数<code>pretrained</code>，然后将值设为<code>True</code>，现在要保留它的数据，保留之前训练的权重。</p>
<p>第二步要冻结它的这些参数，把RES-NET里边所有的parameters，每一个都有一个requires
grad，给它定义成false。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> resnet.parameters():<br>    param.requires_grad = <span class="hljs-literal">False</span> <span class="hljs-comment"># frozen weights</span><br></code></pre></td></tr></table></figure>
<p>设置成false之后进行反向传播的时候这个值就不更新了。不更新的话那就相当于冻结了。</p>
<p>之前写的<code>resnet.fc</code>就相当于重写了fc分类层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">resnet.fc = nn.Linear(feature_num, <span class="hljs-number">10</span>) <span class="hljs-comment"># rewrite fc classifier</span><br></code></pre></td></tr></table></figure>
<p>假设现在的任务和原来任务不相似，或者说现在原来数据量和现在数据量相比偏小，那么对于这个RES-NET，不能把它所有的requires
grad设置成false，要把它前面部分的给它设置成false，后边设置成true。</p>
<p>重写了这个FC
classifire之后，新声明的参数默认它是需要进行梯度下降的，所以不需要在这写成false。就在这里，这个FC的grad默认是true。</p>
<p>那到这一步， transfer就结束了，我们可以重新训练来看看。</p>
<p>你会发现，时间上明显快多了。这个就是因为咱们这次训练的参数少了很多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">0it [<span class="hljs-number">00</span>:<span class="hljs-number">00</span>, ?it/s]ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">0</span><br>1it [<span class="hljs-number">00</span>:<span class="hljs-number">17</span>, <span class="hljs-number">17.99</span>s/it]ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">1</span><br>2it [<span class="hljs-number">00</span>:<span class="hljs-number">34</span>, <span class="hljs-number">16.92</span>s/it]<br>Epoch: <span class="hljs-number">0</span> batch: <span class="hljs-number">1</span>, loss ==&gt; <span class="hljs-number">5.019284725189209</span><br>ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">2</span><br>3it [<span class="hljs-number">00</span>:<span class="hljs-number">50</span>, <span class="hljs-number">16.54</span>s/it]<br>Epoch: <span class="hljs-number">0</span> batch: <span class="hljs-number">2</span>, loss ==&gt; <span class="hljs-number">3.7500953674316406</span><br>ic| epoch: <span class="hljs-number">0</span>, i: <span class="hljs-number">3</span><br>...<br>98it [<span class="hljs-number">26</span>:04, <span class="hljs-number">15.96</span>s/it]<br>Epoch: <span class="hljs-number">1</span> batch: <span class="hljs-number">97</span>, loss ==&gt; <span class="hljs-number">1.108948134884392</span><br>...<br></code></pre></td></tr></table></figure>
<p>之前我们每一轮训练几乎都要花个50s左右，现在基本在16左右，速度上提升了3倍。从总时间上我们也可以看出来，训练速度提升了好几倍，从原来的一小时12分钟，直接降到了26分钟。并且，loss也有所提升。</p>
<p>那么我们该怎么去看这个模型的层数，确定哪些是在前面部分，哪些实在后面呢？对于一个模型而言，最简单的办法就是直接print出来，比如说咱们的resnet18：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision.models <span class="hljs-keyword">import</span> resnet18<br><span class="hljs-built_in">print</span>(resnet18())<br><br>---<br>ResNet(<br>  (conv1): Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">7</span>, <span class="hljs-number">7</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), bias=<span class="hljs-literal">False</span>)<br>  (bn1): BatchNorm2d(<span class="hljs-number">64</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>  (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>  (maxpool): MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>, dilation=<span class="hljs-number">1</span>, ceil_mode=<span class="hljs-literal">False</span>)<br>  (layer1): Sequential(<br>    (<span class="hljs-number">0</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">64</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">64</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>    )<br>    (<span class="hljs-number">1</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">64</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">64</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>    )<br>  )<br>  (layer2): Sequential(<br>    (<span class="hljs-number">0</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">128</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">128</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (downsample): Sequential(<br>        (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), bias=<span class="hljs-literal">False</span>)<br>        (<span class="hljs-number">1</span>): BatchNorm2d(<span class="hljs-number">128</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      )<br>    )<br>    (<span class="hljs-number">1</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">128</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">128</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">128</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>    )<br>  )<br>  (layer3): Sequential(<br>    (<span class="hljs-number">0</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">256</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">256</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (downsample): Sequential(<br>        (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), bias=<span class="hljs-literal">False</span>)<br>        (<span class="hljs-number">1</span>): BatchNorm2d(<span class="hljs-number">256</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      )<br>    )<br>    (<span class="hljs-number">1</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">256</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">256</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">256</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>    )<br>  )<br>  (layer4): Sequential(<br>    (<span class="hljs-number">0</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">512</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">512</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (downsample): Sequential(<br>        (<span class="hljs-number">0</span>): Conv2d(<span class="hljs-number">256</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), stride=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), bias=<span class="hljs-literal">False</span>)<br>        (<span class="hljs-number">1</span>): BatchNorm2d(<span class="hljs-number">512</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      )<br>    )<br>    (<span class="hljs-number">1</span>): BasicBlock(<br>      (conv1): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn1): BatchNorm2d(<span class="hljs-number">512</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>      (relu): ReLU(inplace=<span class="hljs-literal">True</span>)<br>      (conv2): Conv2d(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), stride=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), padding=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), bias=<span class="hljs-literal">False</span>)<br>      (bn2): BatchNorm2d(<span class="hljs-number">512</span>, eps=<span class="hljs-number">1e-05</span>, momentum=<span class="hljs-number">0.1</span>, affine=<span class="hljs-literal">True</span>, track_running_stats=<span class="hljs-literal">True</span>)<br>    )<br>  )<br>  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>  (fc): Linear(in_features=<span class="hljs-number">512</span>, out_features=<span class="hljs-number">1000</span>, bias=<span class="hljs-literal">True</span>)<br>)<br></code></pre></td></tr></table></figure>
<p>这次我将结果打全，我们可以清晰的看到这个模型里从上到下，从前到后的每一层，最后一层是一个fc。</p>
<p>那除此之后，其实我们可以借用第三方库来进行计算，有一个库叫做<code>torchsummary</code>，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchsummary <span class="hljs-keyword">import</span> summary<br>summary(resnet18(), (<span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>))<br><br>---<br>----------------------------------------------------------------<br>        Layer (<span class="hljs-built_in">type</span>)               Output Shape         Param <span class="hljs-comment">#</span><br>================================================================<br>            Conv2d-<span class="hljs-number">1</span>         [-<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, <span class="hljs-number">112</span>, <span class="hljs-number">112</span>]           <span class="hljs-number">9</span>,<span class="hljs-number">408</span><br>            ...<br>AdaptiveAvgPool2d-<span class="hljs-number">67</span>            [-<span class="hljs-number">1</span>, <span class="hljs-number">512</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]               <span class="hljs-number">0</span><br>           Linear-<span class="hljs-number">68</span>                 [-<span class="hljs-number">1</span>, <span class="hljs-number">1000</span>]         <span class="hljs-number">513</span>,<span class="hljs-number">000</span><br>================================================================<br>Total params: <span class="hljs-number">11</span>,<span class="hljs-number">689</span>,<span class="hljs-number">512</span><br>Trainable params: <span class="hljs-number">11</span>,<span class="hljs-number">689</span>,<span class="hljs-number">512</span><br>Non-trainable params: <span class="hljs-number">0</span><br>----------------------------------------------------------------<br>Input size (MB): <span class="hljs-number">0.57</span><br>Forward/backward <span class="hljs-keyword">pass</span> size (MB): <span class="hljs-number">62.79</span><br>Params size (MB): <span class="hljs-number">44.59</span><br>Estimated Total Size (MB): <span class="hljs-number">107.96</span><br>----------------------------------------------------------------<br></code></pre></td></tr></table></figure>
<p>这个去监测模型的层数和信息就更好一些，可以很直观的看到每一层以及整个模型的相关信息。不管是你自己的模型还是第三方预先训练好的其实都可以。我们在后面设置了一下输入的大小，设置了之后，summary在后面参数一共多少就一个一个都给你显示出来了。我们刚才输入的(3,
224,
224)，然后从第一层开始的<code>Output Shape</code>是多少，一层一层的向下就直接有了。</p>
<p>这两个方式都还是很有用的。</p>
<p>那么之后做训练的时候大家要对几个数字稍微多一点敏感性，我们来看，首先我们定义一个loss函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">cross_entropy</span>(<span class="hljs-params">y, yhat</span>): <span class="hljs-keyword">return</span> -np.<span class="hljs-built_in">sum</span>(y*np.log2(yhat))<br></code></pre></td></tr></table></figure>
<p>然后我们输入下面几个值做测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">cross_entropy([<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0.5</span>]*<span class="hljs-number">2</span>)<br>cross_entropy([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0.2</span>]*<span class="hljs-number">5</span>)<br>cross_entropy([<span class="hljs-number">0</span>]*<span class="hljs-number">9</span> + [<span class="hljs-number">1</span>], [<span class="hljs-number">0.1</span>] * <span class="hljs-number">10</span>)<br>cross_entropy([<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0.33</span>] * <span class="hljs-number">3</span>)<br><br>---<br><span class="hljs-number">1.0</span><br><span class="hljs-number">2.321928094887362</span><br><span class="hljs-number">3.321928094887362</span><br><span class="hljs-number">1.5994620704162712</span><br></code></pre></td></tr></table></figure>
<p>transfer
learning基于的是模型从前往后。前面层学的东西比较基础，到后边学的抽象层次越来越高，看到的是更复杂的一些。</p>
<p>那咱们现在就再来演示一下它到底学的学到都是什么东西。那么为了看一下这个到底学的是什么，我再次贡献一下自己。</p>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925030.png"
alt="Alt text" /></p>
<p>这个是早些时候我一个同学帮我画的头像，就拿它来看吧。</p>
<p>首先，我们前面看到打印结果了，resnet18的第一层是conv1，我们来看看第一层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br>preprocess = transforms.Compose([<br>    transforms.Resize(<span class="hljs-number">224</span>),<br>    transforms.CenterCrop(<span class="hljs-number">224</span>),<br>    transforms.ToTensor()<br>])<br>resnet = torchvision.models.resnet18(pretrained=<span class="hljs-literal">True</span>)<br><br>myself = preprocess(Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;./assets/chaheng2.png&#x27;</span>))<br>resnet.conv1(myself.unsqueeze(<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure>
<p>然后我们就可以看到一堆的tensor数据，这个<code>unsqueeze</code>是将数据改变了一下结构，从<code>myself</code>变成了<code>[[myself]]</code>，改成这样是因为torch每次接收的是一个batch的东西，直接输入一个图片是不行的。</p>
<p>我们看一下它的这个输出,第一个卷积的输出是什么：</p>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925031.png"
alt="Alt text" /></p>
<p>我们可以看到，它的shape是<code>[1, 64, 112, 112]</code>,那这里边的分别是什么？</p>
<p>第一个维度，这个1是batch的数量。64是filter的channel，所以它输出了64张图片。
后面的112和112是一组数据，从这个数据来看，这个图片经过卷积之后，经历了一个缩小的变化。从原来的224缩小到了112，
经历了一个下采样。</p>
<p>接着咱们来看一下具体的数据内容，看看output第0个的内容是什么样的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">plt.imshow(output[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>].detach())<br></code></pre></td></tr></table></figure>
<p>因为结果还在内存里，所以我们永乐一个<code>detach()</code>。</p>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925032.png"
alt="Alt text" /></p>
<p>它把我的轮廓给提出来了。</p>
<p>我们再来看看别的是什么样，我们改成<code>[0][2]</code>：</p>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925033.png"
alt="Alt text" /></p>
<p>这个貌似是将背景扣了。</p>
<p>我们不一张一张来看了，咱们来将探索过程写个循环，看一下它到底都做了什么。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">width = <span class="hljs-number">8</span><br>fig, ax = plt.subplots(output[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>] // width, width, figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">20</span>))<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(output[<span class="hljs-number">0</span>].shape[<span class="hljs-number">0</span>]):<br>    ix = np.unravel_index(i, ax.shape)<br>    plt.sca(ax[ix])<br>    ax[ix].title.set_text(<span class="hljs-string">&#x27;filter-&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(i))<br><br>    plt.imshow(output[<span class="hljs-number">0</span>][i].detach())<br><br>plt.show()<br></code></pre></td></tr></table></figure>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925034.png"
alt="Alt text" /></p>
<p>它这64个学到的几乎每个都不一样，那有些是有用的，有些是没用的。有些是从边缘层面上，比如说filter20就是从边缘上，而有一些，比如filter21就是从颜色上。</p>
<p>那么如果我们现在想把第二个、第三个、第四个这些都拿出来的话怎么办？当然理论上可以沿着它的结构给一层一层解出来，但是PyTorch里面给咱们的提供了一个比较简单的方法。</p>
<p>那刚才写的那个代码，其实是在进行前向传播，就我们刚才写代码就是在模拟它的前向传播，forward。PyTorch就给我们提供了一个很方便东西，它可以给前向传播及反向传播的时候注册一个函数。就比如说：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">conv_model = [m <span class="hljs-keyword">for</span> _, m <span class="hljs-keyword">in</span> resnet.named_modules() <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, torch.nn.Conv2d)]<br><br><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> conv_model:<br>    m.register_forward_hook()<br></code></pre></td></tr></table></figure>
<p>我们现在把resnet里边所有的model拿出来，然后如果这个model它是卷机，给这些所有的模型注册一个函数。这个函数是是他在进行前向传播的时候会自己调用的，就不需要咱们再手动的去写了。</p>
<p>那我们现在就来将之前写的内容抽象成一个函数<code>visualize_model</code>，在定义这个函数的时候需要注意一下PyTorch的相关API，</p>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925035.png"
alt="Alt text" /></p>
<p>那我们在定义的时候，也就需要一样传递这些参数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">visualize_model</span>(<span class="hljs-params">model, input_, output</span>):<br>    width = <span class="hljs-number">8</span><br>    ...<br>    plt.show()<br></code></pre></td></tr></table></figure>
<p>这样前向传播的时候,它会自动调用。现在我们就可以让它来进行前向传播：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> conv_model:<br>    m.register_forward_hook(visualize_model)<br><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    resnet(myself.unsqueeze(<span class="hljs-number">0</span>))<br></code></pre></td></tr></table></figure>
<p><code>no_grad</code>的意思是不让它进行反向传播，只进行前向传播。</p>
<p>我们在观察它每一层的结果的时候，就会发现越到后面就越抽象，我们捡中间某一张贴出来来看。</p>
<p><img
src="https://raw.githubusercontent.com/hivandu/notes/main/img/202311131925036.png"
alt="Alt text" /></p>
<p>就基本上，这个时候还能勉强辨认出是个任务头像，再往后的结果，我肉眼已经分辨不出来它是个啥了。就这是整个模型一层一层学到的东西，它里边是从刚开始的时候比较的底层、比较的基础，后边会提取的东西越来越多。</p>
<p>就咱们在这里所做的这种权重可视化，有一个比较有趣的应用：<code>deep dream</code>，它就是将刚才这些学到的靠后的权重，然后应用到一张图片上。就我们刚刚可视化那种层数再应用到一些新图片上，就会产生这样的效果。如果感兴趣的可以自己试一下。</p>
<p>好那咱们这个RES-NET和RES-NET可视化，以及transfer
learning的内容，到这里就可以告一段落了。整个的深度学习的基础部分，也就到这里结束了。</p>
<p>最后，我们来留一个小作业。</p>
<h2 id="作业">作业</h2>
<p>那么本节课的最后，给大家留一个小作业，稍微还是有点难度的，需要大家自己去查阅相关手册才行，不过知识点都是讲过的。作业内容为<strong>「对验证码进行识别」</strong>。</p>
<blockquote>
<ol type="1">
<li><p>练习内容：
训练一个模型，对验证码中的字符进行分类识别，并最终完成验证码识别的任务。</p></li>
<li><p>数据集：
数据集内包含0-9以及A-Z一共36个字符，训练集中每个字符有50张图片，验证集中每个字符有10张图片，验证码数据集是由随机去除的4个字符图片拼接而成。</p></li>
<li><p>需要的相关知识：</p></li>
</ol>
<ul>
<li>数据读取</li>
<li>使用torch搭建、训练、验证模型</li>
<li>模型预测于图片切分</li>
</ul>
</blockquote>
<p>好，给大家提供下思路，我们将我们需要解决的问题分成四步：第一个，先建立字符对照表，第二个，要定义一个<code>datasets</code>和一个<code>dataloader</code>。
第三个，需要定义网络结构。 第四个，定义模型训练函数。
最后，就是验证训练结果。</p>
<p>数据集请关注「坍缩的奇点」后从原文下载。https://mp.weixin.qq.com/s/v_4OOMB_Gg-a1V3a399NEQ</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>32. 深度学习进阶 - Transfer Learning</p><p><a href="https://hivan.me/32. 深度学习进阶 - Transfer Learning/">https://hivan.me/32. 深度学习进阶 - Transfer Learning/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-12-24</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-12-24</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/AI/">AI</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/31.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%8F%8A%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"><span class="level-item">31. 深度学习进阶 - 全连接层及网络结构</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/32.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20Transfer%20Learning/';
            this.page.identifier = '32. 深度学习进阶 - Transfer Learning/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">203</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">5</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">22</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/"><span class="level-start"><span class="level-item">AI秘籍</span></span><span class="level-end"><span class="level-item tag">61</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Math/"><span class="level-start"><span class="level-item">Math</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/"><span class="level-start"><span class="level-item">核心能力基础</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-23T23:30:00.000Z">2023-12-24</time></p><p class="title"><a href="/32.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20Transfer%20Learning/">32. 深度学习进阶 - Transfer Learning</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-19T23:30:00.000Z">2023-12-20</time></p><p class="title"><a href="/31.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%8F%8A%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/">31. 深度学习进阶 - 全连接层及网络结构</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-16T23:30:00.000Z">2023-12-17</time></p><p class="title"><a href="/30.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20%E6%B1%A0%E5%8C%96/">30. 深度学习进阶 - 池化</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-12T23:30:00.000Z">2023-12-13</time></p><p class="title"><a href="/29.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20%E5%8D%B7%E7%A7%AF%E7%9A%84%E5%8E%9F%E7%90%86/">29. 深度学习进阶 - 卷积的原理</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-09T23:30:00.000Z">2023-12-10</time></p><p class="title"><a href="/28.%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BF%9B%E9%98%B6%20-%20LSTM/">28. 深度学习进阶 - LSTM</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/%E6%A0%B8%E5%BF%83%E8%83%BD%E5%8A%9B%E5%9F%BA%E7%A1%80/">核心能力基础</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>