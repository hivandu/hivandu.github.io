<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Machine Learning Part-02 - 茶桁.MAMT</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="茶桁.MAMT"><meta name="msapplication-TileImage" content="https://qiniu.hivan.me/picGo/20230601174411.png?imgNote"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="茶桁.MAMT"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Data Pre-processing Feature-Extractor Split Training, Test, Validation Build Model Gradient Descent Evaluation Predicat Analysis"><meta property="og:type" content="blog"><meta property="og:title" content="Machine Learning Part-02"><meta property="og:url" content="https://hivan.me/example_04/"><meta property="og:site_name" content="茶桁.MAMT"><meta property="og:description" content="Data Pre-processing Feature-Extractor Split Training, Test, Validation Build Model Gradient Descent Evaluation Predicat Analysis"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831230756.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831230855.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831230921.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831230945.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831231306.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831231410.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831231740.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831232005.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831232124.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233019.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233046.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233103.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233425.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233620.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233717.png?imgNote"><meta property="og:image" content="https://qiniu.hivan.me/picGo/20210831233740.png?imgNote"><meta property="article:published_time" content="2021-09-02T12:59:46.686Z"><meta property="article:modified_time" content="2023-06-02T03:48:50.794Z"><meta property="article:author" content="Hivan Du"><meta property="article:tag" content="AI,人工智能,代码,大语言模型"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://qiniu.hivan.me/picGo/20210831230756.png?imgNote"><meta property="twitter:creator" content="@hivan"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hivan.me/example_04/"},"headline":"Machine Learning Part-02","image":[],"datePublished":"2021-09-02T12:59:46.686Z","dateModified":"2023-06-02T03:48:50.794Z","author":{"@type":"Person","name":"Hivan Du"},"publisher":{"@type":"Organization","name":"茶桁.MAMT","logo":{"@type":"ImageObject","url":"https://hivan.me/img/logo.svg"}},"description":"Data Pre-processing Feature-Extractor Split Training, Test, Validation Build Model Gradient Descent Evaluation Predicat Analysis"}</script><link rel="canonical" href="https://hivan.me/example_04/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-09-02T12:59:46.686Z" title="9/2/2021, 8:59:46 PM">2021-09-02</time>发表</span></div></div><h1 class="title is-3 is-size-4-mobile">Machine Learning Part-02</h1><div class="content"><ul>
<li>Data</li>
<li>Pre-processing</li>
<li>Feature-Extractor</li>
<li>Split Training, Test, Validation</li>
<li>Build Model</li>
<li>Gradient Descent</li>
<li>Evaluation</li>
<li>Predicat</li>
<li>Analysis</li>
</ul>
<span id="more"></span>
<p>House Price Regression</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## load data</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="comment">## ususlly will load in csv</span></span><br><span class="line">data = load_boston()</span><br><span class="line"><span class="built_in">print</span>(data[<span class="string">&#x27;DESCR&#x27;</span>])</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">_boston_dataset:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Boston house prices dataset</span></span><br><span class="line"><span class="string">---------------------------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">**Data Set Characteristics:**  </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :Number of Instances: 506 </span></span><br><span class="line"><span class="string">show more (open the raw output data in a text editor) ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Morgan Kaufmann.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df = pd.DataFrame(data[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">df.columns = data[<span class="string">&#x27;feature_names&#x27;</span>]</span><br><span class="line">df[df[<span class="string">&#x27;CHAS&#x27;</span>] == <span class="number">1</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT</span></span><br><span class="line"><span class="string">142	3.32105	0.0	19.58	1.0	0.8710	5.403	100.0	1.3216	5.0	403.0	14.7	396.90	26.82</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">	1.1296	24.0	666.0	20.2	347.88	8.88</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment">## Pre-processing</span></span><br><span class="line">df.std()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">CRIM         8.601545</span></span><br><span class="line"><span class="string">ZN          23.322453</span></span><br><span class="line"><span class="string">INDUS        6.860353</span></span><br><span class="line"><span class="string">CHAS         0.253994</span></span><br><span class="line"><span class="string">NOX          0.115878</span></span><br><span class="line"><span class="string">RM           0.702617</span></span><br><span class="line"><span class="string">AGE         28.148861</span></span><br><span class="line"><span class="string">DIS          2.105710</span></span><br><span class="line"><span class="string">RAD          8.707259</span></span><br><span class="line"><span class="string">TAX        168.537116</span></span><br><span class="line"><span class="string">PTRATIO      2.164946</span></span><br><span class="line"><span class="string">B           91.294864</span></span><br><span class="line"><span class="string">LSTAT        7.141062</span></span><br><span class="line"><span class="string">dtype: float64</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;CHAS&#x27;</span>] = df[<span class="string">&#x27;CHAS&#x27;</span>].astype(<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">df[<span class="string">&#x27;CHAS&#x27;</span>] = df[<span class="string">&#x27;CHAS&#x27;</span>].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line">df[<span class="string">&#x27;RAD&#x27;</span>] = df[<span class="string">&#x27;RAD&#x27;</span>].astype(<span class="string">&#x27;int&#x27;</span>)</span><br><span class="line">df[<span class="string">&#x27;RAD&#x27;</span>] = df[<span class="string">&#x27;RAD&#x27;</span>].astype(<span class="string">&#x27;category&#x27;</span>)</span><br><span class="line"></span><br><span class="line">df</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT</span></span><br><span class="line"><span class="string">0	0.00632	18.0	2.31	0	0.538	6.575	65.2	4.0900	1	296.0	15.3	396.90	4.98</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">505	0.04741	0.0	11.93	0	0.573	6.030	80.8	2.5050	1	273.0	21.0	396.90	7.88</span></span><br><span class="line"><span class="string">506 rows × 13 columns</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;RAD&#x27;</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0      1</span></span><br><span class="line"><span class="string">1      2</span></span><br><span class="line"><span class="string">2      2</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">505    1</span></span><br><span class="line"><span class="string">Name: RAD, Length: 506, dtype: category</span></span><br><span class="line"><span class="string">Categories (9, int64): [1, 2, 3, 4, ..., 6, 7, 8, 24]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">onehoter = OneHotEncoder()</span><br><span class="line">chas_and_rad_vec = onehoter.fit_transform(df[[<span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;RAD&#x27;</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment">## Standarlize</span></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler()</span><br><span class="line">df.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(506, 13)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">real_vec = ss.fit_transform(df.drop(columns = [<span class="string">&#x27;CHAS&#x27;</span>, <span class="string">&#x27;RAD&#x27;</span>]))</span><br><span class="line">chas_and_rad_vec[<span class="number">0</span>].toarray()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.mean(real_vec, axis = <span class="number">0</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([-1.12338772e-16,  7.89881994e-17,  2.10635198e-16, -1.96592852e-16,</span></span><br><span class="line"><span class="string">       -1.08828186e-16, -1.47444639e-16, -8.42540793e-17,  0.00000000e+00,</span></span><br><span class="line"><span class="string">       -4.21270397e-16, -7.44244367e-16, -3.08931624e-16])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">np.std(real_vec, axis = <span class="number">0</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">real_vec.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(506, 11)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">chas_and_rad_vec.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(506, 11)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Feature-Extractor</span></span><br><span class="line">X = np.concatenate((real_vec, chas_and_rad_vec.toarray()), axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">y = data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## Split Training, Test, Validation</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">split_train_val_test</span>(<span class="params">X, y, test_ratio = <span class="number">0.2</span>, val_ratio = <span class="number">0.2</span></span>):</span><br><span class="line">    indices = np.random.choice(<span class="built_in">range</span>(<span class="built_in">len</span>(X)), size = <span class="built_in">len</span>(X), replace=<span class="literal">False</span>)</span><br><span class="line">    train_indices = indices[:<span class="built_in">int</span>(<span class="built_in">len</span>(X) * (<span class="number">1</span>-test_ratio) * (<span class="number">1</span> - val_ratio))]</span><br><span class="line">    val_indices = indices[<span class="built_in">int</span>(<span class="built_in">len</span>(X)*(<span class="number">1</span>-test_ratio) * (<span class="number">1</span>-val_ratio)): <span class="built_in">int</span>(<span class="built_in">len</span>(X) * (<span class="number">1</span>-test_ratio))]</span><br><span class="line">    test_indices = indices[<span class="built_in">int</span>(<span class="built_in">len</span>(X) * (<span class="number">1</span>-test_ratio)):]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (X[train_indices], y[train_indices]), (X[val_indices], y[val_indices]), (X[test_indices], y[test_indices])</span><br><span class="line"></span><br><span class="line">(X_train, y_train), (X_val, y_val), (X_test, y_test) = split_train_val_test(X, y)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>sklearn.model_selection.train_test_split also could be used</p>
</blockquote>
<h4 id="build-model">Build-Model</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">regression = LinearRegression()</span><br><span class="line">regression.fit(X_train, y_train)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">LinearRegression()</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Question: If overfittiing or underfitting? Explain: Why validation set is more useful in deep learning</p>
</blockquote>
<h4 id="gradient-descent">Gradient Descent</h4>
<h4 id="evaluation">Evaluation</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">regression.score(X_train, y_train)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.7477980609064946</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">regression.score(X_val, y_val)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.7611715890963341</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">regression.score(X_test, y_test)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.711869928554872</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Interpreter</span></span><br><span class="line">regression.coef_</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([-1.04208922,  1.30263494,  0.29143618, -2.31827512,  2.40383155,</span></span><br><span class="line"><span class="string">        0.25013857, -3.55953868, -1.68823412, -2.37743843,  0.74411049,</span></span><br><span class="line"><span class="string">       -3.79489254, -0.79143926,  0.79143926, -2.51995654, -2.20671004,</span></span><br><span class="line"><span class="string">        0.65594998, -0.31683083, -0.07929752, -2.15244627, -0.06686364,</span></span><br><span class="line"><span class="string">        1.93167854,  4.75447632])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">regression.intercept_</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">22.070279554739386</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### Predict</span></span><br><span class="line">X_test[<span class="number">0</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([ 1.68404594, -0.48772236,  1.01599907,  1.07378711,  0.21279502,</span></span><br><span class="line"><span class="string">        1.11749449, -0.93188642,  1.53092646,  0.80657583, -3.61192313,</span></span><br><span class="line"><span class="string">        2.29842066,  1.        ,  0.        ,  0.        ,  0.        ,</span></span><br><span class="line"><span class="string">        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,</span></span><br><span class="line"><span class="string">        0.        ,  1.        ])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">regression.predict([X_test[<span class="number">0</span>]])</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([9.64589284])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    plt.scatter(X[:, <span class="number">5</span>], y)</span><br><span class="line">    plt.scatter(X[:, <span class="number">5</span>], regression.predict(X))</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831230756.png?imgNote" alt="image-20210831230756185" /><figcaption aria-hidden="true">image-20210831230756185</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.colors</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_predication_result</span>(<span class="params">x, target</span>):</span><br><span class="line">    width = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">    fig,ax = plt.subplots(x.shape[<span class="number">1</span>]//width + <span class="number">1</span>, width, figsize = (<span class="number">40</span>,<span class="number">40</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">        ix = np.unravel_index(i, ax.shape)</span><br><span class="line">        plt.sca(ax[ix])</span><br><span class="line">        ax[ix].title.set_text(<span class="string">&#x27;Feature-&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">        plt.scatter(x[:, i], target)</span><br><span class="line">        plt.scatter(x[:, i], regression.predict(x))</span><br><span class="line">        </span><br><span class="line">show_predication_result(X_train, y_train)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831230855.png?imgNote" alt="image-20210831230855270" /><figcaption aria-hidden="true">image-20210831230855270</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_predication_result(X_val, y_val)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831230921.png?imgNote" alt="image-20210831230921925" /><figcaption aria-hidden="true">image-20210831230921925</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show_predication_result(X_test, y_test)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831230945.png?imgNote" alt="image-20210831230945492" /><figcaption aria-hidden="true">image-20210831230945492</figcaption>
</figure>
<h4 id="outliers">Outliers</h4>
<h3 id="part-02-logstic-regression">Part-02 Logstic Regression</h3>
<ul>
<li>Data</li>
<li>Pre-processing</li>
<li>Feature-Extractor</li>
<li>Split Training, Test, Validation</li>
<li>Build Model</li>
<li>Gradient Descent</li>
<li>Evaluation</li>
<li>Predicat</li>
<li>Analysis</li>
</ul>
<p>Pre-processing</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> struct <span class="keyword">import</span> unpack</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadmnist</span>(<span class="params">imagefile, labelfile</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Open the images with gzip in read binary mode</span></span><br><span class="line">    images = <span class="built_in">open</span>(imagefile, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">    labels = <span class="built_in">open</span>(labelfile, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get metadata for images</span></span><br><span class="line">    images.read(<span class="number">4</span>) <span class="comment"># skip the magic_number</span></span><br><span class="line">    number_of_images = images.read(<span class="number">4</span>)</span><br><span class="line">    number_of_images = unpack(<span class="string">&#x27;&gt;I&#x27;</span>, number_of_images)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    rows = images.read(<span class="number">4</span>)</span><br><span class="line">    rows = unpack(<span class="string">&#x27;&gt;I&#x27;</span>, rows)[<span class="number">0</span>]</span><br><span class="line">    cols = images.read(<span class="number">4</span>)</span><br><span class="line">    cols = unpack(<span class="string">&#x27;&gt;I&#x27;</span>, cols)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get metadata for labels</span></span><br><span class="line">    labels.read(<span class="number">4</span>)</span><br><span class="line">    N = labels.read(<span class="number">4</span>)</span><br><span class="line">    N = unpack(<span class="string">&#x27;&gt;I&#x27;</span>, N)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get data</span></span><br><span class="line">    x = np.zeros((N, rows*cols), dtype = np.uint8) <span class="comment">#Initialize numpy array</span></span><br><span class="line">    y = np.zeros(N, dtype = np.uint8) <span class="comment"># Initialize numpy array</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(rows*cols):</span><br><span class="line">            tmp_pixel = images.read(<span class="number">1</span>) <span class="comment"># Just a single byte</span></span><br><span class="line">            tmp_pixel = unpack(<span class="string">&#x27;&gt;B&#x27;</span>, tmp_pixel)[<span class="number">0</span>]</span><br><span class="line">            x[i][j] = tmp_pixel</span><br><span class="line">        tmp_label = labels.read(<span class="number">1</span>)</span><br><span class="line">        y[i] = unpack(<span class="string">&#x27;&gt;B&#x27;</span>, tmp_label)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    images.close()</span><br><span class="line">    labels.close()</span><br><span class="line">    <span class="keyword">return</span> (x, y)</span><br><span class="line">  </span><br><span class="line">  X_train, y_train = loadmnist(<span class="string">&#x27;~/data/course_data/t10k-images-idx3-ubyte&#x27;</span>,<span class="string">&#x27;~/data/course_data/t10k-labels-idx1-ubyte&#x27;</span>)</span><br><span class="line">  X_test, y_test = loadmnist(<span class="string">&#x27;~/data/course_data/train-images-idx3-ubyte&#x27;</span>,<span class="string">&#x27;~/data/course_data/train-labels-idx1-ubyte&#x27;</span>)</span><br><span class="line">  </span><br><span class="line">  X_train.shape</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  (10000, 784)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  X_test</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  array([[0, 0, 0, ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">       ...,</span></span><br><span class="line"><span class="string">       [0, 0, 0, ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, ..., 0, 0, 0],</span></span><br><span class="line"><span class="string">       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  y_test</span><br><span class="line">  <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">  array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  </span><br><span class="line">  plt.figure(figsize = (<span class="number">20</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> index, (image, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(X_train[<span class="number">0</span>:<span class="number">5</span>], y_train[<span class="number">0</span>:<span class="number">5</span>])):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="number">5</span>, index+<span class="number">1</span>)</span><br><span class="line">    plt.imshow(np.reshape(image, (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">    plt.title(<span class="string">&#x27;Traininng: %i\n&#x27;</span> % label, fontsize = <span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831231306.png?imgNote" alt="image-20210831231306773" /><figcaption aria-hidden="true">image-20210831231306773</figcaption>
</figure>
<p>We only choose label with 0 and 6</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">zero_train_indices = np.where(y_train == <span class="number">0</span>)</span><br><span class="line">one_train_indices = np.where(y_train == <span class="number">6</span>)</span><br><span class="line">train_indices = np.concatenate((zero_train_indices[<span class="number">0</span>], one_train_indices[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">zero_test_indices = np.where(y_test == <span class="number">0</span>)</span><br><span class="line">one_test_indices = np.where(y_test == <span class="number">6</span>)</span><br><span class="line">test_indices = np.concatenate((zero_test_indices[<span class="number">0</span>], one_test_indices[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">train_indices = np.random.choice(train_indices, size = <span class="built_in">len</span>(train_indices), replace=<span class="literal">False</span>)</span><br><span class="line">test_indices = np.random.choice(test_indices, size = <span class="built_in">len</span>(test_indices), replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">val_ratio= <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line">train_indices = train_indices[: <span class="built_in">int</span>(<span class="built_in">len</span>(train_indices) * (<span class="number">1</span> - val_ratio))]</span><br><span class="line">val_indices = train_indices[<span class="built_in">int</span>(<span class="built_in">len</span>(train_indices) * (<span class="number">1</span> - val_ratio)):]</span><br><span class="line"></span><br><span class="line">binary_x_train = X_train[train_indices]</span><br><span class="line">binary_x_test = X_test[test_indices]</span><br><span class="line">binary_x_val = X_train[val_indices]</span><br><span class="line"></span><br><span class="line">binary_y_train = y_train[train_indices]</span><br><span class="line">binary_y_test = y_test[test_indices]</span><br><span class="line">binary_y_val = y_train[val_indices]</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line">binary_y_train</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([6, 0, 0, ..., 6, 0, 0], dtype=uint8)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">plt.imshow(np.reshape(binary_x_train[<span class="number">1</span>], (<span class="number">28</span>,<span class="number">28</span>)))</span><br><span class="line">plt.title(<span class="string">&#x27;Training: %i\n&#x27;</span> % binary_y_train[<span class="number">1</span>], fontsize =<span class="number">20</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Text(0.5, 1.0, &#x27;Training: 0\n&#x27;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831231410.png?imgNote" alt="image-20210831231410866" /><figcaption aria-hidden="true">image-20210831231410866</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line">Counter(binary_y_train)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Counter(&#123;6: 768, 0: 782&#125;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">Counter(binary_y_test)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Counter(&#123;6: 5918, 0: 5923&#125;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">Counter(binary_y_val)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Counter(&#123;0: 148, 6: 162&#125;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="build-model-1">Build model</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line">clf = LogisticRegression(random_state = <span class="number">0</span>, solver = <span class="string">&#x27;lbfgs&#x27;</span>)</span><br><span class="line"><span class="comment"># L-BFGS-B - Software for Large-scale Bound-constrained Optimization</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">&#x27;ignore&#x27;</span>)</span><br><span class="line">clf.fit(binary_x_train, binary_y_train)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">LogisticRegression(random_state=0)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">clf.coef_</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,</span></span><br><span class="line"><span class="string">         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,</span></span><br><span class="line"><span class="string">show more (open the raw output data in a text editor) ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,</span></span><br><span class="line"><span class="string">         0.00000000e+00]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">clf.intercept_</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([0.00016519])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">clf.score</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;bound method ClassifierMixin.score of LogisticRegression(random_state=0)&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">clf.score(binary_x_train, binary_y_train)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1.0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">clf.score(binary_x_val, binary_y_val)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1.0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">binary_x_test.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(11841, 784)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">binary_y_test.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.9865720800608057</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">predicated_result = clf.predict(binary_x_test)</span><br><span class="line">np.where(binary_y_test != predicated_result)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(array([   17,    45,    66,   137,   260,   279,   323,   453,   529,</span></span><br><span class="line"><span class="string">          739,   753,   947,  1034,  1248,  1290,  1422,  1434,  1444,</span></span><br><span class="line"><span class="string"> 				...</span></span><br><span class="line"><span class="string">        10677, 10739, 10750, 10979, 11010, 11058, 11104, 11113, 11366,</span></span><br><span class="line"><span class="string">        11389, 11421, 11458, 11528, 11659, 11760]),)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">lookup_index = <span class="number">1184</span></span><br><span class="line"></span><br><span class="line">plt.imshow(np.reshape(binary_x_test[lookup_index], (<span class="number">28</span>, <span class="number">28</span>)))</span><br><span class="line">plt.title(<span class="string">&#x27;Actual Value: &#123;&#125; ; Predict Value: &#123;&#125; \n&#x27;</span>.<span class="built_in">format</span>(binary_y_test[lookup_index], predicated_result[lookup_index]), fontsize = <span class="number">20</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Text(0.5, 1.0, &#x27;Actual Value: 6 ; Predict Value: 6 \n&#x27;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831231740.png?imgNote" alt="image-20210831231740052" /><figcaption aria-hidden="true">image-20210831231740052</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">binary_y_test[<span class="number">0</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">6</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">predicated_result[<span class="number">0</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">6</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">metrics.precision_score(binary_y_test, predicated_result, average = <span class="string">&#x27;macro&#x27;</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.9865879016517065</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">metrics.precision_score(binary_y_test, predicated_result, pos_label = <span class="number">6</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.9837056946077608</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">metrics.recall_score(binary_y_test, predicated_result, pos_label = <span class="number">6</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.9895234876647516</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">fpr, tpr, threshold = metrics.roc_curve(binary_y_test, predicated_result, pos_label = <span class="number">6</span>)</span><br><span class="line">metrics.auc(fpr, tpr)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.9865733258009728</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">cm = metrics.confusion_matrix(binary_y_test, predicated_result)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line">data = confusion_matrix(binary_y_test, predicated_result)</span><br><span class="line">data</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([[5826,   97],</span></span><br><span class="line"><span class="string">       [  62, 5856]])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">df_cm = pd.DataFrame(data, columns = np.unique(binary_y_test), index = np.unique(binary_y_test))</span><br><span class="line"></span><br><span class="line">plt.figure(figsize = (<span class="number">10</span>, <span class="number">7</span>))</span><br><span class="line">sns.<span class="built_in">set</span>(font_scale=<span class="number">1.4</span>) <span class="comment"># for label size</span></span><br><span class="line">sns.heatmap(df_cm, cmap=<span class="string">&#x27;Blues&#x27;</span>, annot=<span class="literal">True</span>, annot_kws = &#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">16</span>&#125;) <span class="comment"># font size</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;AxesSubplot:&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831232005.png?imgNote" alt="image-20210831232005063" /><figcaption aria-hidden="true">image-20210831232005063</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df_cm.index.name = <span class="string">&#x27;Actual&#x27;</span></span><br><span class="line">df_cm.columns.name = <span class="string">&#x27;Predicted&#x27;</span></span><br><span class="line">plt.figure(figsize = (<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">sns.heatmap(df_cm, cmap=<span class="string">&#x27;Blues&#x27;</span>, annot=<span class="literal">True</span>, annot_kws=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">16</span>&#125;)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;AxesSubplot:xlabel=&#x27;Predicted&#x27;, ylabel=&#x27;Actual&#x27;&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831232124.png?imgNote" alt="image-20210831232124003" /><figcaption aria-hidden="true">image-20210831232124003</figcaption>
</figure>
<h2 id="boston-code-reproduction-and-reference-answers">Boston code reproduction and reference answers</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import package</span></span><br><span class="line"><span class="comment"># Used to load the Boston housing price data set</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"><span class="comment"># pandas toolkit For students who are new to pandas, please refer to the official 10-minute tutorial: https://pandas.pydata.org/pandas-docs/stable/10min.html</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># seaborn for drawing</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np <span class="comment"># numpy</span></span><br><span class="line"><span class="comment"># Show drawing</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">data = load_boston()</span><br><span class="line">data.keys()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">dict_keys([&#x27;data&#x27;, &#x27;target&#x27;, &#x27;feature_names&#x27;, &#x27;DESCR&#x27;, &#x27;filename&#x27;])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(data[<span class="string">&#x27;data&#x27;</span>])</span><br><span class="line">df.head()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">				0		1			2			3			4			5		6				7			8			9		10			11		12</span></span><br><span class="line"><span class="string">0	0.00632	18.0	2.31	0.0	0.538	6.575	65.2	4.0900	1.0	296.0	15.3	396.90	4.98</span></span><br><span class="line"><span class="string">1	0.02731	 0.0	7.07	0.0	0.469	6.421	78.9	4.9671	2.0	242.0	17.8	396.90	9.14</span></span><br><span class="line"><span class="string">2	0.02729  0.0	7.07	0.0	0.469	7.185	61.1	4.9671	2.0	242.0	17.8	392.83	4.03</span></span><br><span class="line"><span class="string">3	0.03237  0.0	2.18	0.0	0.458	6.998	45.8	6.0622	3.0	222.0	18.7	394.63	2.94</span></span><br><span class="line"><span class="string">4	0.06905  0.0	2.18	0.0	0.458	7.147	54.2	6.0622	3.0	222.0	18.7	396.90	5.33</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">data[<span class="string">&#x27;feature_names&#x27;</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">array([&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;,</span></span><br><span class="line"><span class="string">       &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;], dtype=&#x27;&lt;U7&#x27;)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="field-meaning">Field meaning</h3>
<table>
<thead>
<tr class="header">
<th><strong>名称</strong></th>
<th>中文描述</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>CRIM</strong></td>
<td>住房所在城镇的人均犯罪率</td>
</tr>
<tr class="even">
<td><strong>ZN</strong></td>
<td>住房用地超过 25000 平方尺的比例</td>
</tr>
<tr class="odd">
<td><strong>INDUS</strong></td>
<td>住房所在城镇非零售商用土地的比例</td>
</tr>
<tr class="even">
<td><strong>CHAS</strong></td>
<td>有关查理斯河的虚拟变量（如果住房位于河边则为1,否则为0 ）</td>
</tr>
<tr class="odd">
<td><strong>NOX</strong></td>
<td>一氧化氮浓度</td>
</tr>
<tr class="even">
<td><strong>RM</strong></td>
<td>每处住房的平均房间数</td>
</tr>
<tr class="odd">
<td><strong>AGE</strong></td>
<td>建于 1940 年之前的业主自住房比例</td>
</tr>
<tr class="even">
<td><strong>DIS</strong></td>
<td>住房距离波士顿五大中心区域的加权距离</td>
</tr>
<tr class="odd">
<td><strong>RAD</strong></td>
<td>离住房最近的公路入口编号</td>
</tr>
<tr class="even">
<td><strong>TAX</strong></td>
<td><strong>每</strong> <strong>10000</strong> <strong>美元的全额财产税金额</strong></td>
</tr>
<tr class="odd">
<td><strong>PTRATIO</strong></td>
<td>住房所在城镇的师生比例</td>
</tr>
<tr class="even">
<td><strong>B</strong></td>
<td>1000(Bk-0.63)^2,其中 Bk 指代城镇中黑人的比例</td>
</tr>
<tr class="odd">
<td><strong>LSTAT</strong></td>
<td>弱势群体人口所占比例</td>
</tr>
<tr class="even">
<td><strong>MEDV</strong></td>
<td>业主自住房的中位数房价（以千美元计）</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">df.columns = data[<span class="string">&#x27;feature_names&#x27;</span>]</span><br><span class="line">df.head()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">		CRIM		ZN	INDUS	CHAS		NOX		RM	AGE			DIS		RAD	TAX	PTRATIO		B		LSTAT</span></span><br><span class="line"><span class="string">0	0.00632	18.0	2.31	0.0		0.538	6.575	65.2	4.0900	1.0	296.0	15.3	396.90	4.98</span></span><br><span class="line"><span class="string">1	0.02731	0.0		7.07	0.0		0.469	6.421	78.9	4.9671	2.0	242.0	17.8	396.90	9.14</span></span><br><span class="line"><span class="string">2	0.02729	0.0		7.07	0.0		0.469	7.185	61.1	4.9671	2.0	242.0	17.8	392.83	4.03</span></span><br><span class="line"><span class="string">3	0.03237	0.0		2.18	0.0		0.458	6.998	45.8	6.0622	3.0	222.0	18.7	394.63	2.94</span></span><br><span class="line"><span class="string">4	0.06905	0.0		2.18	0.0		0.458	7.147	54.2	6.0622	3.0	222.0	18.7	396.90	5.33</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">df[<span class="string">&#x27;price&#x27;</span>] = data[<span class="string">&#x27;target&#x27;</span>]</span><br><span class="line">df.head(<span class="number">2</span>)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT	price</span></span><br><span class="line"><span class="string">0	0.00632	18.0	2.31	0.0	0.538	6.575	65.2	4.0900	1.0	296.0	15.3	396.9	4.98	24.0</span></span><br><span class="line"><span class="string">1	0.02731	0.0	7.07	0.0	0.469	6.421	78.9	4.9671	2.0	242.0	17.8	396.9	9.14	21.6</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">sns.heatmap(df.corr(), annot=<span class="literal">True</span>, fmt=<span class="string">&#x27;.1f&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233019.png?imgNote" alt="image-20210831233019474" /><figcaption aria-hidden="true">image-20210831233019474</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.scatter(df[<span class="string">&#x27;RM&#x27;</span>], df[<span class="string">&#x27;price&#x27;</span>])</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;matplotlib.collections.PathCollection at 0x7fe0f984f810&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233046.png?imgNote" alt="image-20210831233046720" /><figcaption aria-hidden="true">image-20210831233046720</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize = (<span class="number">20</span>, <span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">features = [<span class="string">&#x27;LSTAT&#x27;</span>, <span class="string">&#x27;RM&#x27;</span>]</span><br><span class="line">target = df[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, col <span class="keyword">in</span> <span class="built_in">enumerate</span>(features):</span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="built_in">len</span>(features), i+<span class="number">1</span>)</span><br><span class="line">    x = df[col]</span><br><span class="line">    y = target</span><br><span class="line">    plt.scatter(x, y, marker = <span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;&#123;&#125; vs price&#x27;</span>.<span class="built_in">format</span>(col))</span><br><span class="line">    plt.xlabel(col)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;price&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233103.png?imgNote" alt="image-20210831233103355" /><figcaption aria-hidden="true">image-20210831233103355</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">x = df[<span class="string">&#x27;RM&#x27;</span>]</span><br><span class="line">y = df[<span class="string">&#x27;price&#x27;</span>]</span><br><span class="line"></span><br><span class="line">history_notes = &#123;_x: _y <span class="keyword">for</span> _x, _y <span class="keyword">in</span> <span class="built_in">zip</span>(x, y)&#125;</span><br><span class="line">history_notes[<span class="number">6.575</span>]</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">24.0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the top three prices closest to RM:6.57,</span></span><br><span class="line">similary_ys = [y <span class="keyword">for</span> _, y <span class="keyword">in</span> <span class="built_in">sorted</span>(history_notes.items(), key=<span class="keyword">lambda</span> x_y: (x_y[<span class="number">0</span>]-<span class="number">6.57</span>) ** <span class="number">2</span>)[:<span class="number">3</span>]]</span><br><span class="line">similary_ys</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">[23.8, 24.0, 24.8]</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">np.mean(similary_ys) <span class="comment"># Calculate the average of three</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">24.2</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Using historical data to predict data that has never been seen before, the most direct method</p>
<h3 id="k-neighbor-nearst">K-Neighbor-Nearst</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">knn</span>(<span class="params">query_x, history, top_n=<span class="number">3</span></span>):</span><br><span class="line">    sorted_notes = <span class="built_in">sorted</span>(history.items(), key=<span class="keyword">lambda</span> x_y: (x_y[<span class="number">0</span>] - query_x) ** <span class="number">2</span>) </span><br><span class="line">    similar_notes = sorted_notes[:top_n]</span><br><span class="line">    similar_ys = [y <span class="keyword">for</span> _, y <span class="keyword">in</span> similar_notes]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> np.mean(similar_ys)</span><br><span class="line"></span><br><span class="line">knn(<span class="number">5.4</span>, history_notes)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">15.700000000000001</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>In order to obtain results faster, we hope to obtain predictive power by fitting a function <span class="math display">\[
f(rm) = k * rm + b
\]</span></p>
<p>Random Approach</p>
<p><span class="math display">\[ Loss(k, b) = \frac{1}{n} \sum_{i \in N} (\hat{y_i} - y_i) ^ 2 \]</span></p>
<p><span class="math display">\[ Loss(k, b) = \frac{1}{n} \sum_{i \in N} ((k * rm_i + b) - y_i) ^ 2 \]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">yhat, y</span>):</span><br><span class="line">    <span class="keyword">return</span> np.mean((yhat - y) **<span class="number">2</span>)</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">min_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">best_k, bes_b = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(min_loss)</span><br><span class="line"></span><br><span class="line">min_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">best_k, bes_b = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    min_v, max_v = -<span class="number">100</span>, <span class="number">100</span></span><br><span class="line">    k, b = random.randrange(min_v, max_v), random.randrange(min_v, max_v)</span><br><span class="line">    y_hats = [k * rm_i + b <span class="keyword">for</span> rm_i <span class="keyword">in</span> x]</span><br><span class="line">    current_loss = loss(y_hats, y)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> current_loss &lt;min_loss:</span><br><span class="line">        min_loss = current_loss</span><br><span class="line">        best_k, best_b = k, b</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;In step &#123;&#125;, we have obtained the function f(rm) = &#123;&#125; * rm + &#123;&#125;, at this time loss is: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(step, k, b, current_loss))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">In step 0, we have obtained the function f(rm) = 14 * rm + -78, at this time loss is: 212.87040239525695</span></span><br><span class="line"><span class="string">In step 70, we have obtained the function f(rm) = 10 * rm + -47, at this time loss is: 88.70654683794466</span></span><br><span class="line"><span class="string">In step 256, we have obtained the function f(rm) = 13 * rm + -55, at this time loss is: 68.45390542094862</span></span><br><span class="line"><span class="string">In step 526, we have obtained the function f(rm) = 10 * rm + -37, at this time loss is: 54.977297826086954</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.scatter(x, [best_k * rm + best_b <span class="keyword">for</span> rm <span class="keyword">in</span> x])</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;matplotlib.collections.PathCollection at 0x7fe0980f37d0&gt;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233425.png?imgNote" alt="image-20210831233425089" /><figcaption aria-hidden="true">image-20210831233425089</figcaption>
</figure>
<h3 id="monte-carlo-simulation">Monte Carlo simulation</h3>
<h4 id="supervisor">Supervisor</h4>
<p><span class="math display">\[ Loss(k, b) = \frac{1}{n} \sum_{i \in N} ((k * rm_i + b) - y_i) ^ 2 \]</span></p>
<p><span class="math display">\[ \frac{\partial{loss(k, b)}}{\partial{k}} = \frac{2}{n}\sum_{i \in N}(k * rm_i + b - y_i) * rm_i \]</span></p>
<p><span class="math display">\[ \frac{\partial{loss(k, b)}}{\partial{b}} = \frac{2}{n}\sum_{i \in N}(k * rm_i + b - y_i)\]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">partial_k</span>(<span class="params">k, b, x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * np.mean((k*x+b-y) *x)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">partial_b</span>(<span class="params">k, b, x, y</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span>*np.mean(k*x+b-y)</span><br><span class="line">  </span><br><span class="line">k, b = random.random(), random.random()</span><br><span class="line">min_loss = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">best_k, best_b = <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2000</span>):</span><br><span class="line">    k,b = k+(-<span class="number">1</span>*partial_k(k,b,x,y) * learning_rate), b+(-<span class="number">1</span>*partial_b(k,b,x,y) * learning_rate)</span><br><span class="line">    y_hats = k * x +b</span><br><span class="line">    current_loss = loss(y_hats, y)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> current_loss &lt; min_loss:</span><br><span class="line">        min_loss = current_loss</span><br><span class="line">        best_k, best_b = k, b</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;On the &#123;&#125; step, we have func f(rm) = &#123;&#125; * rm + &#123;&#125;, loss is &#123;&#125; now&#x27;</span>.<span class="built_in">format</span>(step, k, b, current_loss))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">On the 0 step, we have func f(rm) = 6.968714597804018 * rm + -21.099847342593957, loss is 45.86961514375004 now</span></span><br><span class="line"><span class="string">On the 1 step, we have func f(rm) = 6.9692276199804555 * rm + -21.103110737199852, loss is 45.86852398135223 now</span></span><br><span class="line"><span class="string">show more (open the raw output data in a text editor) ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">On the 1999 step, we have func f(rm) = 7.783005326604901 * rm + -26.279646762684518, loss is 44.468037178267025 now</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">best_k, best_b</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(10, -37)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">plt.scatter(x, y)</span><br><span class="line">plt.scatter(x, [best_k * rm + best_b <span class="keyword">for</span> rm <span class="keyword">in</span> x])</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233620.png?imgNote" alt="image-20210831233620249" /><figcaption aria-hidden="true">image-20210831233620249</figcaption>
</figure>
<h4 id="supervised-learning">Supervised Learning</h4>
<p>We turn the forecast of housing prices into a more responsible and sophisticated model. What should we do?</p>
<p><span class="math display">\[ f(x) = k * x + b \]</span></p>
<p><span class="math display">\[ f(x) = k2 * \sigma(k_1 * x + b_1) + b2 \]</span></p>
<p><span class="math display">\[ \sigma(x) = \frac{1}{1 + e^(-x)} \]</span></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">sub_x = np.linspace(-<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">plt.plot(sub_x, sigmoid(sub_x))</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233717.png?imgNote" alt="image-20210831233717648" /><figcaption aria-hidden="true">image-20210831233717648</figcaption>
</figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">random_linear</span>(<span class="params">x</span>):</span><br><span class="line">    k, b = random.random(), random.random()</span><br><span class="line">    <span class="keyword">return</span> k * x + b</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">complex_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (random_linear(x))</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    index = random.randrange(<span class="number">0</span>, <span class="built_in">len</span>(sub_x))</span><br><span class="line">    sub_x_1, sub_x_2 = sub_x[:index], sub_x[index:]</span><br><span class="line">    new_y = np.concatenate((complex_function(sub_x_1), complex_function(sub_x_2)))</span><br><span class="line">    plt.plot(sub_x, new_y)</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://qiniu.hivan.me/picGo/20210831233740.png?imgNote" alt="image-20210831233740329" /><figcaption aria-hidden="true">image-20210831233740329</figcaption>
</figure>
<p>We can implement more complex functions through simple, basic modules and repeated superposition</p>
<p>For more and more complex functions? How does the computer seek guidance?</p>
<ol type="1">
<li>What is machine learning?</li>
<li>The shortcomings of the KNN method, what is the background of the proposed linear fitting</li>
<li>How to obtain faster function weight update through supervision method</li>
<li>The combination of nonlinear and linear functions can fit very complex functions</li>
<li>Deep learning we can fit more complex functions through basic function modules</li>
</ol>
<h4 id="assigment">Assigment</h4>
<p><span class="math display">\[ L2-Loss(y, \hat{y}) = \frac{1}{n}\sum{(\hat{y} - y)}^2 \]</span></p>
<p><span class="math display">\[ L1-Loss(y, \hat{y}) = \frac{1}{n}\sum{|(\hat{y} - y)|} \]</span></p>
<p>Change L2-Loss in the code to L1Loss and implement gradient descent</p>
<p>Realize L1Loss gradient descent from 0</p>
<h5 id="import-package">1 Import package</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br></pre></td></tr></table></figure>
<h5 id="load-data-set">2 Load data set</h5>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line">boston = load_boston()</span><br><span class="line">boston.keys()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">dict_keys([&#x27;data&#x27;, &#x27;target&#x27;, &#x27;feature_names&#x27;, &#x27;DESCR&#x27;, &#x27;filename&#x27;])</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">X = boston.data</span><br><span class="line">y = boston.target</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(boston.data, columns = boston.feature_names)</span><br><span class="line">df.head()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT</span></span><br><span class="line"><span class="string">0	0.00632	18.0	2.31	0.0	0.538	6.575	65.2	4.0900	1.0	296.0	15.3	396.90	4.98</span></span><br><span class="line"><span class="string">1	0.02731	0.0	7.07	0.0	0.469	6.421	78.9	4.9671	2.0	242.0	17.8	396.90	9.14</span></span><br><span class="line"><span class="string">2	0.02729	0.0	7.07	0.0	0.469	7.185	61.1	4.9671	2.0	242.0	17.8	392.83	4.03</span></span><br><span class="line"><span class="string">3	0.03237	0.0	2.18	0.0	0.458	6.998	45.8	6.0622	3.0	222.0	18.7	394.63	2.94</span></span><br><span class="line"><span class="string">4	0.06905	0.0	2.18	0.0	0.458	7.147	54.2	6.0622	3.0	222.0	18.7	396.90	5.33</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">df.describe() <span class="comment"># Data description, you can view the statistics of each variable</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT</span></span><br><span class="line"><span class="string">count	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000	506.000000</span></span><br><span class="line"><span class="string">mean	3.613524	11.363636	11.136779	0.069170	0.554695	6.284634	68.574901	3.795043	9.549407	408.237154	18.455534	356.674032	12.653063</span></span><br><span class="line"><span class="string">std	8.601545	23.322453	6.860353	0.253994	0.115878	0.702617	28.148861	2.105710	8.707259	168.537116	2.164946	91.294864	7.141062</span></span><br><span class="line"><span class="string">min	0.006320	0.000000	0.460000	0.000000	0.385000	3.561000	2.900000	1.129600	1.000000	187.000000	12.600000	0.320000	1.730000</span></span><br><span class="line"><span class="string">25%	0.082045	0.000000	5.190000	0.000000	0.449000	5.885500	45.025000	2.100175	4.000000	279.000000	17.400000	375.377500	6.950000</span></span><br><span class="line"><span class="string">50%	0.256510	0.000000	9.690000	0.000000	0.538000	6.208500	77.500000	3.207450	5.000000	330.000000	19.050000	391.440000	11.360000</span></span><br><span class="line"><span class="string">75%	3.677083	12.500000	18.100000	0.000000	0.624000	6.623500	94.075000	5.188425	24.000000	666.000000	20.200000	396.225000	16.955000</span></span><br><span class="line"><span class="string">max	88.976200	100.000000	27.740000	1.000000	0.871000	8.780000	100.000000	12.126500	24.000000	711.000000	22.000000	396.900000	37.970000</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h5 id="data-preprocessing">3 Data preprocessing</h5>
<p>Normalization or standardization can prevent a certain dimension or a few dimensions from affecting the data too much when there are very many dimensions, and secondly, the program can run faster. There are many methods, such as standardization, min-max, z-score, p-norm, etc. How to use it depends on the characteristics of the data set.</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/81560511">Extended reading-the deep learning field of the myth of data standardization</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">ss = StandardScaler() <span class="comment"># z = (x-u) / s u is the mean, s is the standard deviation</span></span><br><span class="line">X = ss.fit_transform(df) <span class="comment"># For linear models, normalization or standardization is generally required, otherwise there will be a gradient explosion, which is generally not required for tree models</span></span><br><span class="line">df = pd.DataFrame(X, columns = [<span class="string">&#x27;CRIM&#x27;</span>,<span class="string">&#x27;ZN&#x27;</span>,<span class="string">&#x27;INDUS&#x27;</span>,<span class="string">&#x27;CHAS&#x27;</span>,<span class="string">&#x27;NOX&#x27;</span>,<span class="string">&#x27;RM&#x27;</span>,<span class="string">&#x27;AGE&#x27;</span>,<span class="string">&#x27;DIS&#x27;</span>,<span class="string">&#x27;RAD&#x27;</span>,<span class="string">&#x27;TAX&#x27;</span> ,<span class="string">&#x27;PTRATIO&#x27;</span>,<span class="string">&#x27;B&#x27;</span>,<span class="string">&#x27;LSTAT&#x27;</span>])</span><br><span class="line">df.describe()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT</span></span><br><span class="line"><span class="string">count	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02	5.060000e+02</span></span><br><span class="line"><span class="string">mean	2.808469e-17	6.599903e-16	-4.633974e-16	-4.353127e-16	1.404235e-16	-1.755293e-17	2.176564e-16	-1.685082e-16	-5.055245e-16	8.987102e-16	-1.067218e-15	4.493551e-16	-2.246775e-16</span></span><br><span class="line"><span class="string">std	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00	1.000990e+00</span></span><br><span class="line"><span class="string">min	-4.197819e-01	-4.877224e-01	-1.557842e+00	-2.725986e-01	-1.465882e+00	-3.880249e+00	-2.335437e+00	-1.267069e+00	-9.828429e-01	-1.313990e+00	-2.707379e+00	-3.907193e+00	-1.531127e+00</span></span><br><span class="line"><span class="string">25%	-4.109696e-01	-4.877224e-01	-8.676906e-01	-2.725986e-01	-9.130288e-01	-5.686303e-01	-8.374480e-01	-8.056878e-01	-6.379618e-01	-7.675760e-01	-4.880391e-01	2.050715e-01	-7.994200e-01</span></span><br><span class="line"><span class="string">50%	-3.906665e-01	-4.877224e-01	-2.110985e-01	-2.725986e-01	-1.442174e-01	-1.084655e-01	3.173816e-01	-2.793234e-01	-5.230014e-01	-4.646726e-01	2.748590e-01	3.811865e-01	-1.812536e-01</span></span><br><span class="line"><span class="string">75%	7.396560e-03	4.877224e-02	1.015999e+00	-2.725986e-01	5.986790e-01	4.827678e-01	9.067981e-01	6.623709e-01	1.661245e+00	1.530926e+00	8.065758e-01	4.336510e-01	6.030188e-01</span></span><br><span class="line"><span class="string">max	9.933931e+00	3.804234e+00	2.422565e+00	3.668398e+00	2.732346e+00	3.555044e+00	1.117494e+00	3.960518e+00	1.661245e+00	1.798194e+00	1.638828e+00	4.410519e-01	3.548771e+00</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p><span class="math display">\[ y=Σwixi+b \]</span></p>
<p>Because the derivation of b is all 1, add a bias b to the data and set it to 1, as a feature of the data and update the gradient wi*b=wi</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">&#x27;bias&#x27;</span>] = <span class="number">1</span></span><br><span class="line">df</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	CRIM	ZN	INDUS	CHAS	NOX	RM	AGE	DIS	RAD	TAX	PTRATIO	B	LSTAT	bias</span></span><br><span class="line"><span class="string">0	-0.419782	0.284830	-1.287909	-0.272599	-0.144217	0.413672	-0.120013	0.140214	-0.982843	-0.666608	-1.459000	0.441052	-1.075562	1</span></span><br><span class="line"><span class="string">1	-0.417339	-0.487722	-0.593381	-0.272599	-0.740262	0.194274	0.367166	0.557160	-0.867883	-0.987329	-0.303094	0.441052	-0.492439	1</span></span><br><span class="line"><span class="string">2	-0.417342	-0.487722	-0.593381	-0.272599	-0.740262	1.282714	-0.265812	0.557160	-0.867883	-0.987329	-0.303094	0.396427	-1.208727	1</span></span><br><span class="line"><span class="string">3	-0.416750	-0.487722	-1.306878	-0.272599	-0.835284	1.016303	-0.809889	1.077737	-0.752922	-1.106115	0.113032	0.416163	-1.361517	1</span></span><br><span class="line"><span class="string">4	-0.412482	-0.487722	-1.306878	-0.272599	-0.835284	1.228577	-0.511180	1.077737	-0.752922	-1.106115	0.113032	0.441052	-1.026501	1</span></span><br><span class="line"><span class="string">...	...	...	...	...	...	...	...	...	...	...	...	...	...	...</span></span><br><span class="line"><span class="string">501	-0.413229	-0.487722	0.115738	-0.272599	0.158124	0.439316	0.018673	-0.625796	-0.982843	-0.803212	1.176466	0.387217	-0.418147	1</span></span><br><span class="line"><span class="string">502	-0.415249	-0.487722	0.115738	-0.272599	0.158124	-0.234548	0.288933	-0.716639	-0.982843	-0.803212	1.176466	0.441052	-0.500850	1</span></span><br><span class="line"><span class="string">503	-0.413447	-0.487722	0.115738	-0.272599	0.158124	0.984960	0.797449	-0.773684	-0.982843	-0.803212	1.176466	0.441052	-0.983048	1</span></span><br><span class="line"><span class="string">504	-0.407764	-0.487722	0.115738	-0.272599	0.158124	0.725672	0.736996	-0.668437	-0.982843	-0.803212	1.176466	0.403225	-0.865302	1</span></span><br><span class="line"><span class="string">505	-0.415000	-0.487722	0.115738	-0.272599	0.158124	-0.362767	0.434732	-0.613246	-0.982843	-0.803212	1.176466	0.441052	-0.669058	1</span></span><br><span class="line"><span class="string">506 rows × 14 columns</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Divide the data set, where 20% of the data is used as the test set X_test, y_test, and the other 80% are used as the training set X_train, y_train, where random_state is the random seed</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train,y_test = train_test_split(df, y, test_size = <span class="number">0.2</span>, random_state = <span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X_train.shape, y_train.shape:&#x27;</span>, X_train.shape, y_train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;X_test.shape, y_test.shape&#x27;</span>, X_test.shape, y_test.shape)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">X_train.shape, y_train.shape: (404, 14) (404,)</span></span><br><span class="line"><span class="string">X_test.shape, y_test.shape (102, 14) (102,)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">X_train = np.array(X_train)</span><br></pre></td></tr></table></figure>
<h4 id="model-training-and-gradient-update">Model training and gradient update</h4>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">l1_cost</span>(<span class="params">X, y, theta</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    X: 特征</span></span><br><span class="line"><span class="string">    y: 目标值</span></span><br><span class="line"><span class="string">    theta: 模型参数</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    k = X.shape[<span class="number">0</span>]</span><br><span class="line">    total_cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        total_cost =+ <span class="number">1</span>/k * np.<span class="built_in">abs</span>(y[i] - theta.dot(X[i, :]))</span><br><span class="line">    <span class="keyword">return</span> total_cost</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">l2_cost</span>(<span class="params">X, y, theta</span>):</span><br><span class="line">    k = X.shape[<span class="number">0</span>]</span><br><span class="line">    total_cost = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        total_cost += <span class="number">1</span>/k * (y[i] - theta.dot(X[i, :])) ** <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> total_cost</span><br><span class="line">  </span><br><span class="line">np.zeros(<span class="number">10</span>).shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(10,)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_l1_gradient</span>(<span class="params">X, y, learning_rate, theta</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Function to calculate the gradient of the MAE loss function</span></span><br><span class="line"><span class="string">    Return the gradient value 0 for the non-differentiable point at 0</span></span><br><span class="line"><span class="string">    X: feature vector</span></span><br><span class="line"><span class="string">    y: target value</span></span><br><span class="line"><span class="string">    learing_rate: learning rate</span></span><br><span class="line"><span class="string">    theta: parameter</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    n = X.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(n)</span><br><span class="line">    e = y-X @ theta</span><br><span class="line">    gradients = -(X.T @ np.sign(e)) / n</span><br><span class="line">    theta = theta-learning_rate * gradients</span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_l2_gradient</span>(<span class="params">X, y, learning_rate, theta</span>):</span><br><span class="line">    k = X.shape[<span class="number">0</span>]</span><br><span class="line">    x = X.shape[<span class="number">1</span>]</span><br><span class="line">    gradients = np.zeros(n)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            gradients[j] += (-<span class="number">2</span>/k) * (y[i] - (theta.dot(X[i, :]))) * X[i, j]</span><br><span class="line">    theta = theta - learning_rate * gradients</span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line">  </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">step_gradient</span>(<span class="params">X, y, learning_rate, theta</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    X: feature vector</span></span><br><span class="line"><span class="string">    y: target value</span></span><br><span class="line"><span class="string">    learing_rate: learning rate</span></span><br><span class="line"><span class="string">    theta: parameter</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    m_deriv = <span class="number">0</span></span><br><span class="line">    N = <span class="built_in">len</span>(X)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):</span><br><span class="line">        <span class="comment"># Calculate the partial derivative</span></span><br><span class="line">        <span class="comment"># -x(y-(mx + b)) / |mx + b|</span></span><br><span class="line">        m_deriv +=-X[i] * (y[i]-(theta*X[i] + b)) / <span class="built_in">abs</span>(y[i]-(theta*X[i] + b))</span><br><span class="line">    <span class="comment"># We subtract because the derivatives point in direction of steepest ascent</span></span><br><span class="line">    theta -= (m_deriv / <span class="built_in">float</span>(N)) * learning_rate</span><br><span class="line"><span class="comment"># theta = theta-learning_rate * gradients</span></span><br><span class="line">    <span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">X_train, y_train, learning_rate, iterations</span>):</span><br><span class="line">    k = X_train.shape[<span class="number">0</span>]</span><br><span class="line">    n = X_train.shape[<span class="number">1</span>]</span><br><span class="line">    theta = np.zeros(n)</span><br><span class="line">    loss_values = []</span><br><span class="line">    <span class="built_in">print</span>(theta.shape)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(iterations):</span><br><span class="line">        theta = step_l1_gradient(X_train, y_train, learning_rate, theta)</span><br><span class="line">        loss = l1_cost(X_train, y_train, theta)</span><br><span class="line">        loss_values.append(loss)</span><br><span class="line">        <span class="built_in">print</span>(i, <span class="string">&#x27;cost:&#x27;</span>, loss)</span><br><span class="line">    <span class="keyword">return</span> theta, loss_values</span><br><span class="line">  </span><br><span class="line"><span class="comment"># Training parameters</span></span><br><span class="line">learning_rate = <span class="number">0.04</span> <span class="comment"># Learning rate</span></span><br><span class="line">iterations = <span class="number">300</span> <span class="comment"># number of iterations</span></span><br><span class="line">theta ,loss_values = gradient_descent(X_train, y_train, learning_rate, iterations)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(14,)</span></span><br><span class="line"><span class="string">404</span></span><br><span class="line"><span class="string">0 cost: 0.04594399172713912</span></span><br><span class="line"><span class="string">404</span></span><br><span class="line"><span class="string">1 cost: 0.045848379493882215</span></span><br><span class="line"><span class="string">404</span></span><br><span class="line"><span class="string">show more (open the raw output data in a text editor) ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">299 cost: 0.017838215258874083</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="heart-practise">Heart Practise</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">path = <span class="string">&#x27;~/data/&#x27;</span></span><br><span class="line">dataPath = path + <span class="string">&#x27;heart.csv&#x27;</span></span><br><span class="line">train_data = pd.read_csv(dataPath)</span><br></pre></td></tr></table></figure>
<h3 id="field-meaning-1">Field meaning</h3>
<table>
<thead>
<tr class="header">
<th><strong>字段名</strong></th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>age</strong></td>
<td>年龄</td>
</tr>
<tr class="even">
<td><strong>sex</strong></td>
<td>性别(1 = 男性, 0 = 女性)</td>
</tr>
<tr class="odd">
<td><strong>cp</strong></td>
<td>胸部疼痛类型(值1：典型心绞痛，值2：非典型性心绞痛，值3：非心绞痛，值4：无症状）</td>
</tr>
<tr class="even">
<td><strong>trestbps</strong></td>
<td>血压</td>
</tr>
<tr class="odd">
<td><strong>chol</strong></td>
<td>胆固醇</td>
</tr>
<tr class="even">
<td><strong>fbs</strong></td>
<td>空腹血糖（&gt; 120 mg/dl，1=真；0=假）</td>
</tr>
<tr class="odd">
<td><strong>restecg</strong></td>
<td>心电图结果（0=正常，1=患有ST-T波异常，2=根据Estes的标准显示可能或确定的左心室肥大）</td>
</tr>
<tr class="even">
<td><strong>thalach</strong></td>
<td>最大心跳数</td>
</tr>
<tr class="odd">
<td><strong>exang</strong></td>
<td>运动时是否心绞痛（1=有过；0=没有）</td>
</tr>
<tr class="even">
<td><strong>oldpeak</strong></td>
<td><strong>运动相对于休息的ST</strong></td>
</tr>
<tr class="odd">
<td><strong>slop</strong></td>
<td>心电图ST segment的倾斜度(值1:上坡，值2:平坦，值3:下坡）</td>
</tr>
<tr class="even">
<td><strong>ca</strong></td>
<td>透视检查看到的血管数</td>
</tr>
<tr class="odd">
<td><strong>thal</strong></td>
<td>缺陷种类（3=正常；6=固定缺陷；7=可逆缺陷）</td>
</tr>
<tr class="even">
<td><strong>target</strong></td>
<td>是否患病（0=否，1=是）</td>
</tr>
</tbody>
</table>
<h3 id="print-a-brief-summary-of-the-data-set">Print a brief summary of the data set</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">train_data.info()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&lt;class &#x27;pandas.core.frame.DataFrame&#x27;&gt;</span></span><br><span class="line"><span class="string">RangeIndex: 303 entries, 0 to 302</span></span><br><span class="line"><span class="string">Data columns (total 14 columns):</span></span><br><span class="line"><span class="string"> #   Column    Non-Null Count  Dtype  </span></span><br><span class="line"><span class="string">---  ------    --------------  -----  </span></span><br><span class="line"><span class="string"> 0   age       303 non-null    int64  </span></span><br><span class="line"><span class="string"> 1   sex       303 non-null    int64  </span></span><br><span class="line"><span class="string"> 2   cp        303 non-null    int64  </span></span><br><span class="line"><span class="string"> 3   trestbps  303 non-null    int64  </span></span><br><span class="line"><span class="string"> 4   chol      303 non-null    int64  </span></span><br><span class="line"><span class="string"> 5   fbs       303 non-null    int64  </span></span><br><span class="line"><span class="string"> 6   restecg   303 non-null    int64  </span></span><br><span class="line"><span class="string"> 7   thalach   303 non-null    int64  </span></span><br><span class="line"><span class="string"> 8   exang     303 non-null    int64  </span></span><br><span class="line"><span class="string"> 9   oldpeak   303 non-null    float64</span></span><br><span class="line"><span class="string"> 10  slope     303 non-null    int64  </span></span><br><span class="line"><span class="string"> 11  ca        303 non-null    int64  </span></span><br><span class="line"><span class="string"> 12  thal      303 non-null    int64  </span></span><br><span class="line"><span class="string"> 13  target    303 non-null    int64  </span></span><br><span class="line"><span class="string">dtypes: float64(1), int64(13)</span></span><br><span class="line"><span class="string">memory usage: 33.3 KB</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">train_data.target.value_counts()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1    165</span></span><br><span class="line"><span class="string">0    138</span></span><br><span class="line"><span class="string">Name: target, dtype: int64</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Change the "sex" column to two columns "sex_0" and "sex_1".</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sex = pd.get_dummies(train_data[<span class="string">&#x27;sex&#x27;</span>], prefix = <span class="string">&quot;sex&quot;</span>) </span><br></pre></td></tr></table></figure>
<p>Add "sex_0" and "sex_1" to the data set.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = pd.concat([train_data,sex], axis = <span class="number">1</span>) </span><br></pre></td></tr></table></figure>
<p>And delete the sex column</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_data = train_data.drop(columns = [<span class="string">&#x27;sex&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>Print out the first five lines. Check whether sex_0, sex_1 are added successfully, and whether sex is deleted successfully.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">train_data.head()</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">	age	cp	trestbps	chol	fbs	restecg	thalach	exang	oldpeak	slope	ca	thal	target	sex_0	sex_1</span></span><br><span class="line"><span class="string">0	63	3			145			233			1			0				150			0			2.3		0		0			1				1			0			1</span></span><br><span class="line"><span class="string">1	37	2			130			250			0			1				187			0			3.5		0		0			2				1			0			1</span></span><br><span class="line"><span class="string">2	41	1			130			204			0			0				172			0			1.4		2		0			2				1			1			0</span></span><br><span class="line"><span class="string">3	56	1			120			236			0			1				178			0			0.8		2		0			2				1			0			1</span></span><br><span class="line"><span class="string">4	57	0			120			354			0			1				163			1			0.6		2		0			2				1			1			0</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Get sample label</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y_data = train_data.target.values</span><br><span class="line">train_data.shape</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">(303, 15)</span><br><span class="line">&quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>Get sample feature set</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x_data = train_data.drop([<span class="string">&#x27;target&#x27;</span>],axis=<span class="number">1</span>)</span><br><span class="line">x_data.shape</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">(303, 14)</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Divide the data set Parameters: <code>test_size=0.3, random_state=33</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train,X_test,y_train,y_test = train_test_split(x_data,y_data,test_size=<span class="number">0.3</span>, random_state=<span class="number">33</span>)</span><br></pre></td></tr></table></figure>
<h3 id="normalization">Normalization</h3>
<p>Import the StandardScaler package and initialize</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">standardScaler = StandardScaler()</span><br></pre></td></tr></table></figure>
<p>fit function/module is used to train model parameters</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">standardScaler.fit(X_train)</span><br></pre></td></tr></table></figure>
<p>Standardize the training set and test set</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X_train = standardScaler.transform(X_train)</span><br><span class="line">X_test = standardScaler.transform(X_test) </span><br></pre></td></tr></table></figure>
<p>Define logistic regression model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression </span><br><span class="line">log_reg = LogisticRegression()</span><br><span class="line">log_reg.fit(X_train,y_train)</span><br></pre></td></tr></table></figure>
<p>Calculate the training set score</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log_reg.score(X_train,y_train)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.8537735849056604</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Calculate the test set score</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">log_reg.score(X_test,y_test)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">0.8461538461538461</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<p>Use the classification_report function to display a text report of the main classification indicators</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line">y_predict_log = log_reg.predict(X_test)</span><br><span class="line"><span class="built_in">print</span>(classification_report(y_test,y_predict_log))</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"> precision    recall  f1-score   support</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">           0       0.93      0.78      0.85        50</span></span><br><span class="line"><span class="string">           1       0.78      0.93      0.84        41</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    accuracy                           0.85        91</span></span><br><span class="line"><span class="string">   macro avg       0.85      0.85      0.85        91</span></span><br><span class="line"><span class="string">weighted avg       0.86      0.85      0.85        91</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>Machine Learning Part-02</p><p><a href="https://hivan.me/example_04/">https://hivan.me/example_04/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Hivan Du</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2021-09-02</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-06-02</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=6479444288ae9600196fa98e&amp;product=inline-share-buttons" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="https://afdian.net/item/72907364008511ee904852540025c377" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="https://qiniu.hivan.me/picGo/20230601221633.jpeg" alt="支付宝"></span></a><a class="button donate" href="https://www.buymeacoffee.com/hivandu" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>送我杯咖啡</span></a><a class="button donate" href="https://patreon.com/user?u=89473430" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="doo@hivan.me"><input type="hidden" name="currency_code" value="USD"></form><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="https://qiniu.hivan.me/IMG_4603.JPG" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/example_09/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">CNN</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/example_05/"><span class="level-item">Machine Learning Part-03</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hivan.me/example_04/';
            this.page.identifier = 'example_04/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'hivan' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://www.gravatar.com/avatar/bdff168cf8a71c11d2712a1679a00c54?s=128" alt="茶桁"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">茶桁</p><p class="is-size-6 is-block">AI游民</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shang Hai</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">157</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">3</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">20</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/hivandu" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/hivandu"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com/hivan"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/hivan"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com/hivan"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzA4NzE4MDQzMg==&amp;action=getalbum&amp;album_id=2932504849574543360&amp;scene=173&amp;from_msgid=2648747980&amp;from_itemidx=1&amp;count=3&amp;nolastread=1&amp;token=1758883909&amp;lang=zh_CN#wechat_redirect"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://www.zhihu.com/column/c_1424326166602178560" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">塌缩的奇点</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li><li><a class="level is-mobile" href="https://www.zhihu.com/column/hivandu" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">茶桁-知乎</span></span><span class="level-right"><span class="level-item tag">www.zhihu.com</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/"><span class="level-start"><span class="level-item">AI秘籍</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/AI%E7%A7%98%E7%B1%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="level-start"><span class="level-item">从零开始接触人工智能大模型</span></span><span class="level-end"><span class="level-item tag">22</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-30T09:06:11.000Z">2023-07-30</time></p><p class="title"><a href="/Introduction-to-Python-scripting/">2. 初识Python脚本</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-29T11:22:20.000Z">2023-07-29</time></p><p class="title"><a href="/AI-cheats-information/">新专辑《AI秘籍》，你所感兴趣的一切</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-29T09:07:28.000Z">2023-07-29</time></p><p class="title"><a href="/Python-features-and-syntax/">1. Python的特性和语法</a></p><p class="categories"><a href="/categories/AI%E7%A7%98%E7%B1%8D/">AI秘籍</a> / <a href="/categories/AI%E7%A7%98%E7%B1%8D/Python/">Python</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T06:13:06.000Z">2023-07-27</time></p><p class="title"><a href="/AI%20Cheats%20Trailer/">《AI秘籍》预告</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-07-27T03:30:11.000Z">2023-07-27</time></p><p class="title"><a href="/Artificial-Neural-Network/">人工神经网络</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="茶桁.MAMT" height="28"></a><p class="is-size-7"><span>&copy; 2023 Hivan Du</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/hivandu"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>