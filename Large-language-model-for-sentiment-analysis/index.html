<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>02 大语言模型做情感分析 | 茶桁.MAMT</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="上一节中，我们介绍了大型语言模型的接口非常简单，仅提供了Complete和Embedding两个接口。但这样看似简单的接口，实际上可以解决很多自然语言处理问题。例如，情感分析、文本分类、文章聚类、摘要生成、搜索等问题，都可以使用大型语言模型解决。接下来的几节课中，我们将介绍如何使用这两个简单的API来解决传统的自然语言处理问题。本节我们将从最常见的自然语言处理问题“情感分析”开始介绍，看看如何使用">
<meta property="og:type" content="article">
<meta property="og:title" content="02 大语言模型做情感分析">
<meta property="og:url" content="https://hivan.me/Large-language-model-for-sentiment-analysis/index.html">
<meta property="og:site_name" content="茶桁.MAMT">
<meta property="og:description" content="上一节中，我们介绍了大型语言模型的接口非常简单，仅提供了Complete和Embedding两个接口。但这样看似简单的接口，实际上可以解决很多自然语言处理问题。例如，情感分析、文本分类、文章聚类、摘要生成、搜索等问题，都可以使用大型语言模型解决。接下来的几节课中，我们将介绍如何使用这两个简单的API来解决传统的自然语言处理问题。本节我们将从最常见的自然语言处理问题“情感分析”开始介绍，看看如何使用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://qiniu.hivan.me/picGo/20230601163807.png?imgNote">
<meta property="og:image" content="http://qiniu.hivan.me/picGo/20230601163817.png?imgNote">
<meta property="og:image" content="http://qiniu.hivan.me/picGo/20230601163823.png?imgNote">
<meta property="article:published_time" content="2023-05-09T08:32:50.000Z">
<meta property="article:modified_time" content="2023-06-01T08:43:47.255Z">
<meta property="article:author" content="Hivan Du">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://qiniu.hivan.me/picGo/20230601163807.png?imgNote">
  
    <link rel="alternate" href="/atom.xml" title="茶桁.MAMT" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">茶桁.MAMT</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">ChaHeng Notes，codding and writting ~</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS 订阅"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="搜索"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="搜索"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://hivan.me"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-Large-language-model-for-sentiment-analysis" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/Large-language-model-for-sentiment-analysis/" class="article-date">
  <time class="dt-published" datetime="2023-05-09T08:32:50.000Z" itemprop="datePublished">2023-05-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      02 大语言模型做情感分析
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>上一节中，我们介绍了大型语言模型的接口非常简单，仅提供了Complete和Embedding两个接口。但这样看似简单的接口，实际上可以解决很多自然语言处理问题。例如，情感分析、文本分类、文章聚类、摘要生成、搜索等问题，都可以使用大型语言模型解决。接下来的几节课中，我们将介绍如何使用这两个简单的API来解决传统的自然语言处理问题。本节我们将从最常见的自然语言处理问题“情感分析”开始介绍，看看如何使用大型语言模型。</p>
<span id="more"></span>

<h2 id="传统的二分类方法：朴素贝叶斯与逻辑回归"><a href="#传统的二分类方法：朴素贝叶斯与逻辑回归" class="headerlink" title="传统的二分类方法：朴素贝叶斯与逻辑回归"></a>传统的二分类方法：朴素贝叶斯与逻辑回归</h2><p>朴素贝叶斯与逻辑回归可以用来解决“情感分析”问题。这些算法的基本思想是，根据给定的标记数据，学习一个分类器，用来将新的输入数据进行分类。对于情感分析问题，分类器的目标是将一段文字分为正面或负面情感。</p>
<p>在这种方法中，我们首先需要对一部分评论数据进行标记，也就是手动标注这些评论是正面还是负面的。然后，我们将这些标记好的数据喂给算法进行学习。学习的过程就是从标记好的数据中提取特征，然后学习一个分类器，这个分类器可以将新的输入数据进行分类。</p>
<p>朴素贝叶斯算法是一种基于贝叶斯定理和特征条件独立假设的算法。它的基本思想是，通过已知的特征条件概率来计算输入数据的分类概率，并选择具有最大概率的类别作为分类结果。在情感分析问题中，朴素贝叶斯算法通过计算评论中每个单词在正面评论和负面评论中出现的频率来进行分类。</p>
<p>逻辑回归是一种广泛应用于分类问题的统计学习方法，其本质是利用一组输入特征和权重参数来计算一个分数，然后将分数转化为概率值。在情感分析问题中，逻辑回归通过使用输入评论的特征和权重参数来计算这段评论属于正面或负面情感的概率。</p>
<p>需要注意的是，传统的二分类方法并不一定是最优解决方案。随着深度学习技术的发展，越来越多的研究表明，使用深度学习模型可以在情感分析问题上获得更好的性能。</p>
<p>朴素贝叶斯算法是一种基于贝叶斯定理和条件独立性假设的分类算法。在垃圾邮件分类中，它的基本思想是对于一封待分类的邮件，通过计算邮件中出现单词的概率，来判断它是否为垃圾邮件。具体地，朴素贝叶斯算法会先从一组已知分类的训练集中学习出每个单词在每个分类下的条件概率，然后根据贝叶斯定理，计算待分类邮件属于每个分类的后验概率，最终将待分类邮件归类到后验概率最大的分类中。</p>
<p>具体而言，朴素贝叶斯算法假设所有特征都是相互独立的，即一个特征的出现并不会影响其它特征的出现概率，这也是“朴素”这个词的由来。在垃圾邮件分类中，这意味着我们可以将一封邮件表示为一个由词汇组成的向量，其中向量的每个元素表示一个单词是否出现在邮件中，这个元素的值通常是0或1。然后，我们可以通过计算训练集中每个单词在垃圾邮件和非垃圾邮件中的出现概率，来计算一个待分类邮件属于垃圾邮件或非垃圾邮件的概率。</p>
<p>具体地，设邮件中出现的单词为w1, w2, …, wn，将邮件表示为一个n维的向量X&#x3D;(x1, x2, …, xn)，其中xi&#x3D;1表示单词wi出现在邮件中，xi&#x3D;0表示单词wi未出现在邮件中。设邮件属于垃圾邮件的概率为P(S)，邮件属于非垃圾邮件的概率为P(H)，则有：</p>
<p>$$P(S|X) &#x3D; \frac {P(X|S)\times P(S)}{P(X)} \ P(H|X) &#x3D; \frac {P(X|H) \times P(H)} { P(X)}$$</p>
<p>其中，P(X|S)表示在垃圾邮件中，向量X出现的概率，即：</p>
<p>$$P(X|S) &#x3D; P(x_1|S) \times P(x_2|S) \times … \times P(x_n|S)$$</p>
<p>同理，P(X|H)表示在非垃圾邮件中，向量X出现的概率，即：</p>
<p>$$P(X|H) &#x3D; P(x_1|H) \times P(x_2|H) \times … \times P(x_n|H)$$</p>
<p>P(S)和P(H)分别表示训练集中垃圾邮件和非垃圾邮件的概率，可通过训练集中垃圾邮件和非垃圾邮件的数量计算得出。接下来，我们需要计算每个单词在垃圾邮件和非垃圾邮件中出现的概率，即P(wi|S)和P(wi|H)。</p>
<p>为了计算这些条件概率，我们需要统计训练集中所有垃圾邮件和非垃圾邮件中每个单词出现的次数，以及每个类别中单词的总数。然后，我们可以使用以下公式来计算每个单词在垃圾邮件和非垃圾邮件中出现的概率：</p>
<p>$$P(w_i|S) &#x3D; \frac{\text{number of times } w_i \text{ appears in spam emails}}{\text{total number of words in spam emails}} \ P(w_i|H) &#x3D; \frac{\text{number of times } w_i \text{ appears in ham emails}}{\text{total number of words in ham emails}}$$</p>
<p>在实际计算中，由于训练集中往往包含大量单词，每个单词的出现次数很少，为了避免概率为0的情况，我们通常会使用拉普拉斯平滑或其他平滑技术来调整概率值。</p>
<p>最终，我们可以使用以下公式来计算一封邮件是垃圾邮件的概率：</p>
<p>$$P(S|email) &#x3D; P(S) \cdot P(w_1|S) \cdot P(w_2|S) \cdot … \cdot P(w_n|S)$$</p>
<p>其中，email表示待分类的邮件，w1、w2、…、wn表示邮件中出现的单词。类似地，我们可以计算邮件为非垃圾邮件的概率：</p>
<p>$$P(H|email) &#x3D; P(H) \cdot P(w_1|H) \cdot P(w_2|H) \cdot … \cdot P(w_n|H)$$</p>
<p>然后，我们可以比较这两个概率的大小，将邮件分类为垃圾邮件或非垃圾邮件。这就是朴素贝叶斯分类算法的基本流程。</p>
<p>一般来说，如果一个词语在差评里出现的概率比好评里高得多，那这个词语所在的评论，就更有可能是一个差评。</p>
<p>$$P(c|x) &#x3D;  \frac{P(x|c)P_c}{P(x)} \ P(c|X)∝ P(x_1|c)\times P(x_2|c)\times … \times P(x_n|c) \times P_c$$</p>
<p>假设我们有一个训练集包含4封邮件，其中2封是垃圾邮件，2封不是垃圾邮件。训练集里的邮件包含以下单词：</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>邮件类型</th>
<th>出现的单词</th>
</tr>
</thead>
<tbody><tr>
<td>Email A</td>
<td>垃圾邮件</td>
<td>buy, money, offer, secret</td>
</tr>
<tr>
<td>Email B</td>
<td>垃圾邮件</td>
<td>buy, secret, sell, money</td>
</tr>
<tr>
<td>Email C</td>
<td>普通邮件</td>
<td>offer, book, sell</td>
</tr>
<tr>
<td>Email D</td>
<td>普通邮件</td>
<td>book, study, exam</td>
</tr>
</tbody></table>
<p>然后来了一封新邮件，里面的单词是：buy、money、sell。</p>
<p>通过计算在垃圾邮件和非垃圾邮件中这些单词出现的概率，我们可以预测这封新邮件是垃圾邮件还是非垃圾邮件。</p>
<p>$$P(buy∣垃圾)&#x3D;2÷2&#x3D;1 \ P(money∣垃圾)&#x3D;2÷2&#x3D;1 \ P(sell∣垃圾)&#x3D;1÷2&#x3D;0.5 \ P(buy∣普通)&#x3D;0÷2&#x3D;0 \ P(money∣普通)&#x3D;0÷2&#x3D;0 \ P(sell∣普通)&#x3D;1div2&#x3D;0.5$$</p>
<p>然后我们把这封邮件里所有词语的条件概率用全概率公式乘起来，就得到了这封邮件是垃圾邮件还有普通邮件的概率。</p>
<p>$$P(垃圾∣X)∝P(buy∣垃圾)×P(money∣垃圾)×P(sell∣垃圾)×P(垃圾)&#x3D;1×1×0.5×0.5&#x3D;0.25$$</p>
<p>$$P(普通∣X)∝P(buy∣普通)×P(money∣普通)×P(sell∣普通)×P(普通)&#x3D;0×0×0.5×0.5&#x3D;0$$</p>
<p>在这里，我们发现 P(垃圾∣X)&gt;P(普通∣X)，而且 P(普通∣X) 其实等于 0。那如果用朴素贝叶斯算法，我们就会认为这封邮件 100% 是垃圾邮件。</p>
<p>朴素贝叶斯算法是一种基于贝叶斯定理和条件独立性假设的分类算法，可以用来进行情感分析等分类问题。在使用朴素贝叶斯算法进行垃圾邮件分类时，通过计算每个单词在垃圾邮件和非垃圾邮件中出现的概率来判断一封邮件是否为垃圾邮件。不过，如果一封邮件中出现的单词不在训练集中，那么朴素贝叶斯算法就不能给出正确的分类结果。此外，像逻辑回归、随机森林等机器学习算法也可以用来进行分类，网上有很多其他人使用这些传统方法来设计情感分析的解决方案，可以在 Kaggle 这个机器学习比赛的网站里<a target="_blank" rel="noopener" href="https://www.kaggle.com/code/ankumagawa/sentimental-analysis-using-naive-bayes-classifier">找到相关</a>的 Jupyter Notebook。虽然这些算法背后涉及到一些数学知识，但在进行实际的 AI 应用开发时，并不需要预先掌握这些知识，因为我们可以借助各种 AI 平台和工具来进行开发。</p>
<h2 id="替代传统方法：特征工程与模型调参"><a href="#替代传统方法：特征工程与模型调参" class="headerlink" title="替代传统方法：特征工程与模型调参"></a>替代传统方法：特征工程与模型调参</h2><p>传统的机器学习算法，在应用到实际问题时，往往需要进行特征工程和模型调参，这两个方面都需要一定的经验和技巧。</p>
<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h3><p>特征工程是机器学习中非常重要的一环，通过对数据进行加工和转换，从原始数据中提取有意义的特征，以便机器学习算法更好地理解和分类数据。在自然语言处理中，特征工程尤其重要，因为自然语言数据的特征通常是复杂且非结构化的。</p>
<p>举个例子，如果我们想对一段文本进行情感分析，我们不能仅仅依靠文本中是否出现特定的单词来判断，因为不同的单词可能在不同的语境下有不同的情感含义。比如，“这家餐馆太糟糕了，一点都不好吃”和“这家餐馆太好吃了，一点都不糟糕”这两句话，从意思上是完全相反的，但是它们都包含相同的单词。这时候，我们需要通过一些特征工程的方法来解决这个问题。</p>
<p>在自然语言处理中，常用的特征工程方法包括：n-gram模型、词袋模型、TF-IDF权重等。</p>
<p>其中，n-gram模型是一种将相邻的n个单词组合在一起形成新的单词序列的方法。通过n-gram模型，我们可以考虑更多单词之间的关系，而不仅仅是单个单词的出现情况。常见的n-gram模型包括bigram（二元模型）和trigram（三元模型）。以二元模型为例，当n&#x3D;2时，我们会将相邻的两个单词组合在一起，从而得到一个新的词组，比如“太糟糕”和“不好吃”。这些词组可以更好地捕捉到单个单词无法表达的情感含义。</p>
<p>词袋模型则是一种将文本表示成一个包含其所有单词的向量的方法。在词袋模型中，我们将文本中的所有单词都列出来，形成一个向量，然后统计每个单词在文本中出现的频率，并将其对应到向量的相应位置。虽然词袋模型并不能考虑单词之间的关系，但是它可以捕捉到文本中每个单词的出现情况。</p>
<p>TF-IDF（词频-逆文档频率）权重是一种根据单词在文本中的频率和其在语料库中的文档频率来赋予单词权重的方法。在TF-IDF模型中，单词在文本中出现的次数越多，它的权重就越大，但是如果它在语料库中出现的文档频率越高，它的权重就越小。这种方法可以用来衡量一个单词在整个文本集合中的重要性，常用于文本分类、信息检索等任务中。TF-IDF权重计算公式如下：</p>
<p>$$W_{ij} &#x3D; tf_{ij} \times log \frac{N}{df_i}$$</p>
<p>其中，$$w_{i,j}$$表示单词$i$在文本$j$中的权重, $tf_{i,j}$表示单词$i$在文本中$j$出现的频率，$N$表示文本集合中的总文档数，$df_i$表示包含单词$i$的文档数。</p>
<p>在实际应用中，TF-IDF通常与其他特征一起使用。比如，在文本分类任务中，我们可以把TF-IDF作为文本特征之一，同时还可以加入词性标注、情感分析等特征来提高分类的准确性。在文本信息检索任务中，我们可以使用TF-IDF对查询和文档进行向量化，并通过计算它们之间的相似度来进行检索。</p>
<p>除了TF-IDF，还有一些其他常用的特征工程方法，比如词袋模型（Bag-of-Words）、词嵌入（Word Embedding）等，每种方法都有其优缺点和适用场景。特征工程是机器学习中非常重要的一环，正确地选择和处理特征可以大大提高模型的性能。</p>
<p>不同的特征工程方式，在不同的问题上效果不一样，比如我们做情感分析，可能就需要保留标点符号，因为像“！”这样的符号往往蕴含着强烈的情感特征。但是，这些种种细微的技巧，让我们在想要解决一个简单的情感分析问题时，也需要撰写大量文本处理的代码，还要了解针对当前特定场景的技巧，这非常依赖工程师的经验。</p>
<h3 id="机器学习相关经验"><a href="#机器学习相关经验" class="headerlink" title="机器学习相关经验"></a>机器学习相关经验</h3><p>机器学习涉及到很多知识和技巧，包括数据处理、模型训练和评估等。在数据处理方面，我们需要将数据集划分为训练集、验证集和测试集，并进行数据清洗、特征选择等操作。在模型训练方面，我们需要选择适合问题的算法、调整模型超参数，避免过拟合和欠拟合等问题。在模型评估方面，我们需要使用合适的指标来评估模型的性能，比如 AUC、准确率、召回率等。此外，针对数据集不够大的情况，我们需要采用交叉验证等技术来提高模型的泛化能力。</p>
<p>但是，随着大语言模型的发展，我们已经不再需要具备这些丰富的机器学习经验了。大语言模型提供了 Completion 和 Embedding 这两个 API，我们可以用不到 10 行代码就能完成情感分析，并且能获得非常好的效果。这极大地降低了机器学习应用的门槛，使得更多人能够轻松地利用机器学习技术来解决各种实际问题。</p>
<h3 id="大语言模型轻松解决"><a href="#大语言模型轻松解决" class="headerlink" title="大语言模型轻松解决"></a>大语言模型轻松解决</h3><p>通过大语言模型来进行情感分析，最简单的方式就是利用它提供的 Embedding 这个 API。这个 API 可以将任何一段文本转换为一个固定长度的向量，以此代表这段文本的语义信息。为了进行情感分析，我们需要事先计算“好评”和“差评”这两个标签的 Embedding。对于一段待分析的文本，我们可以通过 Embedding API 获取该文本的 Embedding。然后，我们将这个文本 Embedding 和“好评”以及“差评”的 Embedding 分别计算余弦相似度（Cosine Similarity），并将两个相似度之间的差值作为该文本的情感分数。如果分数大于 0，则说明这段文本更接近“好评”，反之则更接近“差评”。利用这种方法，我们可以在不需要大量经验和复杂特征工程的情况下，用不到 10 行代码快速地进行情感分析，并获得非常好的效果。</p>
<p>比如，咱们看一下两条惊动上购买iPhone的用户发表的评论。</p>
<blockquote>
<p>实际案例还是来自于徐文浩的文章</p>
</blockquote>
<p><img src="http://qiniu.hivan.me/picGo/20230601163807.png?imgNote" alt="notion image"></p>
<p>这个使用大模型的方法一共有 20 行代码，我们看看它能否帮助我们快速对这两条评论进行情感分析。</p>
<blockquote>
<p>注意，在执行 <code>import</code> 的时候，经常会遇到这样的错误提示： <code>ModuleNotFoundError: No module named &#39;scipy&#39;</code> 此时切换到你所使用的环境内，然后执行一遍安装就行了( <code>conda install -c conda-forge scipy</code> )，少数时候，可能你安装一个之后仍然会报缺少其他模块，继续安装。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> openai</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> openai.embeddings_utils <span class="keyword">import</span> cosine_similarity, get_embedding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取访问open ai的密钥</span></span><br><span class="line">openai.api_key = <span class="string">&quot;这里输入你的API Key&quot;</span></span><br><span class="line"><span class="comment"># 选择模型</span></span><br><span class="line">EMBEDDING_MODEL = <span class="string">&quot;text-embedding-ada-002&quot;</span></span><br><span class="line"></span><br><span class="line">positive_review = get_embedding(<span class="string">&quot;好评&quot;</span>)</span><br><span class="line">negative_review = get_embedding(<span class="string">&quot;差评&quot;</span>)</span><br><span class="line"></span><br><span class="line">positive_example = get_embedding(<span class="string">&quot;买的银色版真的很好看，一天就到了，晚上就开始拿起来完系统很丝滑流畅，做工扎实，手感细腻，很精致哦苹果一如既往的好品质&quot;</span>)</span><br><span class="line">negative_example = get_embedding(<span class="string">&quot;降价厉害，保价不合理，不推荐&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_score</span>(<span class="params">sample_embedding</span>):</span><br><span class="line">	<span class="keyword">return</span> cosine_similarity(sample_embedding, positive_review) - cosine_similarity(sample_embedding, negative_review)</span><br><span class="line"></span><br><span class="line">positive_score = get_score(positive_example)</span><br><span class="line">negative_score = get_score(negative_example)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;好评例子的评分 : %f&quot;</span> % (positive_score))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;差评例子的评分 : %f&quot;</span> % (negative_score))</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">好评例子的评分： <span class="number">0.070963</span></span><br><span class="line">差评例子的评分： -<span class="number">0.072895</span></span><br></pre></td></tr></table></figure>

<p>我们可以看到，通过大语言模型提供的 Embedding 相似度计算方法，可以非常简单地对评论进行情感分析。在对京东商品评论进行测试时，我们发现好评的相似度得分大于0，差评的得分小于0，验证了该方法的有效性。更进一步的，我们可以尝试使用这个方法来分析含义截然相反的评论，看看它能否准确判断。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">good_restraurant = get_embedding(<span class="string">&quot;这家餐馆太好吃了，一点都不糟糕&quot;</span>)</span><br><span class="line">bad_restraurant = get_embedding(<span class="string">&quot;这家餐馆太糟糕了，一点都不好吃&quot;</span>)</span><br><span class="line"></span><br><span class="line">good_score = get_score(good_restraurant)</span><br><span class="line">bad_score = get_score(bad_restraurant)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;好评餐馆的评分 : %f&quot;</span> % (good_score))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;差评餐馆的评分 : %f&quot;</span> % (bad_score))</span><br></pre></td></tr></table></figure>

<p><img src="http://qiniu.hivan.me/picGo/20230601163817.png?imgNote" alt="notion image"></p>
<p>如图所示，我们输出结果为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">好评餐馆的评分 : <span class="number">0.062719</span></span><br><span class="line">差评餐馆的评分 : -<span class="number">0.074591</span></span><br></pre></td></tr></table></figure>

<p>可以看到，虽然两句话分别是“太好吃”“不糟糕”和“太糟糕”“不好吃”，其实词语都一样，但是大语言模型一样能够帮助我们判断出来他们的含义是不同的，一个更接近好评，一个更接近差评。</p>
<h3 id="更大的数据集上的真实案例"><a href="#更大的数据集上的真实案例" class="headerlink" title="更大的数据集上的真实案例"></a>更大的数据集上的真实案例</h3><p>在前面的例子中，我们展示了利用大语言模型进行情感分析的简单方法，并验证了它在小规模数据上的有效性。那么在更大的数据集上，我们的方法是否仍然可靠呢？下面我们将以亚马逊提供的食品评论数据为例进行验证。</p>
<p>该数据集包含了用户对不同品牌的食品的评论以及所打的评分，我们可以将评分转化为好评和差评两个类别，以验证我们的方法准确度。具体而言，我们将1-2星的评分视为差评，4-5星的评分视为好评。为了避免重复计算，我们在数据集中已经提前保存了评论的Embedding信息。</p>
<p>利用Pandas读取CSV数据，我们可以将这些评论和对应的评分加载到内存中，并利用我们之前介绍的Embedding API计算评论的向量。通过计算评论向量与好评、差评向量之间的余弦距离，我们可以得到每个评论的相似度分数。最终，我们将这些分数与阈值进行比较，即可将评论分类为好评或差评。</p>
<p>重新调用 OpenAI 的 API 会很浪费钱，这个数据集里，我们将获取到的 Embedding 信息保存下来了，不需要再重新计算。</p>
<blockquote>
<p>模型和代码我都将上传到自己的Github上，有需要的可以<a target="_blank" rel="noopener" href="https://github.com/hivandu/GPT_develop">自己获取</a></p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</span><br><span class="line"></span><br><span class="line">datafile_path = <span class="string">&#x27;./data/fine_food_reviews_with_embeddings_1k.csv&#x27;</span></span><br><span class="line"></span><br><span class="line">df = pd.read_csv(datafile_path)</span><br><span class="line">df[<span class="string">&#x27;embedding&#x27;</span>] = df.embedding.apply(<span class="built_in">eval</span>).apply(np.array)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将五星评级转换为二元情绪</span></span><br><span class="line">df = df[df.Score != <span class="number">3</span>]</span><br><span class="line">df[<span class="string">&quot;sentiment&quot;</span>] = df.Score.replace(&#123;<span class="number">1</span>: <span class="string">&quot;negative&quot;</span>, <span class="number">2</span>: <span class="string">&quot;negative&quot;</span>, <span class="number">4</span>:<span class="string">&quot;positive&quot;</span>, <span class="number">5</span>:<span class="string">&quot;positive&quot;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>每一条评论都用我们上面的方法，和一个预先设定好的好评和差评的文本去做对比，然后看它离哪个近一些。这里的好评和差评，我们写得稍微长了一点，分别是 “An Amazon review with a negative sentiment.” 和 “An Amazon review with a positive sentiment.”。</p>
<p>在计算完结果之后，我们利用 Scikit-learn 这个机器学习的库，将我们的预测值和实际用户打出的星数做个对比，然后输出对比结果。需要的代码，也就不到 20 行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> PrecisionRecallDisplay</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate_embeddings_approach</span>(<span class="params"></span></span><br><span class="line"><span class="params">    labels = [<span class="string">&#x27;negative&#x27;</span>, <span class="string">&#x27;positive&#x27;</span>], </span></span><br><span class="line"><span class="params">    model = EMBEDDING_MODEL,</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    label_embeddings = [get_embedding(label, engine=model) <span class="keyword">for</span> label <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">label_score</span>(<span class="params">review_embedding, label_embeddings</span>):</span><br><span class="line">        <span class="keyword">return</span> cosine_similarity(review_embedding, label_embeddings[<span class="number">1</span>]) - cosine_similarity(review_embedding, label_embeddings[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">    probas = df[<span class="string">&quot;embedding&quot;</span>].apply(<span class="keyword">lambda</span> x: label_score(x, label_embeddings))</span><br><span class="line">    preds = probas.apply(<span class="keyword">lambda</span> x: <span class="string">&#x27;positive&#x27;</span> <span class="keyword">if</span> x&gt;<span class="number">0</span> <span class="keyword">else</span> <span class="string">&#x27;negative&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    report = classification_report(df.sentiment, preds)</span><br><span class="line">    <span class="built_in">print</span>(report)</span><br><span class="line"></span><br><span class="line">    display = PrecisionRecallDisplay.from_predictions(df.sentiment, probas, pos_label=<span class="string">&#x27;positive&#x27;</span>)</span><br><span class="line">    _ = display.ax_.set_title(<span class="string">&quot;2-class Precision-Recall curve&quot;</span>)</span><br><span class="line"></span><br><span class="line">evaluate_embeddings_approach(labels=[<span class="string">&#x27;An Amazon review with a negative sentiment.&#x27;</span>, <span class="string">&#x27;An Amazon review with a positive sentiment.&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>输出结果</p>
<p><img src="http://qiniu.hivan.me/picGo/20230601163823.png?imgNote" alt="notion image"></p>
<p>我们可以看到通过简单的调用大模型接口计算向量相似度的方法可以达到相当高的精度，而不需要进行任何机器学习训练。现在，我们来看一下如何在具体数据集上使用这个方法进行情感分析。</p>
<p>我们使用的是亚马逊商品评论数据集，包含了约 130 万条评论以及对应的评分。我们将评分为 1 或 2 的评论视为负面评论，评分为 4 或 5 的评论视为正面评论，而评分为 3 的评论则排除在外。我们使用 Python 中的 Pandas 库读取数据集，再使用 OpenAI 提供的 Embedding API 获取评论的向量表示，并计算每个评论向量与正面评论和负面评论向量之间的余弦相似度。对于余弦相似度大于 0 的评论，我们认为其为正面评论，余弦相似度小于 0 的评论则认为其为负面评论。最后，我们通过比较模型的预测结果与真实标签的一致性来评估模型的性能。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本课程介绍了使用大型语言模型进行情感分析的零样本分类方法。这种方法不需要额外的训练数据，利用大型语言模型中预训练的“好评”和“差评”的概念信息，可以判断未见过的评论的情感极性。通过计算不同文本在大型语言模型中的嵌入距离，可以进行情感分析。使用这种方法可以轻松地在经典数据集上达到95%以上的准确度，并且降低了机器学习的门槛。利用 OpenAI的API可以在几分钟内获得所需的结果，这使得文本分类的应用变得更加容易。</p>
<p>在学习完本节课程后，希望你能够进一步巩固所学内容并掌握实践能力。因此，我们建议你进行一些课后练习，以加深对大模型应用于情感分析的理解和实战能力的提升。你可以尝试将本节课程中讲解的方法应用到其他数据集上，比如 Kaggle 提供的亚马逊耳机评论数据，看看是否也会有很好的效果。该数据集较大，你可以选择挑选几条数据进行尝试，因为 OpenAI 会对你的调用进行限速，免费的 Token 数量也比较有限。对于大批量数据的处理，我们会在后面进行详细讲解。</p>
<p>欢迎你将你的结果分享到评论区，也欢迎你把这节课分享给感兴趣的朋友。我们下节课再见！</p>
<p>数据集：<a target="_blank" rel="noopener" href="https://www.kaggle.com/datasets/shitalkat/amazonearphonesreviews">https://www.kaggle.com/datasets/shitalkat/amazonearphonesreviews</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://hivan.me/Large-language-model-for-sentiment-analysis/" data-id="clid1r2g1001656j7ddnphga5" data-title="02 大语言模型做情感分析" class="article-share-link"><span class="fa fa-share">分享</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/AI/" rel="tag">AI</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/Best-ChatGPT-Chrome-Extension/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">前一篇</strong>
      <div class="article-nav-title">
        
          最佳 ChatGPT Chrome 扩展程序
        
      </div>
    </a>
  
  
    <a href="/Enter-the-door-of-AI-learn-to-communicate-with-it/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">后一篇</strong>
      <div class="article-nav-title">01 进入AI大门，学会与其交谈</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/develop/">develop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/software/">software</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%8E%A5%E8%A7%A6%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%A4%A7%E6%A8%A1%E5%9E%8B/">从零开始接触人工智能大模型</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/AI/" rel="tag">AI</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ChatGPT/" rel="tag">ChatGPT</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Chrome/" rel="tag">Chrome</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gmail/" rel="tag">Gmail</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google/" rel="tag">Google</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Google-Plus/" rel="tag">Google Plus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Gplus/" rel="tag">Gplus</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mac/" rel="tag">Mac</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Mail/" rel="tag">Mail</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Model/" rel="tag">Model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/NFC/" rel="tag">NFC</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/O2O/" rel="tag">O2O</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PS/" rel="tag">PS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Python/" rel="tag">Python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/QQ/" rel="tag">QQ</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SNS/" rel="tag">SNS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Stable-Diffusion/" rel="tag">Stable Diffusion</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Tool/" rel="tag">Tool</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Translate/" rel="tag">Translate</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/allove/" rel="tag">allove</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/app/" rel="tag">app</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/avn/" rel="tag">avn</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/blog/" rel="tag">blog</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/bluehost/" rel="tag">bluehost</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/code/" rel="tag">code</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/css/" rel="tag">css</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/device/" rel="tag">device</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/feed/" rel="tag">feed</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flickr/" rel="tag">flickr</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/forward/" rel="tag">forward</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/gmail/" rel="tag">gmail</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/habari/" rel="tag">habari</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hexo/" rel="tag">hexo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ifttt/" rel="tag">ifttt</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/install/" rel="tag">install</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ireader/" rel="tag">ireader</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/istef/" rel="tag">istef</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/javascript/" rel="tag">javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/location/" rel="tag">location</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/more/" rel="tag">more</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/net/" rel="tag">net</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/nitrous/" rel="tag">nitrous</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/node/" rel="tag">node</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pageflakes/" rel="tag">pageflakes</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/picasaweb/" rel="tag">picasaweb</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/plugin/" rel="tag">plugin</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/reader/" rel="tag">reader</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/research/" rel="tag">research</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/search/" rel="tag">search</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/sms/" rel="tag">sms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/telnet/" rel="tag">telnet</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/twitter/" rel="tag">twitter</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/url/" rel="tag">url</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/version/" rel="tag">version</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/windows-8/" rel="tag">windows 8</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/wordpress/" rel="tag">wordpress</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E4%B8%96%E7%95%8C%E6%9D%AF/" rel="tag">世界杯</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E5%BE%AE%E5%8D%9A/" rel="tag">微博</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%97%B6%E5%8C%BA/" rel="tag">时区</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%A4%BE%E4%BA%A4/" rel="tag">社交</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%8A%B1%E5%84%BF%E5%BC%80%E4%BA%86/" rel="tag">花儿开了</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%A1%A8%E6%83%85/" rel="tag">表情</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/" rel="tag">过滤器</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%BF%9B%E5%BA%A6/" rel="tag">进度</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/AI/" style="font-size: 20px;">AI</a> <a href="/tags/ChatGPT/" style="font-size: 10px;">ChatGPT</a> <a href="/tags/Chrome/" style="font-size: 10px;">Chrome</a> <a href="/tags/Gmail/" style="font-size: 10px;">Gmail</a> <a href="/tags/Google/" style="font-size: 18px;">Google</a> <a href="/tags/Google-Plus/" style="font-size: 10px;">Google Plus</a> <a href="/tags/Gplus/" style="font-size: 10px;">Gplus</a> <a href="/tags/Mac/" style="font-size: 10px;">Mac</a> <a href="/tags/Mail/" style="font-size: 10px;">Mail</a> <a href="/tags/Model/" style="font-size: 10px;">Model</a> <a href="/tags/NFC/" style="font-size: 10px;">NFC</a> <a href="/tags/O2O/" style="font-size: 10px;">O2O</a> <a href="/tags/PS/" style="font-size: 10px;">PS</a> <a href="/tags/Python/" style="font-size: 16px;">Python</a> <a href="/tags/QQ/" style="font-size: 10px;">QQ</a> <a href="/tags/SNS/" style="font-size: 10px;">SNS</a> <a href="/tags/Stable-Diffusion/" style="font-size: 12px;">Stable Diffusion</a> <a href="/tags/Tool/" style="font-size: 10px;">Tool</a> <a href="/tags/Translate/" style="font-size: 10px;">Translate</a> <a href="/tags/allove/" style="font-size: 10px;">allove</a> <a href="/tags/app/" style="font-size: 10px;">app</a> <a href="/tags/avn/" style="font-size: 10px;">avn</a> <a href="/tags/blog/" style="font-size: 10px;">blog</a> <a href="/tags/bluehost/" style="font-size: 10px;">bluehost</a> <a href="/tags/code/" style="font-size: 10px;">code</a> <a href="/tags/css/" style="font-size: 10px;">css</a> <a href="/tags/device/" style="font-size: 10px;">device</a> <a href="/tags/feed/" style="font-size: 10px;">feed</a> <a href="/tags/flickr/" style="font-size: 10px;">flickr</a> <a href="/tags/forward/" style="font-size: 10px;">forward</a> <a href="/tags/gmail/" style="font-size: 10px;">gmail</a> <a href="/tags/habari/" style="font-size: 16px;">habari</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a> <a href="/tags/ifttt/" style="font-size: 12px;">ifttt</a> <a href="/tags/install/" style="font-size: 10px;">install</a> <a href="/tags/ireader/" style="font-size: 10px;">ireader</a> <a href="/tags/istef/" style="font-size: 10px;">istef</a> <a href="/tags/javascript/" style="font-size: 10px;">javascript</a> <a href="/tags/location/" style="font-size: 10px;">location</a> <a href="/tags/more/" style="font-size: 10px;">more</a> <a href="/tags/net/" style="font-size: 10px;">net</a> <a href="/tags/nitrous/" style="font-size: 10px;">nitrous</a> <a href="/tags/node/" style="font-size: 10px;">node</a> <a href="/tags/pageflakes/" style="font-size: 10px;">pageflakes</a> <a href="/tags/picasaweb/" style="font-size: 10px;">picasaweb</a> <a href="/tags/plugin/" style="font-size: 10px;">plugin</a> <a href="/tags/reader/" style="font-size: 10px;">reader</a> <a href="/tags/research/" style="font-size: 10px;">research</a> <a href="/tags/search/" style="font-size: 10px;">search</a> <a href="/tags/sms/" style="font-size: 10px;">sms</a> <a href="/tags/telnet/" style="font-size: 10px;">telnet</a> <a href="/tags/twitter/" style="font-size: 12px;">twitter</a> <a href="/tags/url/" style="font-size: 10px;">url</a> <a href="/tags/version/" style="font-size: 10px;">version</a> <a href="/tags/windows-8/" style="font-size: 10px;">windows 8</a> <a href="/tags/wordpress/" style="font-size: 14px;">wordpress</a> <a href="/tags/%E4%B8%96%E7%95%8C%E6%9D%AF/" style="font-size: 10px;">世界杯</a> <a href="/tags/%E5%BE%AE%E5%8D%9A/" style="font-size: 10px;">微博</a> <a href="/tags/%E6%97%B6%E5%8C%BA/" style="font-size: 10px;">时区</a> <a href="/tags/%E7%A4%BE%E4%BA%A4/" style="font-size: 10px;">社交</a> <a href="/tags/%E8%8A%B1%E5%84%BF%E5%BC%80%E4%BA%86/" style="font-size: 10px;">花儿开了</a> <a href="/tags/%E8%A1%A8%E6%83%85/" style="font-size: 10px;">表情</a> <a href="/tags/%E8%BF%87%E6%BB%A4%E5%99%A8/" style="font-size: 10px;">过滤器</a> <a href="/tags/%E8%BF%9B%E5%BA%A6/" style="font-size: 10px;">进度</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">五月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">四月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">三月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">二月 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">三月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">一月 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">九月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">八月 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/06/">六月 2018</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">十一月 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/06/">六月 2014</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/12/">十二月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/08/">八月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/03/">三月 2013</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/07/">七月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/04/">四月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2012/01/">一月 2012</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/11/">十一月 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/10/">十月 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2011/07/">七月 2011</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/12/">十二月 2010</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2010/04/">四月 2010</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/10/">十月 2009</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2009/02/">二月 2009</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2008/06/">六月 2008</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/10/">十月 2006</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/09/">九月 2006</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2006/06/">六月 2006</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/Use-AI-to-write-a-snake-game/">利用AI写一个『贪吃蛇游戏』</a>
          </li>
        
          <li>
            <a href="/Use-multi-step-prompts-to-ask-AI-to-write-tests-for-you/">13 使用多步提示语让AI帮你写测试</a>
          </li>
        
          <li>
            <a href="/AI-create-a-excel-plugin/">12 AI帮你写个小插件，轻松处理Excel文件</a>
          </li>
        
          <li>
            <a href="/Save-costs-with-an-open-source-model/">11 用好开源模型节约成本</a>
          </li>
        
          <li>
            <a href="/Use-AI-to-index-and-analyze-documents-and-images/">10 利用AI索引并分析文献和图片</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 Hivan Du<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>